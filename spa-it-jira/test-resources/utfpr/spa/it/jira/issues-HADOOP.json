{
    "expand": "schema,names",
    "issues": [
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The reason that new objects are allocated during map is so that new objects will be available for the combiner.  So fixing HADOOP-110 is easy, but HADOOP-2 must be fixed first, since it is the underlying problem.",
                            "created": "2006-03-30T05:08:01.000+0000",
                            "id": "12372305",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/12372305",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-30T05:08:01.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "This patch clones the keys and values before they are cached in the CombiningCollector.\nIt adds a new method named WritableUtils.clone(Writable, JobConf) that copies the the given Writable.",
                            "created": "2006-03-31T04:29:21.000+0000",
                            "id": "12372534",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/12372534",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-03-31T04:29:21.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  Thanks Owen!",
                            "created": "2006-03-31T05:11:16.000+0000",
                            "id": "12372564",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/12372564",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-31T05:11:16.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in HBase-TRUNK #3371 (See [https://builds.apache.org/job/HBase-TRUNK/3371/])\n    HBASE-6869 Update our hadoop-2 to 2.0.1-alpha (Revision 1389071)\n\n     Result = FAILURE",
                            "created": "2012-09-23T15:53:11.677+0000",
                            "id": "13461448",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13461448",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2012-09-23T15:53:11.677+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #189 (See [https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/189/])\n    HBASE-6869 Update our hadoop-2 to 2.0.1-alpha (Revision 1389071)\n\n     Result = FAILURE",
                            "created": "2012-09-23T23:36:41.377+0000",
                            "id": "13461539",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13461539",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2012-09-23T23:36:41.377+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in flume-trunk #320 (See [https://builds.apache.org/job/flume-trunk/320/])\n    FLUME-1653: Update Hadoop-23 profile to point to hadoop-2 alpha artifacts (Revision 831a86fc5501a8624b184ea65e53749df31692b8)\n\n     Result = SUCCESS",
                            "created": "2012-10-30T03:35:09.516+0000",
                            "id": "13486624",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13486624",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2012-10-30T03:35:09.516+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Accumulo-1.5-Hadoop-2.0 #75 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/75/])\n    ACCUMULO-804: start-dfs.sh is in a different place in hadoop-2 (Revision 1467401)\n\n     Result = UNSTABLE",
                            "created": "2013-04-12T20:23:22.688+0000",
                            "id": "13630584",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13630584",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-04-12T20:23:22.688+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Accumulo-1.5 #76 (See [https://builds.apache.org/job/Accumulo-1.5/76/])\n    ACCUMULO-804: start-dfs.sh is in a different place in hadoop-2 (Revision 1467401)\n\n     Result = SUCCESS",
                            "created": "2013-04-12T20:34:10.272+0000",
                            "id": "13630602",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13630602",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-04-12T20:34:10.272+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-trunk-Commit #3938 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3938/])\n    MAPREDUCE-5184. Document compatibility for MapReduce applications in hadoop-2 vis-a-vis hadoop-1. Contributed by Zhijie Shen. (Revision 1493570)\n\n     Result = SUCCESS",
                            "created": "2013-06-16T19:15:31.688+0000",
                            "id": "13684750",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13684750",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-16T19:15:31.688+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-Yarn-trunk #243 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/243/])\n    MAPREDUCE-5184. Document compatibility for MapReduce applications in hadoop-2 vis-a-vis hadoop-1. Contributed by Zhijie Shen. (Revision 1493570)\n\n     Result = SUCCESS",
                            "created": "2013-06-17T10:53:29.796+0000",
                            "id": "13685448",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13685448",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-17T10:53:29.796+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-Hdfs-trunk #1433 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1433/])\n    MAPREDUCE-5184. Document compatibility for MapReduce applications in hadoop-2 vis-a-vis hadoop-1. Contributed by Zhijie Shen. (Revision 1493570)\n\n     Result = FAILURE",
                            "created": "2013-06-17T13:05:38.441+0000",
                            "id": "13685534",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13685534",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-17T13:05:38.441+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-Mapreduce-trunk #1460 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1460/])\n    MAPREDUCE-5184. Document compatibility for MapReduce applications in hadoop-2 vis-a-vis hadoop-1. Contributed by Zhijie Shen. (Revision 1493570)\n\n     Result = SUCCESS",
                            "created": "2013-06-17T14:09:01.694+0000",
                            "id": "13685588",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13685588",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-17T14:09:01.694+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hive-trunk-h0.21 #2175 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2175/])\n    HIVE-4436 : hive.exec.parallel=true doesn't work on hadoop-2\n (Gopal V via Navis) (Revision 1498773)\n\n     Result = FAILURE",
                            "created": "2013-07-02T15:08:25.580+0000",
                            "id": "13697863",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13697863",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-07-02T15:08:25.580+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hive-trunk-hadoop2 #269 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/269/])\n    HIVE-4436 : hive.exec.parallel=true doesn't work on hadoop-2\n (Gopal V via Navis) (Revision 1498773)\n\n     Result = FAILURE",
                            "created": "2013-07-02T17:24:17.598+0000",
                            "id": "13698008",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545/comment/13698008",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-07-02T17:24:17.598+0000"
                        }
                    ],
                    "maxResults": 14,
                    "startAt": 0,
                    "total": 14
                },
                "components": [],
                "created": "2006-02-04T05:54:30.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-03-30 05:08:01.0",
                "customfield_12310222": "1_*:*_1_*:*_4749406000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_594243000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124570",
                "customfield_12310920": "75282",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "If the map function reuses the key or value by destructively modifying it after the output.collect(key,value) call and your application uses a combiner, the data is corrupted by having lots of instances with the last key or value.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12312140",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A problem which impairs or prevents the functions of the product.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                                    "id": "1",
                                    "name": "Bug",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "new key and value instances are allocated before each map"
                            },
                            "id": "12330855",
                            "key": "HADOOP-110",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12330855"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12312140",
                        "type": {
                            "id": "10001",
                            "inward": "is depended upon by",
                            "name": "dependent",
                            "outward": "depends upon",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-31T05:11:16.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Reused Keys and Values fail with a Combiner",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2013-07-02T17:24:17.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2/watchers",
                    "watchCount": 1
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328545",
            "key": "HADOOP-2",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328545"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "This patch makes the driver process delete the output directory before submitting the job.",
                            "created": "2006-02-11T02:52:29.000+0000",
                            "id": "12365932",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328546/comment/12365932",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-11T02:52:29.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "An even safer way to fix this would be to have JobClient throw an exception if the output directory already exists.  That way folks won't inadvertantly overwrite things.",
                            "created": "2006-02-11T03:04:44.000+0000",
                            "id": "12365934",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328546/comment/12365934",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-11T03:04:44.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Ok, this patch ensures that the output directory is set and does not exist.\nIf the application wants to clobber old data, they need to delete the files themselves.\nI added the check for the output directory being set, because otherwise the job doesn't fail until\nthe reduces try to run. With the added check, they fail before they are submitted. \n\nI wasn't sure we wanted to support the no reduces case, but it was pretty easy to handle here by\nnot requiring an output directory.",
                            "created": "2006-03-23T01:39:04.000+0000",
                            "id": "12371438",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328546/comment/12371438",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-03-23T01:39:04.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  I converted under_scored variable names to camelCase.",
                            "created": "2006-03-23T04:14:11.000+0000",
                            "id": "12371459",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328546/comment/12371459",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-23T04:14:11.000+0000"
                        }
                    ],
                    "maxResults": 4,
                    "startAt": 0,
                    "total": 4
                },
                "components": [],
                "created": "2006-02-04T05:58:10.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-11 03:04:44.0",
                "customfield_12310222": "1_*:*_1_*:*_4054568000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_1288866000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "80543",
                "customfield_12310920": "78944",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The output directory for the reduces is not cleaned up and therefore if you can see left overs from previous runs, if they had more reduces. For example, if you run the application once with reduces=10 and then rerun with reduces=8, your output directory will have frag00000 to frag00009 with the first 8 fragments from the second run and the last 2 fragments from the first run.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-23T04:14:18.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Output directories are not cleaned up before the reduces run",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3/votes",
                    "votes": 1
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328546",
            "key": "HADOOP-3",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328546"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Pete Wyckoff",
                    "emailAddress": "pwyckoff@facebook.com",
                    "name": "wyckoff",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "John Xing",
                                "emailAddress": "johnx@apache.org",
                                "name": "johnx",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                            },
                            "body": "It works with new hadoop project now (tarball attached).\nThe intended commit location is http://svn.apache.org/repos/asf/lucene/hadoop/trunk/contrib/fuse\nPlease vote on this issue.",
                            "created": "2006-02-05T04:06:54.000+0000",
                            "id": "12365179",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12365179",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "John Xing",
                                "emailAddress": "johnx@apache.org",
                                "name": "johnx",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                            },
                            "updated": "2006-02-05T04:06:54.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "body": "I changed the code for fuse-hadoop. This is a working version for mounting DFS to linux file system. This version works fine with FUSE-J.2.2.3 and HADOOP.0.5.0\n\nEnjoy",
                            "created": "2006-08-17T17:35:41.000+0000",
                            "id": "12428713",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12428713",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "updated": "2006-08-17T17:35:41.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "body": "I changed the code for fuse-hadoop. This is a working version for mounting DFS to linux file system. This version works fine with FUSE-J.2.4 and HADOOP.0.5.0\n\nEnjoy",
                            "created": "2006-08-17T17:36:09.000+0000",
                            "id": "12428714",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12428714",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "updated": "2006-08-17T17:36:09.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "body": "I changed the code for fuse-hadoop. This is a working version for mounting DFS to linux file system. This version works fine with HADOOP.0.5.0\n\nEnjoy",
                            "created": "2006-08-17T17:39:31.000+0000",
                            "id": "12428717",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12428717",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nguyen Quoc Mai",
                                "emailAddress": "nmai@webmail.us",
                                "name": "nqmai",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nqmai"
                            },
                            "updated": "2006-08-17T17:39:31.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I'd like to be able to commit this to the contrib tree, but it could use a bit more polish.  Unfortunately we cannot commit the fuse-j jar file, since it is released under the LGPL.  What would be great is a build.xml that downloaded and built fuse-j.\n\nThe README could also include more info on installing fuse.\n\nOn Ubuntu I was able to do this with:\n\nsudo apt-get install fuse-utils libfuse2 libfuse-devel\n\nIf you've never built things on your Ubuntu box then you might also need:\n\nsudo apt-get install make gcc libc6-dev\n",
                            "created": "2006-08-17T21:36:08.000+0000",
                            "id": "12428802",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12428802",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-08-17T21:36:08.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "There are already tools to mount WebDAV on Windows, MacOS and Linux.  So HADOOP-496 will provide a more universal solution for this issue.  I'd like to resolve this as a duplicate of that issue.  Does anyone object?\n",
                            "created": "2006-10-28T03:41:00.000+0000",
                            "id": "12445323",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12445323",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-10-28T03:41:00.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "body": "Has anyone made any comparison (performance or other) of these two different approaches. It lloks like the webdav version (were dfs client is in servlet) introduces one more network hop compared to fuse version (where the dfs client is in machine using the dfs).\n\nOne way or the other I could easily satisfy my mounting needs with any one of these solutions - so hopefully one will be integrated (so it gets maintenance attention).\n",
                            "created": "2006-10-28T06:44:12.000+0000",
                            "id": "12445345",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12445345",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "updated": "2006-10-28T06:44:12.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I'm cancelling this patch to remove it from the queue of patches that we intend to immenently apply to the current trunk.  This is still useful stuff, and, depending on what happens with webdav, we may still decide to integrate it, so the issue should remain open for now.",
                            "created": "2006-11-03T19:29:53.000+0000",
                            "id": "12447059",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12447059",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-11-03T19:29:53.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "body": "Hello,\nWe posted this on HADOOP-496 and were pointed to this jira entry as a better place to post this patch.  Pasting our original submission message below...\n\n--------------------------------------\nHi,\n\nWe revived the old fuse-hadoop project (a FUSE-J based plugin that lets you mount Hadoop-FS). We have tried this on a small cluster (10 nodes) and basic functionality works (mount, ls, cat,cp, mkdir, rm, mv, ...).\n\nThe main changes include some bug fixes to FUSE-J and changing the previous fuse-hadoop implementation to enforce write-once. We found the FUSE framework to be straightforward and simple.\n\nWe have seen several mentions of using FUSE with Hadoop, so if there is a better place to post these files, please let me know.\n\nAttachments to follow...\n\n-thanks\n--------------------------------------\n\nAttachments include the following:\n  * fuse-j-hadoop package\n  * fuse-j patch.\n",
                            "created": "2007-12-03T19:49:02.545+0000",
                            "id": "12547964",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12547964",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "updated": "2007-12-03T19:49:02.545+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "It is unfortunate that this requires patches to the fuse-j sources.  The fuse-j project does not appear to be active, so I don't see much point in trying to submit these as a patch there.\n\nWe cannot host GPL'd code or even patches to GPL'd code at Apache.  We can however have optional commands in our build scripts that download GPL'd code.  So this could be structured as a contrib module whose build.xml, when a non-default build option is specified, downloads, patches and compiles fuse-j.  But since the patch to fuse-j itself cannot be hosted at Apache, it might be simpler to just create a jar file for the patched version, host that somewhere, and bypass the patch and compile steps.  It would be great to get this into a form that we can commit, so that it stays synchronized with the rest of Hadoop.",
                            "created": "2007-12-04T21:12:06.473+0000",
                            "id": "12548409",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548409",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2007-12-04T21:12:06.473+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I think I commented on another JIRA that I have implemented a dfs fuse module for the straight C fuse module.\n\nthus far I have only implemented read-only and everything works fine. It's been up for about a month with low use, but no problems.\n\npete\n",
                            "created": "2007-12-04T22:17:43.828+0000",
                            "id": "12548436",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548436",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2007-12-04T22:17:43.828+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I think I commented on another JIRA that I have implemented a dfs fuse module for the straight C fuse module.\n\nYes, you noted that in HADOOP-496.  Can you post a patch that implements this?",
                            "created": "2007-12-04T22:33:41.166+0000",
                            "id": "12548444",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548444",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2007-12-04T22:33:41.166+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Yes but need a couple of days to get our build guy to make the Makefile.am less facebook-centric.\n\n",
                            "created": "2007-12-04T22:50:46.387+0000",
                            "id": "12548452",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548452",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2007-12-04T22:50:46.387+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "body": "hi Doug,\n\nThanks for pointing out this issue.  I will remove the FUSE-J patch and try one of the other routes you suggested (to have a patched FUSE-J available), and will come back with a resolution on this very soon.\n\n-anurag",
                            "created": "2007-12-05T19:50:25.182+0000",
                            "id": "12548789",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548789",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "updated": "2007-12-05T19:50:25.182+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "body": "Hi Doug,\n\nI went through the license for Fuse-J and it is distributed under LGPL, do you think that would allow the Fuse-J patches to be hosted on Apache?\n\n(In the latter case we would still modify the submission above to be a contrib module that downloads Fuse-J, applies our patch, and builds it, except we won't have to find a place to host the patch).\n\n-thanks\n-anurag\n",
                            "created": "2007-12-05T20:33:42.359+0000",
                            "id": "12548806",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548806",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "updated": "2007-12-05T20:33:42.359+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I went through the license for Fuse-J and it is distributed under LGPL,\n\nUnfortunately, the ASF cannot host things published under LGPL either.  Sorry!",
                            "created": "2007-12-05T20:36:41.976+0000",
                            "id": "12548807",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548807",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2007-12-05T20:36:41.976+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "body": "hi Doug.  ok :- ), we will follow one of the alternate options you suggested of hosting either the patch or the jar file ourselves, and fixing the fuse-j-hadoop package build to work with this.  Will re-submit our changes soon.\n-thanks,\n-anurag",
                            "created": "2007-12-05T22:44:19.593+0000",
                            "id": "12548852",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12548852",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "updated": "2007-12-05T22:44:19.593+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Here's the source. I will attach the Makefiles and full tar tomorrow or Wed morning.\n\n",
                            "created": "2007-12-11T00:00:14.600+0000",
                            "id": "12550239",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12550239",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2007-12-11T00:00:14.600+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "body": "hi,\nWe re-submitted the fuse-j-hadoopfs package with the following changes (as suggested above):\n- we are hosting a patched FUSE-J on a separate server.\n- the fuse-j-hadoopfs build downloads this patched version at compile time.\n\nWe restructured the fuse-j-hadoopfs build to be a contrib, and have tested it with the Hadoop source-tree build.\n\nThe fuse-j-hadoopfs build is a no-op when a standard \"compile\" target is specified.  To actually build fuse-j-hadoopfs, the user has to specify the following command line: \"ant compile -Dbuild-fuse-j-hadoopfs=1\".\n\nWe still have the following todo's remaining:\n- Pick up some environment variables dynamically, so the user doesn't have to set them in our build.properties file (these do not affect the no-op build).\n- Change the 'hadoopfs_fuse_mount.sh' script to use the 'hadoop/bin' scripts, so it can automatically pick up hadoop-specific conf, jar and class files.\n\nThe above tarball (fuse-j-hadoopfs-03.tar.gz) consists of a directory that can be placed inside \"hadoop/src/contrib\", please let us know if we should submit this as a patch-file instead, or if we need to make more changes...\n\n-thanks\n\n",
                            "created": "2007-12-12T19:55:02.701+0000",
                            "id": "12551102",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12551102",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Anurag Sharma",
                                "emailAddress": "anurag106@hotmail.com",
                                "name": "as106",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=as106"
                            },
                            "updated": "2007-12-12T19:58:39.893+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Here's the same code (w/o the closelog after the return in main :)) and the Makefile.am - sorry I haven't been able to get to this and making a nice autoconf. But, it is easy to build:\n\n0. install hadoop 14.x\n1. build and install latest fuse\n2. compile fuse_dfs.c with 2 includes - one for fuse and one for hadoop's hdfs.h and their libraries as well.\n3. run it ./fuse_dfs -debug -server <hadoopnn> -port <hadoopnnport> /mnt/hdfs -d -o allow_other\n\nObviously, hadoop needs to be in your class path and your ld library path needs the fuse and hdfs .sos\n\nWhen ready for production remove the -debug (which is an option to fuse-dfs for deubgging) and the -d which is the fuse debugging option.\n\nOn my return from vacation, I will make better docs and autoconf.\n\nNote again, this is read only, but it is really easy to implement writes.\n\n-- pete\n",
                            "created": "2007-12-13T23:00:23.164+0000",
                            "id": "12551636",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12551636",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2007-12-13T23:00:23.164+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I implemented mkdir, mv, rm and rmdir. But, since the programmatic API doesn't use the Trash feature, this is a pretty big problem.\n\n2 solutions:\n\n1. have fuse dfs rename things into /Trash\n2. make the programmatic API use the Trash. Which is more general.\n\nI'm just wondering why the programmatic API never used trash in the first place??\n\n-- pete\n ",
                            "created": "2008-01-22T21:09:40.502+0000",
                            "id": "12561469",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12561469",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-01-22T21:09:40.502+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I'm just wondering why the programmatic API never used trash in the first place??\n\nBecause most other programmatic APIs don't.  Unix 'rm' does not use the trash, nor does the unlink system call, nor does DOS command line, etc.  Trash is usually only a feature of a user-interface, like a GUI and command shells designed for interactive use.\n",
                            "created": "2008-01-22T23:19:51.180+0000",
                            "id": "12561516",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12561516",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-01-22T23:19:51.180+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "The hadoop API is not POSIX-compliant. Wouldn't it be better to protect people from what is catastrophic data loss?\n\n",
                            "created": "2008-01-22T23:22:28.013+0000",
                            "id": "12561517",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12561517",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-01-22T23:22:28.013+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "newer version which supports mkdir, rmdir, mv, and rm. NOTE - this is still a work in progress. Any help appreciated :)\n",
                            "created": "2008-01-24T19:24:37.266+0000",
                            "id": "12562176",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12562176",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-01-24T19:24:37.266+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "body": "Since  a) the latest patches from Pete are not depending on fuse-j and b) fuse is now part of linux kernel (2.6.14 and later) It would be really nice to get this into hadoop proper. \n\nBefore that it would be nice to try this out so i am begging for some more information on how to compile this :)\nI downloaded fuse-dfs.tgz and there were two files fuse_dfs.c and Makefile.am , with what commands do I generate the makefile, tried many starting with auto* but none were succesfull.\n\n\n\n",
                            "created": "2008-01-24T20:53:23.897+0000",
                            "id": "12562214",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12562214",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "updated": "2008-01-24T20:53:23.897+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "body": "I did some testing with the c version of this tool (and managed to write a working makefile :). For some reason it only worked for me when running it with fuse debug on, anyone else seen this? Other than that it worked great.",
                            "created": "2008-01-28T16:09:19.674+0000",
                            "id": "12563182",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12563182",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "updated": "2008-01-28T16:09:19.674+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jason",
                                "emailAddress": "jason@attributor.com",
                                "name": "jason_attributor",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jason_attributor"
                            },
                            "body": "I have seen the debug issue myself, I think it is related to fuse more \nthan the fuse_dfs.c, as i also see that with some of my ssh mounts to \nsome systems.\n\n\n",
                            "created": "2008-01-28T17:43:42.655+0000",
                            "id": "12563216",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12563216",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jason",
                                "emailAddress": "jason@attributor.com",
                                "name": "jason_attributor",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jason_attributor"
                            },
                            "updated": "2008-01-28T17:43:42.655+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Sami - can you attach the Makefile? \n",
                            "created": "2008-01-28T18:08:34.945+0000",
                            "id": "12563222",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12563222",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-01-28T18:08:34.945+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "should have mentioned the problem with mine is  that it is generated with some custom auto make macros that we use here. \n",
                            "created": "2008-01-28T18:10:37.147+0000",
                            "id": "12563223",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12563223",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-01-28T18:10:37.147+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "body": "Here's the makefile I used. One should perhaps adapt to the model that the other c* modules are using.",
                            "created": "2008-01-28T18:31:37.013+0000",
                            "id": "12563235",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12563235",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                                },
                                "displayName": "Sami Siren",
                                "emailAddress": "ssiren@gmail.com",
                                "name": "siren",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                            },
                            "updated": "2008-01-28T18:31:37.013+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Here's a version with configure to make things easier.\n\nJust run bootstrap.sh after setting the right hdfs, fuse and jdk paths.\n\nI still haven't added a version # (next on my list) or better docs (next next on my list).\n\n--- pete\n",
                            "created": "2008-02-07T22:12:23.418+0000",
                            "id": "12566818",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12566818",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-07T22:12:23.418+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Includes version # from the configure.ac into fuse_dfs.c so fuse_dfs --version prints it out. And also include better README documentation.\n\nThe package is pretty much complete now other than implementing writes! If someone has 0.15+ Hadoop installed and wants to work on it, that would be great. 15 because you can see file creates before they are closed which is needed for the implementation. I only have 0.14.2 right now.\n\nThis newest version should be pretty self explanatory.\n-- pete\n",
                            "created": "2008-02-08T22:42:34.938+0000",
                            "id": "12567232",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12567232",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-08T22:42:34.938+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Pete,\n\nI have been experimenting with fuse_dfs.c and have a few questions:\n\n(1) I am using a previous version of fuse_dfs.c, mainly because I dont have bootstrap.sh. However, with respect to the new fuse_dfs.c option parsing - is this compatible with calling via mount.fuse, and autofs?\n\nThis how I currently mount using an autofs map containing:\n{code}\nhdfs            -fstype=fuse,rw,nodev,nonempty,noatime,allow_other  :/path/to/fuse_dfs_moutn/fuse_dfs.sh\\#dfs\\://namenode\\:9000\n{code}\nfuse_dfs.sh is just a shell script setting the CLASSPATH and LD_LIBRARY_PATH, and essentially, just execs the fuse_dfs. If I changed to the more recent version, I would probably have to put the dfs://namenode:9000 configuration into the script I think.\n\n(2) Have you done any sort of performance testing? I'm experimenting with HDFS for use in a mixed envionment (hadoop and non-hadoop jobs), and the throughput I see is miserable. For example, I use a test network of 8 P3-1GHz nodes, and a similar client on 100meg network.\n\nBelow, I compare cat-ing a 512MB file from (a) an NFS mount on the same network as the cluster nodes (b) using the hadoop frontend and (c) using the FUSE HDFS filesystem.\n\n{noformat}\n# (a)\n$ time cat /mnt/tmp/data.df > /dev/null\n\nreal 0m47.280s\nuser 0m0.059s\nsys 0m2.476s\n\n# (b)\n$ time bin/hadoop fs -cat hdfs:///user/craigm/data.df > /dev/null\n\nreal 0m48.839s\nuser 0m16.256s\nsys 0m7.001s\n\n# (c)\n$ time cat /misc/hdfs/user/craigm/data.df >/dev/null\n\nreal    1m41.686s\nuser    0m0.135s\nsys     0m2.302s\n{noformat}\n\nNote that the NFS and Hadoop fs -cat obtain about 10.5MB/sec, while the hdfs fuse mount (in /misc/hdfs) achieves only 5MB/sec. Is this an expected overhead for FUSE? \n\nI did try tuning rd_buf_size to match the size of reads that the kernel was requesting - ie 128KB instead of 32KB, however this made matters worse:\n\n{noformat}\n# with 128KB buffer size\n$ time cat /misc/hdfs/user/craigm/data.df >/dev/null\n\nreal    2m11.080s\nuser    0m0.113s\nsys     0m2.180s\n{noformat}\n\nPerhaps an option would be to keep the HDFS file open between reads and timeout the connection when not used, or something; read more than we need and then keep it in the memory? Both would overly complicate the neat code though!\n\n(3) If I use an autofs for hdfs, then mounts will timeout quickly (30 seconds), and then reconnect again on demand. Perhaps fuse_dfs.c can implement the destroy fuse operation to free up the connection to the namenode, etc?\n\nCheers\n\nCraig",
                            "created": "2008-02-19T22:30:27.667+0000",
                            "id": "12570484",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570484",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-19T22:30:27.667+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Craig,\n\nI may be using an older fuse? I have #dfs#dfs://hadoopNN01.facebook.com:9000 /mnt/hdfs    fuse    allow_other,rw    0 0 \n\nFor performance, it's really fast when there's 0 load on the namenode, but start running a couple of jobs and it gets killed.  Obviously because one operation may require multiple fuse calls and thus multiple dfs calls versus the single one for bin/hadoop dfs.   I'm noticing that all the critical sections in the namenode do things like logging to the debug log *IN* the critical section. And since everything locks fsRoot, just one job can really hose a real-time system. I don't see anything to do here other than trying to fix these after verifying with jconsole this is the problem.\n\nAnd I will add the autofs destroy function this week.\n\nSo, what do you think I should do for #1, revert to the older configuration code? (which was way nicer anyway). Do you have your bash script so I can use it too?\n\nthanks, pete\n\n",
                            "created": "2008-02-19T23:36:38.513+0000",
                            "id": "12570501",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570501",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-19T23:36:38.513+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "For #1, I think thats an fstab line, not an autofs line, perhaps? I'm not sure the fuse version will make any difference, mount will only pass through the source path, the dest path and the -o options. Would it be possible to keep all options for fuse_dfs.c in -o options? On the other hand, if a shell script is always needed to set the CLASSPATH and LD_LIBRARY_PATH options, then it is not as important how the options are set from fstab or autofs. (LD_LIBRARY_PATH could be fixed bya  /etc/ld.conf.d entry)\n\nMy test had no load on the namenode, and usage of the namenode CPU looks low. In contrast, the fuse_dcs CPU usage was high.\n\nI would like to profile or jconsole the fuse_dfs binary, but the getJNIEnv() method in src/c++/libhdfs/hdfsJniHelper.c could be a bit more helpful for passing agument to the JVM initialisation. Essentially, it only allows fills in -Djava.class.path from the CLASSPATH to be set, not any other arbitrary system properties or -X options etc, bah.  Reported separately as HADOOP-2857.\n\nWill attach bash script shortly.\n\nC",
                            "created": "2008-02-20T13:38:06.492+0000",
                            "id": "12570683",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570683",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-20T15:52:00.942+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Shell script to set LD_LIBRARY_PATH and CLASSPATH when called from mount.fuse (which can be called from mount, and hence from autofs etc).\n\n",
                            "created": "2008-02-20T14:52:33.776+0000",
                            "id": "12570707",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570707",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-20T14:52:33.776+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I made some changes - mainly caching the file handle in fi->fh and it's performing much better now. I'm attaching the new one.\n\n-- pete\n",
                            "created": "2008-02-20T23:11:53.616+0000",
                            "id": "12570878",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570878",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-20T23:11:53.616+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "newest fuse dfs which should perofrm better on reads. I'm seeing this on a cluster in use:\n\n > time cat part-00000 > /dev/null \n\nreal    1m25.078s\nuser    0m0.056s\nsys     0m1.514s\n > du -kh part-00000 \n1.1G    part-00000\n\n",
                            "created": "2008-02-20T23:13:42.805+0000",
                            "id": "12570879",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570879",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-20T23:13:42.805+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Craig,\n\nI'm setting fi->fh in open as you suggest. You're right I didn't look at pread and tell here - good point.\n\n-- pete\n",
                            "created": "2008-02-20T23:46:18.674+0000",
                            "id": "12570889",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570889",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-20T23:46:18.674+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I added the destroy method. Also looked and pread should be correct. \n\nI'm hoping to test with 0.16.x soon and see if writes work!\n\n-- pete\n",
                            "created": "2008-02-21T00:25:51.111+0000",
                            "id": "12570905",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570905",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-21T00:25:51.111+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "version 0.2.0 includes better read and in theory writes but they won't work wi/o hadoop 0.16 and I can't test. Obviously, the writes have to be append only.  And I'm still not sure what the semantics are as far as block size.\n\n",
                            "created": "2008-02-21T00:40:56.785+0000",
                            "id": "12570907",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570907",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-21T00:40:56.785+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "should have been this one that includes init method :)\n",
                            "created": "2008-02-21T00:57:24.169+0000",
                            "id": "12570910",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12570910",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-21T00:57:24.169+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "\nHi Pete,\n\n\nDefinently using the latest tar this time ;-)\nMy first time using the new build system - looks good! \n\nSome comments:\n\n1. Firstly, I shouldnt have deleted my last comment - though it was clearly in error as I was reading the wrong version of fuse_dfs.c. In your comments, can you say which file you've just uploaded?\n\nFor posterity, previous comment was:\n\n{quote}\n\nI will try the newer version tomorrow when @work. I note that fi->fh isnt used or set in dfs_read in your latest version. Could we set it in dfs_open for O_READONLY, and then use it if available? \n\nI'm not clear on the semantics of hdfsPread  - does it assume that offset is after previous offset?\nIf so then we need to check that the current read on a file is strictly after the previous read for a previously open FH to be of use - hdfsTell could be of use here.\n{quote}\n\n2. With respect to the read speed, this is indeed a bit faster in our test setting (nearer 6MB/sec), but not yet similar to the Hadoop fs shell (about 10.5MB/sec). Fuse version 2.7.2\n{noformat}\n# time bin/hadoop fs -cat /user/craigm/data.df > /dev/null \n\nreal    0m50.347s\nuser    0m16.023s\nsys     0m6.644s\n\n# time cat /misc/hdfs/user/craigm/data.df > /dev/null \n\nreal    1m31.263s\nuser    0m0.131s\nsys     0m2.384s\n\n{noformat}\nI'm trying to measure the CPU taken by fuse_dfs for the same read, so we know how much CPU time it burns.\n\nCan I ask how your test time test compares to using the Hadoop fs shell on the same machine? When reading, the CPU on the client is used 45%ish, similar to the Hadoop fs shell CPU use.\n\nI feel it would be good to aim for similar performance as the Hadoop fs shell, as this seems reasonable compared to NFS in my test setting, and should scale better as the number of concurrent reads increases, given available wire bandwidth.\n\n3. With respect to the build system, it could be clearer what --with-dfspath= is meant to point to. src/Makefile.am seems to assume that include files are at ${dfspath}/include/linux and the hdfs.so at ${dfspath}/include/shared. This isnt how the Hadoop installation is laid out. Perhaps it would be better if we could give an option to the hadoop installation and it's taken from there?\n\n4. src/Makefile.am assumes an amd64 architecture. Same problem I noted in my shell script about guessing the locations of the JRE shared lib files.\n\n5 (minor). the last tar.gz had a link to aclocal.m4 in the external folder that was absolute - ie to your installation. Should be deleted when building tar file.\n\n6 (minor). update print_usage if you're happy with the specification of filesystem options. I made no changes to my shell script or my autofs mount for this version to work :-)\n\n\nCheers\n\nCraig",
                            "created": "2008-02-21T10:43:58.248+0000",
                            "id": "12571004",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12571004",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-21T10:43:58.248+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rui Shi",
                                "emailAddress": "shearershot@yahoo.com",
                                "name": "ruish",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ruish"
                            },
                            "body": "Hi Pete,\n\nCould you please explain in more details why write can not be implemented before 0.16. And how we expect write to work with 0.16?\n\nThanks a lot!\n\nRui\n",
                            "created": "2008-02-21T22:22:53.569+0000",
                            "id": "12571211",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12571211",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rui Shi",
                                "emailAddress": "shearershot@yahoo.com",
                                "name": "ruish",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ruish"
                            },
                            "updated": "2008-02-21T22:22:53.569+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Pete,\n\nI have tried everything to profile fuse_dfs. Valgrind (callgrind) doesnt play with Sun Java, and I failed to get the GNU profiler to give any output. I wrote a patch for HADOOP-2857, but using this I cant get any stack traces from the Java profiler - it's as if no Java code is run!\n\nCraig\n\n",
                            "created": "2008-02-22T13:13:46.295+0000",
                            "id": "12571399",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12571399",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-22T13:13:46.295+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Rui,\n\nIt's because of the order FUSE calls the implementation. The file is created with an open and then closed and then opened again. \n\nSo in <16, that second open in write mode will fail :(  I have tried hacking things so that the code doesn't do the close on the file in between and caches the filehandle and so fakes the second open and everything works fine.\n\nSo, I think as long as appends are coming in, it should work with 16. I haven't looked at the implementation, but hopefully it buffers things till it gets to a full block and isn't creating small blocks all over the place :)  If it does, it's easy enough to buffer in fuse (although 128MB is a big buffer).\n\npete\n\nps although we're on 15.3 at FB, I can't upgrade our test cluster to 16 yet as we want to install HBASE and need to try it there. I'm gonna try applying the hbase patch that  the powerset guys nicely gave me soon and then if all goes well, I can upgrade our test cluster to 16 and test things.\n\n",
                            "created": "2008-02-26T01:14:03.271+0000",
                            "id": "12572334",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12572334",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-26T01:14:03.271+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Craig,\n\nI see now that the buffer size for the OS reads is only 128K and since there's no ioctl for fuse to bump it up, it's a problem. I think what we can do is create a fuse block device mount and then using blockdev -setblocksize 128M, we should see some real speedups.\n\nUnfortunately, fuse on my dev machine isn't configured properly for this.  First there's no /dev/fuseblk  which it assumes and even with that there I get a useless error message.\n\nI just want to verify with one of the kernel guys here how big the buffer can get before going to crazy. I'll ask one of them today and update this tomorrow.\n\n-- pete\n",
                            "created": "2008-02-26T01:18:43.194+0000",
                            "id": "12572335",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12572335",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-26T01:18:43.194+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Craig,\n\nI should mention I tried to get fuse to do more readahead than 128K, but setting that param didn't seem to do anything. I can probably play with this tomorrow.  To be honest, I don't know exactly what it means when you configure fuse module as a block device since you also need to specify the mount point. Is fuse under the covers just doing the block device so we can do better ioctl? I mean there's no way to implement a real block device since we'd have to make it look like a real filesystem. But, fuse requires both the block device and the mount point.\n\n-- pete\n",
                            "created": "2008-02-26T01:33:17.812+0000",
                            "id": "12572338",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12572338",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-26T01:33:17.812+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Hi Pete,\n\nThe block stuff in fuse is appallingly documented. I have hunted the Web for info on this all afternoon, to understand it further. To be honest, the only thing I have found useful is reading the source of ntfs-3g.c at http://ntfs-3g.cvs.sourceforge.net/ntfs-3g/ntfs-3g/src/ntfs-3g.c?revision=1.106&view=markup\n\nI test I did do a few days ago was to comparing reading an NFS mounted file directly vs, the same file read via NFS via a FUSE fs - http://mattwork.potsdam.edu/projects/wiki/index.php/Rofs#rofs_code_.28C.29 (ROFS, the Read-Only Filesystem). Speed results were fairly comparable between NFS & NFS+ROFS, so it suggests that FUSE doesnt add too much overhead to IO. Hence then we can only suspect that the problem is in either (a) JNI interface, or (b) the size of the reads we're performing. A simple C tool can be generated to exclude (a).\n\nI dont have any objections to pretty large buffer sizes for fuse_dfs.c - HDFS is designed for large files, and streaming read access.\n\nBtw, you mentioned you are re-exporting the mounted FS as NFS - have you had any issues vs the issues described in fuses' README.NFS? \n\nRegards\n\nCraig\n",
                            "created": "2008-02-26T18:44:08.352+0000",
                            "id": "12572599",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12572599",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-02-26T18:55:08.028+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "\nI just talked to one of our kernel guys and he isn't 100% sure as he hasn't done that much IO stuff on Linux but thinks the 128K readahead may just be the maximum.  \n\nwe could always do like 1MB readaheads ourselves although that would complicate things - although not that much since we could keep the cached data with the open file handle so there's no dirty cache problems or garbage collection issues since we just dump it when we do the close. So, maybe that's the easiest way to go... I can probably look at that tomorrow or Thursday.\n\npete\n",
                            "created": "2008-02-26T19:30:51.643+0000",
                            "id": "12572622",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12572622",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-02-26T19:30:51.643+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rui Shi",
                                "emailAddress": "shearershot@yahoo.com",
                                "name": "ruish",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ruish"
                            },
                            "body": "Hi Pete,\n\nThanks a lot for the explanation!\n\nBut as I heard from the hdfs team, 0.16 still does not support file appending. Suppose appending is not supported, can we still try writing file in Fuse as the work around you described?\n\nThanks,\n\nRui\n\n\n\n",
                            "created": "2008-02-28T00:59:37.918+0000",
                            "id": "12573115",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12573115",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rui Shi",
                                "emailAddress": "shearershot@yahoo.com",
                                "name": "ruish",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ruish"
                            },
                            "updated": "2008-02-28T00:59:37.918+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Hi Pete,\n\nHave you had a chance to look at FUSE readaheads? I have attached a version of fuse_dfs.c I have patched, which reads 10MB chunks from DFS, and cache these in the a struct held in the filehandle. \n\nI'm seeing some improvement (down to 1m 20 compared to \"bin/hadoop dfs -cat file > /dev/null\" which takes about 50 seconds). Increasing the buffer size shows some improvement [I only did some quick tests]  - I tried up to 30MB, but I dont think there's much improvement over 5-10MB\n\nDo you think we're reaching the limit such that the overheads of JNI are making it impossible to go any faster? Ie Where do we go from here?\n\nAnother comment I have is that the configure/makefile asks for a dfs_home. It might be easier to ask for Hadoop home, then build the appropriate paths from there (${hadoop_home}/libhdfs and ${hadoop_home}/src/c++/libhdfs). Hadoop has no include/linux folders etc. Finally, we need a way to detect whether to use i386 or amd64 to find jvm.so\n\nCraig",
                            "created": "2008-03-19T18:38:44.654+0000",
                            "id": "12580496",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12580496",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-03-19T18:38:44.654+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "HEre's my most recent one. I will try merging Craig's read ahead code in and then I guess see about getting it into contrib.\n",
                            "created": "2008-04-10T23:44:37.671+0000",
                            "id": "12587816",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587816",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-10T23:44:37.671+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I should have mentioned I fixed the autoconf problems and made the \"protectedpaths\" configurable. I guess we'll have to have a discussion about whether people like this because I think Doug clearly doesn't :)\n",
                            "created": "2008-04-10T23:45:51.336+0000",
                            "id": "12587818",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587818",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-10T23:45:51.336+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "This is by no means a completely final product but more of a version 0.1. but, it has decent autoconf, comments and readme files and has been working in production for quite a while.\n",
                            "created": "2008-04-11T00:54:40.135+0000",
                            "id": "12587820",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587820",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-11T00:54:40.135+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "First checkin.\n",
                            "created": "2008-04-11T00:55:58.697+0000",
                            "id": "12587821",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587821",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-11T00:55:58.697+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Changed the affected versions and fixes to unknown from 0.5",
                            "created": "2008-04-11T00:57:04.076+0000",
                            "id": "12587822",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587822",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-11T00:57:04.076+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12379898/patch.txt\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included -1.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit -1.  The applied patch generated 211 release audit warnings (more than the trunk's current 202 warnings).\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2201/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2201/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2201/artifact/trunk/build/test/checkstyle-errors.html\nRelease audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2201/artifact/trunk/current/releaseAuditDiffWarnings.txt\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2201/console\n\nThis message is automatically generated.",
                            "created": "2008-04-11T02:15:20.732+0000",
                            "id": "12587829",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12587829",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-04-11T02:15:20.732+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Help - I don't know what a release audit warning is ?? It just lists the filenames in the release audit link.\n\nAlso, unit testing for this is pretty hard, but can be done to some extent in the future by running each function like fuse calls them, but these would be C unit tests anyway which I don't know if we have support for.\n\nDo people want to comment on the feature of moving deleted files to /Trash and also of not allowing rmdir on some \"special directories\" e.g., '/' '/user' /warehouse' ... ??",
                            "created": "2008-04-11T18:29:30.196+0000",
                            "id": "12588068",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12588068",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-11T18:29:30.196+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The release audit flags new files that don't contain the Apache license (or old files that have had it removed).  In this case most of those flagged are fine to not have the Apache license, since they're automatically generated stuff, but it probably wouldn't hurt to add it to the shell scripts.\n\nSome automated tests would be good, e.g., an end-to-end test that starts HDFS, mounts it with fuse, and then lists and reads files through the mount.  But such tests should not be run by default, since the default build does not compile C++ code, nor should it depend on fuse being installed.  But it would be good to eventually configure Hudson to run these, to verify that fuse continues to show signs of life as Hadoop evolves.\n\nSo, in summary, Hudson will not generate a clean report card for this issue, since it will contain some files that don't have the Apache license, and Hudson will not, at this point, automatically run any new JUnit tests for it.  But that doesn't mean that some licenses and tests shouldn't still be added before we commit the patch.",
                            "created": "2008-04-11T19:13:01.544+0000",
                            "id": "12588080",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12588080",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-11T19:13:01.544+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Doug,\n\nI will add the header to all the files - think I just had it in the C file.\n\nSure, I will add a Python script or something to drive creating a few files in DFS sand then trying to ls and cat them from a mount.\n\npete\n",
                            "created": "2008-04-11T21:56:32.739+0000",
                            "id": "12588146",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12588146",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-11T21:56:32.739+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I will add a Python script or something to drive creating a few files in DFS sand then trying to ls and cat them from a mount.\n\nIt will be easier to integrate Java unit tests.  Also, currently I don't think we require Python, so I wouldn't want to add a system dependency just to test one component.  Perhaps, if you don't like Java, you could write tests in C or as bash scripts, then somehow hook them into the test-contrib target?",
                            "created": "2008-04-11T22:39:11.109+0000",
                            "id": "12588152",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12588152",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-11T22:39:11.109+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nigel Daley",
                                "emailAddress": "nigel@apache.org",
                                "name": "nidaley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nidaley"
                            },
                            "body": "FWIW, Hudson nightly and patch builds do run with -Dcompile.c++=yes so that tests for Pipes and libhdfs get built and run.  What doesn't get built is the eclipse plugin and the native compression library (libhadoop).",
                            "created": "2008-04-11T23:01:18.104+0000",
                            "id": "12588160",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12588160",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Nigel Daley",
                                "emailAddress": "nigel@apache.org",
                                "name": "nidaley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=nidaley"
                            },
                            "updated": "2008-04-11T23:01:18.104+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Latest update - includes all the headers for license in every file and a test/TestFuseDFS.java . Not sure how to link this into the other build.xmls to have it buil\\t and run but assume we don't want that right now anwyay.\n",
                            "created": "2008-04-15T18:47:14.818+0000",
                            "id": "12589189",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12589189",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-15T18:47:14.818+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "I have created HADOOP-3264 noting the fact that permissions/owner/group-owner get/set isnt supported in libhdfs, and would be useful for fuse-hdfs. Not a blocker for this JIRA, but related all the same.\n\n",
                            "created": "2008-04-16T11:53:03.135+0000",
                            "id": "12589508",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12589508",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-04-16T11:53:03.135+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I updated the patch and am hoping this operation re-starts things JIRA wise - ie runs tests and email Doug.\n",
                            "created": "2008-04-17T19:00:00.388+0000",
                            "id": "12590151",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12590151",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-17T19:00:00.388+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "newest patch.\n",
                            "created": "2008-04-17T23:35:49.849+0000",
                            "id": "12590242",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12590242",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-17T23:35:49.849+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "incremeneted patch #",
                            "created": "2008-04-17T23:37:57.547+0000",
                            "id": "12590243",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12590243",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-17T23:37:57.547+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Pete,\n\nI havent had time to test your latest patch, but things seems to be improving. I note your comments about exporting the fuse mount. There is a README.NFS in the fuse distribution, which concerns exporting FUSE mounts.  I have copied it in verbatim below from version 2.7.3  - seems not quite mature yet.\n\n{noformat}\nFUSE module in official kernels (>= 2.6.14) don't support NFS\nexporting.  In this case if you need NFS exporting capability, use the\n'--enable-kernel-module' configure option to compile the module from\nthis package.  And make sure, that the FUSE is not compiled into the\nkernel (CONFIG_FUSE_FS must be 'm' or 'n').\n\nYou need to add an fsid=NNN option to /etc/exports to make exporting a\nFUSE directory work.\n\nYou may get ESTALE (Stale NFS file handle) errors with this.  This is\nbecause the current FUSE kernel API and the userspace library cannot\nhandle a situation where the kernel forgets about an inode which is\nstill referenced by the remote NFS client.  This problem will be\naddressed in a later version.\n\nIn the future it planned that NFS exporting will be done solely in\nuserspace.\n{noformat}\n\nRegards\n\nC",
                            "created": "2008-04-18T19:08:01.396+0000",
                            "id": "12590576",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12590576",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-04-18T19:08:01.396+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12380454/patch2.txt\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2277/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2277/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2277/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2277/console\n\nThis message is automatically generated.",
                            "created": "2008-04-20T08:47:31.949+0000",
                            "id": "12590751",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12590751",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-04-20T08:47:31.949+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Can someone please validate that this works for them?",
                            "created": "2008-04-25T20:08:24.835+0000",
                            "id": "12592488",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592488",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2008-04-25T20:08:24.835+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I finally got this to compile, after modifying plain-bootstrap.sh and src/Makefile.am.  The latter has some hardwired paths to make things work for Pete.  Most of the stuff in the former is stuff that's already known to Hadoop's build (JDK location, libhdfs location, etc.)\n\nIt should be possible to get this to build from the top-level build.xml, provided:\n - one specifies a -Dcompile.fuse=true or somesuch option\n - one has the appropriate unix environment (g++ installed, libfuse-dev installed, etc.)\nThe environmental requirements should be described as best as possible in the README.  The build should be dependent on libhdfs.\n\nPete, are you familiar with Ant?\n",
                            "created": "2008-04-25T22:00:02.397+0000",
                            "id": "12592517",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592517",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-25T22:00:02.397+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Addressed doug's concerns.\n\nI got rid of the home/pwyckoff sutff in Makefie.am, switched all the autoconf variables to match build.xml env vars and added a compile-fusedfs target to src/contrib/build-contrib.xml and I updated the documents.\n\nSo, now to build, you:\n\nant compile-contrib -Dfusedfs=1\n\n",
                            "created": "2008-04-26T01:47:23.857+0000",
                            "id": "12592540",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592540",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-26T01:47:23.857+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "patch2.txt old news\n",
                            "created": "2008-04-26T01:47:59.091+0000",
                            "id": "12592541",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592541",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-26T01:47:59.091+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "patch3.txt\n",
                            "created": "2008-04-26T01:48:17.002+0000",
                            "id": "12592542",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592542",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-26T01:48:17.002+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12380975/patch3.txt\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    patch -1.  The patch command could not apply the patch.\n\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2335/console\n\nThis message is automatically generated.",
                            "created": "2008-04-26T02:08:07.147+0000",
                            "id": "12592549",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592549",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-04-26T02:08:07.147+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Maurizio",
                                "emailAddress": "maurizio316@interfree.it",
                                "name": "maurizio316",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=maurizio316"
                            },
                            "body": "Hi, \nprobably I'm missing something, but I don't understand how patch mechanism works. (Actually, I'm not sure this is the appropriate way, in term of netiquette, to find help)\nDo I download and untar every files present above?\nCould someone suggest me how I can install this sw?\n\nthanks in advance\n\nMaurizio",
                            "created": "2008-04-26T09:15:31.067+0000",
                            "id": "12592559",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592559",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Maurizio",
                                "emailAddress": "maurizio316@interfree.it",
                                "name": "maurizio316",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=maurizio316"
                            },
                            "updated": "2008-04-26T09:18:51.390+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "I have some minor issues. I was working on compiling on Friday afternoon, but Doug beat me to it with identical comments ;-)\n\n\n * I see that the ant script calls the make file, with the correct env vars overridden. In that case, do we need the bootstrap, automake, configure etc? Why not a simpler build system like that used by libhdfs etc? The makefile contains references to the system that configure was run on.\n * build-contrib.xml in patch3.txt has the wrong path.\n * I think it would be better if the built fuse_dfs module was placed in $HADOOP_HOME/contrib/fuse-dfs, in a similar manner to libhdfs, etc\n * If we're keeping configure et al:\n ** README.BUILD refers to bootstrap.sh, while the script is plain_bootstrap.sh\n ** the configure script doesnt identify the JARCH for non-64bit platforms - see config.log for my platform\n{code}\nconfigure:1377: checking target system type\nconfigure:1391: result: i686-pc-linux-gnu\n{code}\nbut JARCH is unset, should be i386. I presume this works ok from the ant script?\n * fuse_dfs_wrapper.sh has some issues - perhaps you could base this more closely on the fuse_dfs.sh I attached previously to this JIRA?\n  ** various variables have to be written in, eg JAVA_HOME, OS_ARCH has already been identified in configure/ant?, why cant they be set in the script?\n  ** fuse_dfs should be called with \"$@\" instead of $1 $2. However, if i use \"$@\" then and call the wrapper script via mount, then mount add -o ro to the end, and fuse_dfs cant handle this?\n  ** the classpath is hard-coded - why can't you identify all the classpath automatically from the HADOOP_HOME path?\n \n\nWill test new build in due course.\n\nMaurizio - see http://en.wikipedia.org/wiki/Patch_(Unix) and apply the patch to a recent release of Hadoop. It requires FUSE.",
                            "created": "2008-04-26T23:14:34.406+0000",
                            "id": "12592602",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592602",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-04-28T12:52:52.732+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "\nFixed a few changes and addressed the points Craig and Doug brought up.\n\nChanges:\n\n1. I changed the top-level build to have a compile-contrib-fuse target that exports the right properties and then has a subant task of the build.xml in the fuse-dfs directory.\n   NOTE: I couldn't use the normal compile-contrib path as that path doesn''t inherit properties to the subant call.  I think it's much easier for the million properties set in the top level build.xml to be available in the subant call rather than trying to re-create them. And since this is a build, I needed arch related ones.\n\n2. fixed fuse_dfs_wrapper.sh to set env vars only if not set and to pass all the args ala $@ to the executable\n\n3. added build.xml in src/contrib/fuse-dfs\n  It (A) calls bootstraph.sh to get a correct Makefile and then (B) calls the Makefile to build fuse_dfs\n  NOTE: I left all the autoconf stuff because doing something like libhdfs where there's only a Makefile would cause bad builds for environments unlike mine - I end up having to edit Makefile for libhdfs to set OS_ARCH=amd64.\n\n4. I updated README and I removed README.build",
                            "created": "2008-04-28T19:00:00.534+0000",
                            "id": "12592874",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592874",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-28T19:00:00.534+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Hi Maurizio,\n\nTo apply this patch, go to your checkout of hadoop - the top level and do \"patch -p0 < patch4.txt\"\n\nThis should apply it, and then read the README is src/contrib/fuse-dfs on instructions on how to compile. Let me know if you have any problems.\n\n-- pete\n",
                            "created": "2008-04-28T19:03:02.527+0000",
                            "id": "12592875",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592875",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-28T19:03:02.527+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "patch4.txt",
                            "created": "2008-04-29T01:35:53.549+0000",
                            "id": "12592934",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12592934",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-29T01:35:53.549+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12381125/patch4.txt\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs -1.  The patch appears to cause Findbugs to fail.\n\n    core tests -1.  The patch failed core unit tests.\n\n    contrib tests -1.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2339/testReport/\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2339/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2339/console\n\nThis message is automatically generated.",
                            "created": "2008-04-29T20:13:06.610+0000",
                            "id": "12593096",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593096",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-04-29T20:13:06.610+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "This still doesn't work out of the box for me.  I'll attach a new version that does.",
                            "created": "2008-04-29T21:14:34.105+0000",
                            "id": "12593120",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593120",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-29T21:14:34.105+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Here's a version that builds for me.  I changed it to fit within the normal contrib compilation framework.\n\nIf you want to compile it alone, manually, then you must first run 'ant -Dcompile.c++=1 compile-libhdfs' at root, then run 'ant -Dfusedfs=1' when connected to src/contrib/fuse-dfs, or you can simply run 'ant compile-contrib -Dcompile.c++=1 -Dcompile.fusedfs=1' at top-level to compile it along with all other contrib modules.\n\nI have not yet tested that it runs, however.\n\nBuilding this generates a lot of files that we'll need to add to the svn ignore list, and that are not removed by 'make clean'.  Are all of these needed?\n",
                            "created": "2008-04-29T21:24:54.582+0000",
                            "id": "12593126",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593126",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-29T21:24:54.582+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The right version of the patch...",
                            "created": "2008-04-29T21:26:37.289+0000",
                            "id": "12593128",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593128",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-29T21:26:37.289+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "After applying the patch you must 'chmod +x src/contrib/fuse-dfs/bootstrap.sh' before building the first time.\n",
                            "created": "2008-04-29T21:33:12.654+0000",
                            "id": "12593133",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593133",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-29T21:33:12.654+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12381140/HADOOP-4.patch\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs -1.  The patch appears to cause Findbugs to fail.\n\n    core tests -1.  The patch failed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2344/testReport/\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2344/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2344/console\n\nThis message is automatically generated.",
                            "created": "2008-04-29T23:23:25.156+0000",
                            "id": "12593165",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593165",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-04-29T23:23:25.156+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "thanks doug. I will provide a make clean that cleans up everything.\n\n",
                            "created": "2008-04-29T23:26:52.529+0000",
                            "id": "12593168",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593168",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-29T23:26:52.529+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Doug,\n\nYour patch didn't seem to work for me unless I modified the entries using ${basedir} in src/contrib/fuse-dfs/build.xml to  append ../../../ to it. It seems in my build, basedir is now the fuse-dfs dir whereas before, I think it was pointing to the top level ??\n\nI'm also uploading patch5.txt which  includes a clean: target that does all the clean up in the Makefile in src/contrib/fuse-dfs.\n\nBut, note I had to include the below difference to src/contrib/fuse-dfs/build.xml (other than that it's identical to your patch).\n\nthanks, pete\n\n\n\n--- fuse-dfs/build.xml  2008-04-29 17:41:55.000000000 -0700\n+++ fuse-dfs.new/build.xml  2008-04-29 17:37:47.000000000 -0700\n@@ -22,10 +22,9 @@\n   <!-- fuse-dfs targets.                                                  -->\n   <!-- ================================================================== -->\n   <target name=\"compile\" if=\"fusedfs\">\n-    <property name=\"fuse-dfs.dir\" value=\"${basedir}/src/contrib/fuse-dfs/\"/>\n+    <property name=\"fuse-dfs.dir\" value=\"${basedir}\"/>\n     <exec dir=\"${fuse-dfs.dir}\" executable=\"${fuse-dfs.dir}/bootstrap.sh\">\n     </exec>\n-\n     <exec dir=\"${fuse-dfs.dir}\" executable=\"make\">\n       <env key=\"OS_NAME\" value=\"${os.name}\"/>\n       <env key=\"OS_ARCH\" value=\"${os.arch}\"/>\n@@ -29,11 +28,10 @@\n     <exec dir=\"${fuse-dfs.dir}\" executable=\"make\">\n       <env key=\"OS_NAME\" value=\"${os.name}\"/>\n       <env key=\"OS_ARCH\" value=\"${os.arch}\"/>\n-      <env key=\"HADOOP_HOME\" value=\"${basedir}\"/>\n+      <env key=\"HADOOP_HOME\" value=\"${basedir}/../../..\"/>\n       <env key=\"PROTECTED_PATHS\" value=\"/,/Trash,/user\"/>\n       <env key=\"PACKAGE_VERSION\" value=\"0.1.0\"/>\n       <env key=\"FUSE_HOME\" value=\"/usr/local\"/>\n-      <env key=\"LIBHDFS_BUILD_DIR\" value=\"${basedir}/src/c++/libhdfs\"/>\n     </exec>\n   </target>\n </project>\n",
                            "created": "2008-04-30T00:43:37.275+0000",
                            "id": "12593183",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593183",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-30T00:43:37.275+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Note, the comment I made about the {basedir} in src/contrib/fuse-dfs/build.xml seems to be the thing that also made the last hudson build fail.",
                            "created": "2008-04-30T00:51:00.239+0000",
                            "id": "12593186",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593186",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-30T00:51:00.239+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "sorry - should be patch4.txt\n",
                            "created": "2008-04-30T00:52:29.764+0000",
                            "id": "12593187",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593187",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-04-30T00:52:29.764+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Your diff above isn't to my patch.  My patch, e.g., sets HADOOP_HOME to ${hadoop.home}, not to ${basedir}.  In my patch, src/contrib/fuse-dfs/build.xml does not refer to ${basedir} at all, since ${basedir} is the CWD and can thus be elided in relative paths.",
                            "created": "2008-04-30T18:30:27.448+0000",
                            "id": "12593400",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593400",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-30T18:30:27.448+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "fixes the cleanup problem",
                            "created": "2008-05-01T18:35:44.139+0000",
                            "id": "12593604",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593604",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T18:35:44.139+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Your changes to src/c++/libhdfs/Makefile break things for me.  Also, you undid one of my changes to build.xml, making compile-libhdfs conditional on compile.c++.  This is required to make compile-libhdfs an optional target, which we must do now that compile-contrib depends on it.  Finally, there are still a lot of generated symlinks and files left in src/contrib/fuse-dfs after a 'make clean'.",
                            "created": "2008-05-01T20:22:56.641+0000",
                            "id": "12593627",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593627",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-01T20:22:56.641+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "all im' trying to do is add:\n\nclean:\n        rm -rf autom4te.cache config.guess config.log config.status config.sub configure depcomp src/.deps install-sh Makefile.in src/Makefile.in src/Makefile missing Makefile src/fuse_dfs.o src/fuse_dfs\n\nto src/contrib/Makefile.am   (this will clean up everything)\n\nand change src/contrib/build.xml to do executable bin/sh with arg value=bootstrap.sh to avoid the chmod +x problem.\n\nI thought that is all i changed.\n\n",
                            "created": "2008-05-01T21:38:08.067+0000",
                            "id": "12593646",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593646",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T21:38:08.067+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "patch6.txt",
                            "created": "2008-05-01T21:46:56.186+0000",
                            "id": "12593648",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593648",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T21:46:56.186+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "this is it",
                            "created": "2008-05-01T21:47:15.270+0000",
                            "id": "12593649",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593649",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T21:47:15.270+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "last patch is just doug's HADOOP-4 and the 2 above changes and removing make clean from boostrap.sh and configure.ac",
                            "created": "2008-05-01T21:48:11.310+0000",
                            "id": "12593650",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593650",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T21:48:11.310+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> avoid the chmod +x problem\n\nI wouldn't worry too much about that.  The patch doesn't remember that it's executable, but subversion will.  But, sure, fixing that is fine too.\n\n> I thought that is all i changed.\n\nDid you 'svn revert -R .' and make sure that 'svn stat' reported nothing before applying my patch and making new mods?",
                            "created": "2008-05-01T21:48:55.551+0000",
                            "id": "12593651",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593651",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-01T21:48:55.551+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "Yes, I think what may have happened is I uploaded an older patch.\n\nThis time I did a revert, applied HADOOP-4 and just edited those files and created the patch.",
                            "created": "2008-05-01T21:51:34.782+0000",
                            "id": "12593652",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593652",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-01T21:51:34.782+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Raghu Angadi",
                                "emailAddress": "rangadi@apache.org",
                                "name": "rangadi",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rangadi"
                            },
                            "body": "This got assigned to by mistake. I haven't followed this jira closely till now.",
                            "created": "2008-05-01T21:55:47.522+0000",
                            "id": "12593653",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593653",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Raghu Angadi",
                                "emailAddress": "rangadi@apache.org",
                                "name": "rangadi",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rangadi"
                            },
                            "updated": "2008-05-01T21:55:47.522+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12381278/patch6.txt\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs -1.  The patch appears to cause Findbugs to fail.\n\n    core tests -1.  The patch failed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2360/testReport/\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2360/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2360/console\n\nThis message is automatically generated.",
                            "created": "2008-05-01T23:00:54.401+0000",
                            "id": "12593668",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593668",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-05-01T23:00:54.401+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "\nHi Doug,\n\nThe following is the compile error that happens when running with Hudson - I don't understand why it's having this problem. Can you look at it? Thanks for your help with this.\n\npete\n\n-------------------\n\n\nBUILD FAILED\n/zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/build.xml:780: The following error occurred while executing this line:\n/zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/src/contrib/build.xml:39: The following error occurred while executing this line:\n/zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/src/contrib/build-contrib.xml:157: /zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/build/contrib/fuse-dfs/classes not found.\n\n",
                            "created": "2008-05-02T03:33:26.711+0000",
                            "id": "12593708",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593708",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-02T03:33:26.711+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I don't understand why it's having this problem.\n\nThe problem is that the \"jar\" and \"package\" targets are failing in fuse-dfs.",
                            "created": "2008-05-02T21:44:41.438+0000",
                            "id": "12593902",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593902",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-02T21:44:41.438+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Somehow you lost my 'if=\"compile.c++\" addition to the compile-libhdfs target in build.xml again.  I re-added that, updated the README, and added \"jar\" and \"package\" targets to make Hudson happier.\n\nThis now builds for me.  I also tested it.  I was able to mount an HDFS filesystem list directories, and read files.",
                            "created": "2008-05-02T21:48:12.663+0000",
                            "id": "12593905",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593905",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-02T21:48:12.663+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12381349/HADOOP-4.patch\nagainst trunk revision 645773.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 13 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests -1.  The patch failed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2372/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2372/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2372/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2372/console\n\nThis message is automatically generated.",
                            "created": "2008-05-03T10:33:50.316+0000",
                            "id": "12593985",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12593985",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-05-03T10:33:50.316+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Comments on the latest patch:\n\n\n *  +1 It compiles for me from ant\n\n * -1 but only after I build libhdfs or alter fuse-dfs/src/Makefile.am to refer to $(HADOOP_HOME)/libhdfs and not $(HADOOP_HOME)/build/libhdfs\n\n * -1fuse_dfs_wrapper.sh : LD_LIBRARY_PATH should be set after JAVA_HOME; LD_LIBRARY_PATH should contain $HADOOP_HOME/libhdfs\n\n * -1 I think that there should be package target in fuse-dfs/build.xml that copies fuse-dfs stuff into $HADOOP_HOME/contrib/fuse-dfs - this to be the final place that fuse-dfs can always be found at in a hadoop installation\n\n * Note: when I run my fuse-dfs mount as root, I have to turn dfs.permissions to off. root doesnt have any permissions in our dfs setup, so hence everything gets permission denied. In future, we should alter libhdfs such that it has a \"super-user API\" - i.e. if I access file X as user Y, am I permitted to access it? See also HADOOP-3264, which deals with supporting permissions in libhdfs\n\n",
                            "created": "2008-05-03T23:18:51.985+0000",
                            "id": "12594038",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594038",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-05-03T23:18:51.985+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Allen Wittenauer",
                                "emailAddress": "awittenauer@linkedin.com",
                                "name": "aw",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=aw"
                            },
                            "body": "a) Rather than use LD_LIBRARY_PATH, would it be better to set a runtime link path that used $ORIGIN?\n\nb) what happens if root is part of the super group?",
                            "created": "2008-05-04T00:42:15.029+0000",
                            "id": "12594047",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594047",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Allen Wittenauer",
                                "emailAddress": "awittenauer@linkedin.com",
                                "name": "aw",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=aw"
                            },
                            "updated": "2008-05-04T00:42:15.029+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "@Allen\n\na) not sure what you mean here. Ideally, I'd like to use fuse_dfs_wrapper.sh in my fstab/automount lines, so it should have all env vars already set, if they can be derived at build or run time.\n\nb) This works fine. Permissions within fuse-dfs are a whole other kettle of fish, so I think I'll keep quiet until fuse-dfs is committed, then start another JIRA. It's just worth noting that if you want to share a fuse-dfs mount between multiple users, then the DFS permissions model will be broken.",
                            "created": "2008-05-04T13:37:24.801+0000",
                            "id": "12594093",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594093",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-05-04T13:37:24.801+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> -1 but only after I build libhdfs \n\nThe confusion is that libhdfs is now conditioned on compile.c++, but fuse-dfs does not, so it's possible to invoke ant at the top level in such a way that it will try to compile fuse-dfs without having compiled libhdfs.  To fix this we should probably make fuse-dfs conditional on compile.c++ too.  In any case, you need to specify compile.c++=1 for top-level builds of fuse-dfs to work.\n\n> -1 I think that there should be package target in fuse-dfs/build.xml that copies fuse-dfs stuff into $HADOOP_HOME/contrib/fuse-dfs\n\nGood idea.   The fuse-dfs package target should copy things to ${dist.dir}/contrib/${name}.\n\nWho will update the patch?\n\n",
                            "created": "2008-05-05T18:10:25.513+0000",
                            "id": "12594292",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594292",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-05T18:10:25.513+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "i added the package target and also made fuse dfs build dependent on both compile.c++ and fusedfs properties.\n\nI also remove aclocal.m4 as that's a generated file.\n",
                            "created": "2008-05-05T23:32:11.328+0000",
                            "id": "12594397",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594397",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-05T23:32:11.328+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "HADOOP-4.patch\n",
                            "created": "2008-05-05T23:34:01.922+0000",
                            "id": "12594398",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594398",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-05T23:34:01.922+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12381459/HADOOP-4.patch\n  against trunk revision 653638.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 13 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    -1 findbugs.  The patch appears to cause Findbugs to fail.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2401/testReport/\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2401/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2401/console\n\nThis message is automatically generated.",
                            "created": "2008-05-06T00:30:48.039+0000",
                            "id": "12594413",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594413",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-05-06T00:30:48.039+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "my bad - added if for the package target.\n",
                            "created": "2008-05-06T00:58:33.403+0000",
                            "id": "12594429",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594429",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-06T00:58:33.403+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Here's a new version that:\n  - includes the README in releases\n  - doesn't overload \"compile.c++\" for libhdfs, but adds a new \"libhdfs\" property, since \"compile.c++\" is used by Hudson on Solaris, and libhdfs doesn't (yet) compile on Solaris.\n  - includes libhdfs & fuse-dfs in releases if libhdfs=1 and fusedfs=1\n",
                            "created": "2008-05-06T23:15:51.567+0000",
                            "id": "12594736",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594736",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-06T23:15:51.567+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12381541/HADOOP-4.patch\n  against trunk revision 653906.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 13 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2415/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2415/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2415/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2415/console\n\nThis message is automatically generated.",
                            "created": "2008-05-07T00:34:43.965+0000",
                            "id": "12594745",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12594745",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-05-07T00:34:43.965+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Any reason for me not to commit this now?",
                            "created": "2008-05-09T21:28:39.941+0000",
                            "id": "12595724",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12595724",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-09T21:28:39.941+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Sorry, will review over the weekend. Thesis writing this week...",
                            "created": "2008-05-09T21:55:01.661+0000",
                            "id": "12595737",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12595737",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-05-09T21:55:01.661+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Minor notes:\n * I had to recompile set ant property -Dlibhdfs=1 to get this to compile - perhaps a warning message would have been desirable if the properties are not set?\n * Concerning the note on compiling libhdfs for 64bit arch:\n{noformat}\nNOTE: for amd64 architecture, libhdfs will not compile unless you edit\nthe Makefile in src/c++/libhdfs/Makefile and set OS_ARCH=amd64\n(probably the same for others too).\n{noformat}\nIn the editing of src/c++/libhdfs/Makefile it is sufficient to just change -m32 to -m64 in the CPPFLAGS and LDFLAGS lines, until HADOOP-3344 is ready.\n\nOtherwise, good to be committed.\n\nC",
                            "created": "2008-05-14T14:32:52.161+0000",
                            "id": "12596774",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12596774",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-05-14T14:32:52.161+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "I made the change to the README that craig suggested.\n",
                            "created": "2008-05-20T21:09:47.008+0000",
                            "id": "12598467",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12598467",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-20T21:09:47.008+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> I made the change to the README that craig suggested. \n\nYes, but it doesn't look like you started with my patch, but rather with an older version...",
                            "created": "2008-05-22T20:23:56.924+0000",
                            "id": "12599173",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12599173",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-22T20:23:56.924+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "body": "yes, it looks like i was thinking the jira attachment #-ing would be chronological. I think how to set the architecture to 64 bit is pretty trivial difference and would be done either way, so i recommend we just commit the latest good patch and then move on from there.\n\n--  pete\n",
                            "created": "2008-05-22T20:32:22.865+0000",
                            "id": "12599177",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12599177",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Pete Wyckoff",
                                "emailAddress": "pwyckoff@facebook.com",
                                "name": "wyckoff",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=wyckoff"
                            },
                            "updated": "2008-05-22T20:32:22.865+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  Thanks, Pete!",
                            "created": "2008-05-29T20:18:36.969+0000",
                            "id": "12600908",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12600908",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-29T20:18:36.969+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "Excellent. Thanks for your good work Pete & Doug. Doug or someone, can you create a contrib/fuse-dfs component to JIRA for any future issues.\n\nCheers :-)",
                            "created": "2008-05-30T19:04:49.062+0000",
                            "id": "12601222",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601222",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-05-30T19:04:49.062+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "done!",
                            "created": "2008-05-30T21:10:42.330+0000",
                            "id": "12601254",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601254",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2008-05-30T21:10:42.330+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Since we have the component, we might as well use it!",
                            "created": "2008-05-30T22:50:15.612+0000",
                            "id": "12601285",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601285",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-30T22:50:15.612+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=10046",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=10046"
                                },
                                "displayName": "Tsz Wo (Nicholas), SZE",
                                "emailAddress": "szetszwo@hortonworks.com",
                                "name": "szetszwo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo"
                            },
                            "body": "Some facebook related stuff found in the patch and got into trunk.  For example, search \"facebook\" in src/contrib/fuse-dfs/configure.ac",
                            "created": "2008-05-30T23:06:35.823+0000",
                            "id": "12601291",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601291",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=10046",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=10046"
                                },
                                "displayName": "Tsz Wo (Nicholas), SZE",
                                "emailAddress": "szetszwo@hortonworks.com",
                                "name": "szetszwo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo"
                            },
                            "updated": "2008-05-30T23:06:35.823+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "> Some facebook related stuff found in the patch and got into trunk.\n\nDo you want to file another issue for this?\n",
                            "created": "2008-05-30T23:12:45.122+0000",
                            "id": "12601297",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601297",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-05-30T23:12:45.122+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=10046",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=10046"
                                },
                                "displayName": "Tsz Wo (Nicholas), SZE",
                                "emailAddress": "szetszwo@hortonworks.com",
                                "name": "szetszwo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo"
                            },
                            "body": "Sure, created HADOOP-3476",
                            "created": "2008-05-30T23:19:05.958+0000",
                            "id": "12601299",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601299",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=10046",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=10046"
                                },
                                "displayName": "Tsz Wo (Nicholas), SZE",
                                "emailAddress": "szetszwo@hortonworks.com",
                                "name": "szetszwo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=szetszwo"
                            },
                            "updated": "2008-05-30T23:19:05.958+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-trunk #509 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/509/])",
                            "created": "2008-06-01T13:49:59.313+0000",
                            "id": "12601473",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12601473",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2008-06-01T13:49:59.313+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "chosuan",
                                "emailAddress": "chosuan@kribb.re.kr",
                                "name": "chosuan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chosuan"
                            },
                            "body": "Fuse-dfs Make Error!!!\n\nHelp me please..\n\nMake Compile Error Message is....\n==================================================================================================\n[root@chosuan2 fuse-dfs]# make\nMaking all in .\nmake[1]: Entering directory `/root/fuse/fuse-dfs'\nmake[1]: Leaving directory `/root/fuse/fuse-dfs'\nMaking all in src\nmake[1]: Entering directory `/root/fuse/fuse-dfs/src'\ngcc  -Wall -O3 -L/hdfs/shared -lhdfs -L/usr/local/lib -lfuse -L/usr/jdk1.6.0_06/jre/lib/amd64/server -ljvm   -o fuse_dfs fuse_dfs.o  \n/usr/bin/ld: skipping incompatible /usr/jdk1.6.0_06/jre/lib/amd64/server/libhdfs.so when searching for -lhdfs\n/usr/bin/ld: cannot find -lhdfs\ncollect2: ld returned 1 exit status\nmake[1]: *** [fuse_dfs] error 1\nmake[1]: Leaving directory `/root/fuse/fuse-dfs/src'\nmake: *** [all-recursive] error 1\n==================================================================================================",
                            "created": "2008-06-11T06:49:58.330+0000",
                            "id": "12604138",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12604138",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "chosuan",
                                "emailAddress": "chosuan@kribb.re.kr",
                                "name": "chosuan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chosuan"
                            },
                            "updated": "2008-06-11T06:50:31.457+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "body": "chousan:\n\nlibhdfs isnt build 64bit by default. You need to rebuild it 64bit, ensuring to remove -m32 from the Makefile.\n\nSee HADOOP-3344 for more details",
                            "created": "2008-06-11T12:37:49.244+0000",
                            "id": "12604203",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12604203",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Craig Macdonald",
                                "emailAddress": "craigm@dcs.gla.ac.uk",
                                "name": "craigm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=craigm"
                            },
                            "updated": "2008-06-11T12:37:49.244+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Robert Chansler",
                                "emailAddress": "rchansler@yahoo.com",
                                "name": "chansler",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chansler"
                            },
                            "body": "Moved the usage info form the release note to the description so that the release notes file can be generated automatically with modest sized notes for each item.\n\nCongratulations for getting this in!",
                            "created": "2008-07-04T00:48:42.524+0000",
                            "id": "12610392",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/12610392",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Robert Chansler",
                                "emailAddress": "rchansler@yahoo.com",
                                "name": "chansler",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chansler"
                            },
                            "updated": "2008-07-04T00:48:42.524+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rita M",
                                "emailAddress": "rmorgan466@gmail.com",
                                "name": "rita",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rita"
                            },
                            "body": "By looking at \r\n\r\nhdfs            -fstype=fuse,rw,nodev,nonempty,noatime,allow_other  :/path/to/fuse_dfs_moutn/fuse_dfs.sh\\#dfs\\://namenode\\:9000\r\n\r\nDoes this still work with a recent version of autofs? Can someone please confirm",
                            "created": "2012-07-19T11:12:58.041+0000",
                            "id": "13418217",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568/comment/13418217",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rita M",
                                "emailAddress": "rmorgan466@gmail.com",
                                "name": "rita",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rita"
                            },
                            "updated": "2012-07-19T11:12:58.041+0000"
                        }
                    ],
                    "maxResults": 134,
                    "startAt": 0,
                    "total": 134
                },
                "components": [],
                "created": "2006-02-05T03:55:29.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": "Introduced FUSE module for HDFS. Module allows mount of HDFS as a Unix filesystem,  and optionally the export of that mount point to other machines. Writes are disabled. rmdir, mv, mkdir, rm are  supported, but not cp, touch, and the like. Usage information is attached to the Jira record.\n\n",
                "customfield_12310220": "2006-08-17 17:35:41.0",
                "customfield_12310222": "3_*:*_4_*:*_16720356_*|*_10002_*:*_13_*:*_10936968981_*|*_1_*:*_11_*:*_62026898664_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_7342307800",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "34.0",
                "customfield_12310320": null,
                "customfield_12310420": "38818",
                "customfield_12310920": "78945",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "This is a FUSE module for Hadoop's HDFS.\n\nIt allows one to mount HDFS as a Unix filesystem and optionally export\nthat mount point to other machines.\n\nrmdir, mv, mkdir, rm are all supported. just not cp, touch, ..., but actual writes require: https://issues.apache.org/jira/browse/HADOOP-3485\n\nFor the most up-to-date documentation, see: http://wiki.apache.org/hadoop/MountableHDFS\n\nBUILDING:\n\n\nRequirements:\n\n   1. a Linux kernel > 2.6.9 or a kernel module from FUSE - i.e., you\n   compile it yourself and then modprobe it. Better off with the\n   former option if possible.  (Note for now if you use the kernel\n   with fuse included, it doesn't allow you to export this through NFS\n   so be warned. See the FUSE email list for more about this.)\n\n   2. FUSE should be installed in /usr/local or FUSE_HOME ant\n   environment variable\n\nTo build:\n\n   1. in HADOOP_HOME: ant compile-contrib -Dcompile.c++=1 -Dfusedfs=1 -Dlibhdfs=1\n\n\nNOTE: for amd64 architecture, libhdfs will not compile unless you edit\nthe Makefile in src/c++/libhdfs/Makefile and set OS_ARCH=amd64\n(probably the same for others too).\n\n--------------------------------------------------------------------------------\n\nCONFIGURING:\n\nLook at all the paths in fuse_dfs_wrapper.sh and either correct them\nor set them in your environment before running. (note for automount\nand mount as root, you probably cannnot control the environment, so\nbest to set them in the wrapper)\n\nINSTALLING:\n\n1. mkdir /mnt/dfs (or wherever you want to mount it)\n\n2. fuse_dfs_wrapper.sh dfs://hadoop_server1.foo.com:9000 /mnt/dfs -d\n; and from another terminal, try ls /mnt/dfs\n\nIf 2 works, try again dropping the debug mode, i.e., -d\n\n(note - common problems are that you don't have libhdfs.so or\nlibjvm.so or libfuse.so on your LD_LIBRARY_PATH, and your CLASSPATH\ndoes not contain hadoop and other required jars.)\n\n--------------------------------------------------------------------------------\n\n\nDEPLOYING:\n\nin a root shell do the following:\n\n1. add the following to /etc/fstab -\n  fuse_dfs#dfs://hadoop_server.foo.com:9000 /mnt/dfs fuse\n  allow_other,rw 0 0\n\n2. mount /mnt/dfs Expect problems with not finding fuse_dfs. You will\n   need to probably add this to /sbin and then problems finding the\n   above 3 libraries. Add these using ldconfig.\n\n--------------------------------------------------------------------------------\n\nEXPORTING:\n\nAdd the following to /etc/exports:\n\n  /mnt/hdfs *.foo.com(no_root_squash,rw,fsid=1,sync)\n\nNOTE - you cannot export this with a FUSE module built into the kernel\n- e.g., kernel 2.6.17. For info on this, refer to the FUSE wiki.\n--------------------------------------------------------------------------------\n\nADVANCED:\n\nyou may want to ensure certain directories cannot be deleted from the\nshell until the FS has permissions. You can set this in the build.xml\nfile in src/contrib/fuse-dfs/build.xml\n\n",
                "duedate": null,
                "environment": "OSs that support FUSE. Includes Linux, MacOSx, OpenSolaris... http://fuse.sourceforge.net/wiki/index.php/OperatingSystems\n",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12312972",
                        "name": "0.18.0",
                        "releaseDate": "2008-08-22",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12312972"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12311790",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A new feature of the product, which has yet to be developed.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png",
                                    "id": "2",
                                    "name": "New Feature",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "tool to mount ndfs on linux"
                            },
                            "id": "12328508",
                            "key": "HADOOP-17",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328508"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12311790",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "John Xing",
                    "emailAddress": "johnx@apache.org",
                    "name": "johnx",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2008-05-29T20:18:37.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "tool to mount dfs on linux",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2012-07-19T11:12:58.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4/votes",
                    "votes": 4
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4/watchers",
                    "watchCount": 11
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328568",
            "key": "HADOOP-4",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "You're right, this is needed to start the jobtracker, which is not tested by current unit tests.  We really need a unit test that uses the jobtracker and tasktracker.  Thanks for catching this, Owen!",
                            "created": "2006-02-07T04:28:13.000+0000",
                            "id": "12365326",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328611/comment/12365326",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T04:28:13.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2006-02-07T03:04:15.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 04:28:13.0",
                "customfield_12310222": "1_*:*_1_*:*_5038000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6659009000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124571",
                "customfield_12310920": "78946",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The hadoop lib directory needs a copy of the commons-logging-api jar file from nutch's lib directory.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T04:28:13.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "need commons-logging-api jar file",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:26.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328611",
            "key": "HADOOP-5",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328611"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  Thanks, Owen!",
                            "created": "2006-02-07T03:34:35.000+0000",
                            "id": "12365310",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328620/comment/12365310",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T03:34:35.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2006-02-07T03:19:03.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 03:34:35.0",
                "customfield_12310222": "1_*:*_1_*:*_932000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6662227000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124572",
                "customfield_12310920": "78947",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "When running a developer build, the hadoop script needs the build directory on the classpath so that the job tracker can find the webapps directory.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T03:34:35.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "missing build directory in classpath",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:26.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328620",
            "key": "HADOOP-6",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328620"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  Say!  Here's a patch that implements the JobTracker rewrite.  Please take a look and let me know what you think....",
                            "created": "2006-01-21T05:42:08.000+0000",
                            "id": "12363456",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363456",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-01-21T05:42:08.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "byron miller",
                                "emailAddress": "byron_miller@compaid.com",
                                "name": "byronm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=byronm"
                            },
                            "body": "As Mr Burns would say \"eggcelent\"  I'll give this a try.  BTW, is it possible to implement functionality that would start jobs that are lagging on nodes that have completed tasks like google does?  for example if your 90% done and the last 10 jobs are hung because of bad hardware, slow response or failure and have the ability to redo the long running jobs in parallel on alternate nodes and complete the first one that finishes?  this way if you have a huge crawl and certain nodes slow or fail those jobs can be alternated on completed nodes to try and wrap up and terminate any dead jobs when done?\n\nhope that makes sense..",
                            "created": "2006-01-21T08:09:08.000+0000",
                            "id": "12363477",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363477",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "byron miller",
                                "emailAddress": "byron_miller@compaid.com",
                                "name": "byronm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=byronm"
                            },
                            "updated": "2006-01-21T08:09:08.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Byron, that's exactly what Mike means by \"speculative execution\".",
                            "created": "2006-01-22T12:37:31.000+0000",
                            "id": "12363554",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363554",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-01-22T12:37:31.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chrismattmann&avatarId=15061",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=chrismattmann&avatarId=15061"
                                },
                                "displayName": "Chris A. Mattmann",
                                "emailAddress": "chris.mattmann@jpl.nasa.gov",
                                "name": "chrismattmann",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chrismattmann"
                            },
                            "body": "Guys,\n\nGreg Barish and the folks who worked on the Theseus planning system for information agents at USC did a lot of work on this subject. Theseus is implemented in java, and as I recall, includes the capability to perform speculative execution...\n\nhttp://www.isi.edu/~barish/",
                            "created": "2006-01-22T13:56:38.000+0000",
                            "id": "12363557",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363557",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chrismattmann&avatarId=15061",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=chrismattmann&avatarId=15061"
                                },
                                "displayName": "Chris A. Mattmann",
                                "emailAddress": "chris.mattmann@jpl.nasa.gov",
                                "name": "chrismattmann",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=chrismattmann"
                            },
                            "updated": "2006-01-22T13:56:38.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "byron miller",
                                "emailAddress": "byron_miller@compaid.com",
                                "name": "byronm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=byronm"
                            },
                            "body": "so thats what they call it :) thanks",
                            "created": "2006-01-22T20:26:15.000+0000",
                            "id": "12363563",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363563",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "byron miller",
                                "emailAddress": "byron_miller@compaid.com",
                                "name": "byronm",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=byronm"
                            },
                            "updated": "2006-01-22T20:26:15.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  One more thing:\n\n  You'll see in this patch that ReduceTasks contain a 2D array of map tasks.  They used to\ncontain a 1D array, one map task for each map-split of the data.\n\n  This 2D business is less than perfect, so let me explain...\n\n  Each Reduce task needs to know when its map task predecessors have completed.\nIn the old days, this was easy.  There was one map id for each split of the data, so for\nk splits, there were k map ids to know about.\n\n  But in a world with speculative execution and early-start of reduce tasks, there could\nbe multiple possible map tasks that work on the same split of data.  So for each of the\nk splits, there could be up to M tasks working on it.  Thus, the reduce task knows about\nk * M map ids.  When any one of the M for each split has completed, the reduce task knows\nit can move on.\n\n   But this is a little silly.  The JobTracker has a \"TaskInProgress\" abstraction that represents\nthe idea of a \"split's worth of work\".  A single TIP contains M map task ids.  Instead of the\nreduce task looking all over for map task ids, it should just deal with TIP ids.  That way,\nwe're back to a 1D array, and the reduce task code is easier to understand.\n\n  Anyway, it will still work as is.  I'll improve the code in a future patch.  For the moment,\nI'll let this patch stand.  I just wanted to let people know...\n",
                            "created": "2006-01-23T13:58:06.000+0000",
                            "id": "12363616",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363616",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-01-23T13:58:06.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Dominik Friedrich",
                                "emailAddress": "dominik@wipe-records.org",
                                "name": "positron",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=positron"
                            },
                            "body": "I tested this patch and jobs seem to run into deadlocks when one node crashes while others are loading map output data from that node. Here some lines tasktracker on node B that tries to copy map data from node A which has crashed:\n\n060124 181752 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 181753 task_r_7jjqag 0.17820947% reduce > copy >\n060124 181753 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 181754 task_r_7jjqag 0.17820947% reduce > copy >\n060124 181754 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 181755 task_r_7jjqag 0.17820947% reduce > copy >\n060124 181755 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 181756 task_r_7jjqag 0.17820947% reduce > copy >\n[...]\n060124 223510 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 223511 task_r_7jjqag 0.17820947% reduce > copy >\n060124 223511 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 223512 task_r_7jjqag 0.17820947% reduce > copy >\n060124 223512 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n060124 223513 task_r_7jjqag 0.17820947% reduce > copy >\n060124 223513 task_r_27r56x 0.2212838% reduce > copy > task_m_1ujusx@nodeA:50040\n\nNode A was removed from the jobtracker's node list but it seems like not all tasks depending on that node have been killed.",
                            "created": "2006-01-25T06:47:33.000+0000",
                            "id": "12363888",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12363888",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Dominik Friedrich",
                                "emailAddress": "dominik@wipe-records.org",
                                "name": "positron",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=positron"
                            },
                            "updated": "2006-01-25T06:47:33.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Mike committed this last week.",
                            "created": "2006-02-07T03:38:43.000+0000",
                            "id": "12365311",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12365311",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T03:38:43.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mikkel Kamstrup Erlandsen",
                                "emailAddress": "mikkel.kamstrup@gmail.com",
                                "name": "kamstrup",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=kamstrup"
                            },
                            "body": "This is likely me being dumb, but I don't think this issue is fixed.\n\nWhen I run any of the provided example programs wordcount/grep (also pi with specualtive excecution enabled) reduce tasks does not start before all map tasks have completed.\n\nMy cluster contains three nodes and I am running Hadoop 0.4.0.",
                            "created": "2006-07-18T11:43:28.000+0000",
                            "id": "12421847",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927/comment/12421847",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mikkel Kamstrup Erlandsen",
                                "emailAddress": "mikkel.kamstrup@gmail.com",
                                "name": "kamstrup",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=kamstrup"
                            },
                            "updated": "2006-07-18T11:43:28.000+0000"
                        }
                    ],
                    "maxResults": 9,
                    "startAt": 0,
                    "total": 9
                },
                "components": [],
                "created": "2006-01-21T05:40:53.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-01-21 08:09:08.0",
                "customfield_12310222": "1_*:*_1_*:*_1461470000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6661980000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124573",
                "customfield_12310920": "78948",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The MapReduce JobTracker is not great at allocating tasks to TaskTracker worker nodes.\n\nHere are the problems:\n1) There is no speculative execution of tasks\n2) Reduce tasks must wait until all map tasks are completed before doing any work\n3) TaskTrackers don't distinguish between Map and Reduce jobs.  Also, the number of\ntasks at a single node is limited to some constant.  That means you can get weird deadlock\nproblems upon machine failure.  The reduces take up all the available execution slots, but they\ndon't do productive work, because they're waiting for a map task to complete.  Of course, that\nmap task won't even be started until the reduce tasks finish, so you can see the problem...\n4) The JobTracker is so complicated that it's hard to fix any of these.\n\n\nThe right solution is a rewrite of the JobTracker to be a lot more flexible in task handling.\nIt has to be a lot simpler.  One way to make it simpler is to add an abstraction I'll call\n\"TaskInProgress\".  Jobs are broken into chunks called TasksInProgress.  All the TaskInProgress\nobjects must be complete, somehow, before the Job is complete.\n\nA single TaskInProgress can be executed by one or more Tasks.  TaskTrackers are assigned Tasks.\nIf a Task fails, we report it back to the JobTracker, where the TaskInProgress lives.  The TIP can then\ndecide whether to launch additional  Tasks or not.\n\nSpeculative execution is handled within the TIP.  It simply launches multiple Tasks in parallel.  The\nTaskTrackers have no idea that these Tasks are actually doing the same chunk of work.  The TIP\nis complete when any one of its Tasks are complete.\n\n",
                "duedate": null,
                "environment": "All",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Mike Cafarella",
                    "emailAddress": "mjc@cloudera.com",
                    "name": "michael_cafarella",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T03:38:43.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "MapReduce has a series of problems concerning task-allocation to worker nodes",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:24.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-7/votes",
                    "votes": 1
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-7/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12327927",
            "key": "HADOOP-7",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327927"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Peter Sandstr\u00f6m",
                                "emailAddress": "sandstrom.p@gmail.com",
                                "name": "sandstrom.p",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=sandstrom.p"
                            },
                            "body": "fixes the problem by connecting to the NameNode and using the address that the local socket is bound to instead of calling getLocalHost(), beware that this makes machineName in the DataNode constructor unused.",
                            "created": "2005-07-24T23:51:00.000+0000",
                            "id": "12316614",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12312573/comment/12316614",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Peter Sandstr\u00f6m",
                                "emailAddress": "sandstrom.p@gmail.com",
                                "name": "sandstrom.p",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=sandstrom.p"
                            },
                            "updated": "2005-07-24T23:51:00.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The problem with this fix is that, if the namenode is down, the socket creation fails and we fail to launch a datanode.  So it would be great to have a better method than InetAddress.getLocalHost(), that tries harder to return the appropriate IP to advertise to the namenode, but that doesn't require the namenode to be up.\n\nPerhaps this could use NetworkInterfaces.getInetAddresses() and find the first that is not a loopback interface?",
                            "created": "2006-02-24T08:00:04.000+0000",
                            "id": "12367595",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12312573/comment/12367595",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-24T08:00:04.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "This is a known JVM bug:\n\nhttp://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4665037\n\nSo let's let Sun fix it, rather than fix it ourselves.  One can workaround it by altering one's linux configuration.",
                            "created": "2006-02-24T08:13:30.000+0000",
                            "id": "12367598",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12312573/comment/12367598",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-24T08:13:30.000+0000"
                        }
                    ],
                    "maxResults": 3,
                    "startAt": 0,
                    "total": 3
                },
                "components": [],
                "created": "2005-07-24T23:46:18.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-24 08:00:04.0",
                "customfield_12310222": "1_*:*_1_*:*_18520032000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_3607316000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124574",
                "customfield_12310920": "78949",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": null,
                "duedate": null,
                "environment": "Linux",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Peter Sandstr\u00f6m",
                    "emailAddress": "sandstrom.p@gmail.com",
                    "name": "sandstrom.p",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=sandstrom.p"
                },
                "resolution": {
                    "description": "The problem described is an issue which will never be fixed.",
                    "id": "2",
                    "name": "Won't Fix",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
                },
                "resolutiondate": "2006-02-24T08:13:30.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "NDFS DataNode advertises localhost as it's address",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:47.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-8/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-8/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12312573",
            "key": "HADOOP-8",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12312573"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Ari Rabkin",
                    "emailAddress": "asrabkin@gmail.com",
                    "name": "asrabkin",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "body": "This is a less pressing issue these days, since you can pass a size to the local dir allocator and it'll do the right thing.\nDo people think this is still worth fixing?   It should be straightforward to do something roulette-y in LocalDirAllocator.getLocalPathForWrite for unknown-size writes.",
                            "created": "2008-07-17T15:39:18.177+0000",
                            "id": "12614398",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12614398",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "updated": "2008-07-17T15:39:18.177+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "body": "Patch fixing this issue.",
                            "created": "2008-07-21T22:53:51.149+0000",
                            "id": "12615455",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12615455",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "updated": "2008-07-21T22:53:51.149+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "body": "downgrading priority",
                            "created": "2008-07-21T22:55:04.747+0000",
                            "id": "12615456",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12615456",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "updated": "2008-07-21T22:55:04.747+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "body": "+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12386584/hadoop9.patch\n  against trunk revision 678593.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2920/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2920/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2920/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2920/console\n\nThis message is automatically generated.",
                            "created": "2008-07-22T03:04:20.388+0000",
                            "id": "12615499",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12615499",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393"
                                },
                                "displayName": "Hadoop QA",
                                "emailAddress": "jira@apache.org",
                                "name": "hadoopqa",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa"
                            },
                            "updated": "2008-07-22T03:04:20.388+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "I just committed this. Thanks, Ari!",
                            "created": "2008-08-12T21:21:12.364+0000",
                            "id": "12621983",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12621983",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2008-08-12T21:21:12.364+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in Hadoop-trunk #581 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/581/])",
                            "created": "2008-08-22T12:34:19.005+0000",
                            "id": "12624768",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12624768",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2008-08-22T12:34:19.005+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pbaclace&avatarId=10630",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pbaclace&avatarId=10630"
                                },
                                "displayName": "Paul Baclace",
                                "emailAddress": "peb.apache@baclace.net",
                                "name": "pbaclace",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=pbaclace"
                            },
                            "body": "You're welcome, Owen!   (I wrote the roulette selection patch.)\r\n",
                            "created": "2010-11-05T03:34:56.324+0000",
                            "id": "12928463",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12928463",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pbaclace&avatarId=10630",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pbaclace&avatarId=10630"
                                },
                                "displayName": "Paul Baclace",
                                "emailAddress": "peb.apache@baclace.net",
                                "name": "pbaclace",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=pbaclace"
                            },
                            "updated": "2010-11-05T03:34:56.324+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "body": "Paul -- I'm confused. Are you sure this is the issue you meant to comment on?  The patch on this Jira wasn't yours. ",
                            "created": "2010-11-05T05:02:58.182+0000",
                            "id": "12928474",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12928474",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Ari Rabkin",
                                "emailAddress": "asrabkin@gmail.com",
                                "name": "asrabkin",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=asrabkin"
                            },
                            "updated": "2010-11-05T05:02:58.182+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pbaclace&avatarId=10630",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pbaclace&avatarId=10630"
                                },
                                "displayName": "Paul Baclace",
                                "emailAddress": "peb.apache@baclace.net",
                                "name": "pbaclace",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=pbaclace"
                            },
                            "body": "Ari,\r\n\r\nThis issue was originally NUTCH-181 before Hadoop was split off.  I wrote a patch Dec. 29 2005 and used it at archive.org Jan-Feb 2006.  Looking at my old notes, I created this issue on Jan. 11 2006, and prepared the patch on Feb. 28 2006, but it was either lost in a Jira transition or the attachment somehow failed.  \r\n\r\nWhen I looked at your patch yesterday, it was similar enough to what I remembered (5 years ago) that I thought it must be a revision of the patch I did.  Today I found my source and 2005-2006 work notes and it is clear that you implemented the change without seeing mine.\r\n\r\nThanks for doing it in same \"roulette-y\" spirit of my lost patch! \r\n",
                            "created": "2010-11-06T05:27:57.066+0000",
                            "id": "12928934",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698/comment/12928934",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pbaclace&avatarId=10630",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pbaclace&avatarId=10630"
                                },
                                "displayName": "Paul Baclace",
                                "emailAddress": "peb.apache@baclace.net",
                                "name": "pbaclace",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=pbaclace"
                            },
                            "updated": "2010-11-06T05:27:57.066+0000"
                        }
                    ],
                    "maxResults": 9,
                    "startAt": 0,
                    "total": 9
                },
                "components": [],
                "created": "2006-01-17T10:09:39.000+0000",
                "customfield_10010": null,
                "customfield_12310191": [
                    {
                        "id": "10343",
                        "self": "https://issues.apache.org/jira/rest/api/2/customFieldOption/10343",
                        "value": "Reviewed"
                    }
                ],
                "customfield_12310192": null,
                "customfield_12310220": "2008-07-17 15:39:18.177",
                "customfield_12310222": "10002_*:*_1_*:*_1895199416_*|*_1_*:*_1_*:*_79188293960_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_8648231688",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124575",
                "customfield_12310920": "78950",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "When mapred.local.dir is used to specify multiple  temp dir. areas, space allocation limited by smallest area because the temp dir. selection algorithm is \"round robin starting from a randomish point\".   When round robin is used with approximately constant sized chunks, the smallest area runs out of space first, and this is a fatal error. \n\nWorkaround: only list local fs dirs in mapred.local.dir with similarly-sized available areas.\n\nI wrote a patch to JobConf (currenly being tested) which uses df to check available space (once a minute or less often) and then uses an efficient roulette selection to do allocation weighted by magnitude of available space. \n\n",
                "duedate": null,
                "environment": "all",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12313211",
                        "name": "0.19.0",
                        "releaseDate": "2008-11-20",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12313211"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pbaclace&avatarId=10630",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pbaclace&avatarId=10630"
                    },
                    "displayName": "Paul Baclace",
                    "emailAddress": "peb.apache@baclace.net",
                    "name": "pbaclace",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=pbaclace"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2008-08-12T21:21:12.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "mapred.local.dir  temp dir. space allocation limited by smallest area",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2010-11-06T05:27:57.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9/watchers",
                    "watchCount": 3
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12327698",
            "key": "HADOOP-9",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327698"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "This has been fixed.  The paramter is now dfs.replication in hadoop-default.xml.",
                            "created": "2006-02-07T04:15:25.000+0000",
                            "id": "12365319",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12317942/comment/12365319",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T04:15:25.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2005-10-14T06:02:45.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 04:15:25.0",
                "customfield_12310222": "1_*:*_1_*:*_10015960000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6659779000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124576",
                "customfield_12310920": "78951",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "ndfs.replication is not documented within the nutch-default.xml configuration file.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.png",
                    "id": "5",
                    "name": "Trivial",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/5"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Rod Taylor",
                    "emailAddress": "rbt@sitesell.com",
                    "name": "rbt",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T04:15:25.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "ndfs.replication is not documented within the nutch-default.xml configuration file.",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:47.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12317942",
            "key": "HADOOP-10",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12317942"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "We've thus far avoided loading job-specific code in the JobTracker and TaskTracker, in order to keep these more reliable.  File splitting is performed by the job tracker.  So if you're overriding InputFormat.getSplits(), then fixing this is harder.  But if you're simply overriding getRecordReader(), then this should be easier to fix.  In that case one could fix this by moving getSplits() to a new interface that's used only by the TaskTracker.  If this is important to you, please submit a patch to this effect.",
                            "created": "2006-02-01T04:14:34.000+0000",
                            "id": "12364678",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268/comment/12364678",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-01T04:14:34.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Wouldn't it be appropriate to make input splitting into a task, so that getSplits could be run by the TaskTrackerChild? That way the current interfaces would remain and the user could override it from the job.jar. \n\nAn example where we would find it useful is where the map input is coming from external servers over sockets. getSplits could return splits of the form FileSplit(\"host:port\", 0 ,1000) and the RecordReader needs to know how to translate that name into a data stream.",
                            "created": "2006-02-01T07:59:33.000+0000",
                            "id": "12364739",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268/comment/12364739",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-01T07:59:33.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "I think the reason to keep getSplits() in the jobtracker, is because the result of getSplits() determines the actual number of map tasks that's run, and the job tracker does more setup and tracking *after* getSplits(). How would you separate that out?",
                            "created": "2006-02-01T08:18:24.000+0000",
                            "id": "12364743",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268/comment/12364743",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-01T08:18:24.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "I would schedule the getSplits task and when it completed, I would schedule the map jobs. It would be pretty parallel to the way the completion of the map tasks causes the reduces to be scheduled. I think the right place to hook it would be in JobTracker.JobInProgress.completedTask(String). One difference that I'm aware of, is that until getSplits returns, you don't have any idea how many maps will be needed, so you can't create the map tasks when the job is created.",
                            "created": "2006-02-01T16:11:46.000+0000",
                            "id": "12364773",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268/comment/12364773",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-01T16:11:46.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I fixed this by having the JobTracker load the InputFormat from the job's jar.",
                            "created": "2006-02-10T08:01:54.000+0000",
                            "id": "12365790",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268/comment/12365790",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-10T08:01:54.000+0000"
                        }
                    ],
                    "maxResults": 5,
                    "startAt": 0,
                    "total": 5
                },
                "components": [],
                "created": "2006-01-31T07:00:17.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-01 04:14:34.0",
                "customfield_12310222": "1_*:*_1_*:*_867698000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6386990000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124577",
                "customfield_12310920": "78952",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "During development, I've been creating/tweaking custom InputFormat implementations. However, when you try to run a job against a running cluster, you get:\n  Exception in thread \"main\" java.io.IOException: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: my.custom.InputFormat\n          at org.apache.nutch.ipc.Client.call(Client.java:294)\n          at org.apache.nutch.ipc.RPC$Invoker.invoke(RPC.java:127)\n          at $Proxy0.submitJob(Unknown Source)\n          at org.apache.nutch.mapred.JobClient.submitJob(JobClient.java:259)\n          at org.apache.nutch.mapred.JobClient.runJob(JobClient.java:288)\n          at com.parc.uir.wikipedia.WikipediaJob.main(WikipediaJob.java:85)\n\nThis error goes away if I restart the TaskTrackers/JobTracker with a classpath which includes the needed code. Other classes (Mapper, Reducer) appear to be available out of the jar file specified in the JobConf, but not the InputFormat. Obviously, it's less than idea to have to restart the JobTracker whenever there's a change to a job-specific class.",
                "duedate": null,
                "environment": "~20 node nutch mapreduce environment, running SVN trunk, on Linux",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12311791",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A problem which impairs or prevents the functions of the product.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                                    "id": "1",
                                    "name": "Bug",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "RPC call times out while indexing map task is computing splits"
                            },
                            "id": "12328376",
                            "key": "HADOOP-16",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12311791",
                        "type": {
                            "id": "10030",
                            "inward": "is related to",
                            "name": "Reference",
                            "outward": "relates to",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Bryan Pendleton",
                    "emailAddress": "bpapache5@geekdom.net",
                    "name": "bpendleton",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-10T08:01:55.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "InputFormat used in job must be in JobTracker classpath (not loaded from job JAR)",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328268",
            "key": "HADOOP-12",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Mike Cafarella",
                    "emailAddress": "mjc@cloudera.com",
                    "name": "michael_cafarella",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "I'm seeing a similar problem with the latest code. I have a task that takes a lot of input files (currently ~1400, each several gigabytes each). The amount of time spent hitting hasTaskWithHit() for each task is exhorbitant, easily causing a timeout. This code does all of the work up front - if you had, say, 1400 tasks, and 2 taskrunners, you could easily dispatch the first 2xsimultaneous running tasks first, then go back and spend time calculating the rest of the matchups. Certainly, a lot of the steps in the job setup after listFiles() could be potentially slow for certain problem sizes.",
                            "created": "2006-02-10T17:19:51.000+0000",
                            "id": "12365857",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12365857",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-10T17:19:51.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Chris Schneider",
                                "emailAddress": "Schmed@TransPac.com",
                                "name": "schmed",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=schmed"
                            },
                            "body": "Everyone should probably be made aware of the strange behavior we see during indexing, at least for a relatively large number of large segments (topN=500K, depth=20) with a relatively large crawldb (50M URLs). Note that this was all performed with ipc.client.timeout set to 30 minutes.\n\nAfter launching the indexing job, the web UI shows all of the TaskTrackers, but the numbers in the \"Secs since heartbeat\" column just keep increasing. This goes on for about 10 minutes until the JobTracker finally loses all of them (and the tasks they were working on), as is shown in its log:\n\n060210 224115 parsing file:/home/crawler/nutch/conf/nutch-site.xml\n060210 225151 Lost tracker 'tracker_37064'\n060210 225151 Task 'task_m_4ftk58' has been lost.\n060210 225151 Task 'task_m_6ww2ri' has been lost.\n\n...(snip)...\n\n060210 225151 Task 'task_r_y6d190' has been lost.\n060210 225151 Lost tracker 'tracker_92921'\n060210 225151 Task 'task_m_9p24at' has been lost.\n\n...(etc)...\n\nAt this point, the web UI is still up, the job shows 0% complete, and the TaskTrackers table is empty. It goes on for an hour or so like this, during which any rational person would probably want to kill the job and start over.\n\nDon't do this! Keep the faith!!!\n\nAbout an hour later, the JobTracker magically reestablishes its connection to the TaskTrackers (which now have new names), as is shown in its log:\n\n060210 225151 Task 'task_r_yj3y3o' has been lost.\n060210 235403 Adding task 'task_m_k9u9a8' to set for tracker 'tracker_85874'\n060210 235404 Adding task 'task_m_pijt4q' to set for tracker 'tracker_61888'\n\n...(etc)...\n\nThe web UI also shows that the TaskTrackers are back (with their new names).\n\nThere's nothing in the TaskTracker logs during the initial 10 minutes, then a bunch of exiting and closing messages, until finally the TaskTrackers start \"Reinitializing local state\":\n\n060210 225403 Stopping server on 50050\n060210 230102 Server handler 4 on 50050: exiting\n\n...(snip)...\n\n060210 230105 Server handler 7 on 50050: exiting\n060210 232024 Server listener on port 50050: exiting\n060210 232403 Stopping server on 50040\n060210 234902 Server listener on port 50040: exiting\n060210 234925 Server connection on port 50040 from 192.168.1.5: exiting\n\n...(snip)...\n\n060210 235009 Server connection on port 50040 from 192.168.1.10: exiting\n060210 235013 Client connection to 192.168.1.4:50040: closing\n060210 235014 Client connection to 192.168.1.7:50040: closing\n060210 235015 Server connection on port 50040 from 192.168.1.7: exiting\n060210 235016 Server handler 0 on 50040: exiting\n\n...(snip)...\n\n060210 235024 Server handler 2 on 50040: exiting\n060210 235403 Reinitializing local state\n060210 235403 Server listener on port 50050: starting\n060210 235403 Server handler 0 on 50050: starting\n\n...(etc)...\n\nDuring the time that the TaskTrackers are lost, neither the master nor the slave machines seem to be using much of the CPU or RAM, and the DataNode logs are quiet. I suppose that it's probably I/O bound on the master machine, but even that seems mysterious to me. It would seem particularly inappropriate for the JobTracker to punt the TaskTrackers because the master was too busy to listen for their heartbeats.\n\nAt any rate, once the TaskTrackers go through the \"Reinitializing local state\" thing, the indexing job seems to proceed normally, and it eventually completes with no errors.\n",
                            "created": "2006-02-12T04:20:17.000+0000",
                            "id": "12366022",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366022",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Chris Schneider",
                                "emailAddress": "Schmed@TransPac.com",
                                "name": "schmed",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=schmed"
                            },
                            "updated": "2006-02-12T04:20:17.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "Looking further into my concern about hasTaskWithCacheHit overhead (called from obtainNewMapTask in JobInProgress).... it looks like obtainNewMapTask actually calls hasTaskWithCacheHit once for each map job, but always chooses the first choice - why even call the relatively expensive hasTaskWithCacheHit if you've already chosen a value for cacheTarget? Likewise, once you've filled in both cacheTarget and hasTarget, why not break out of that for loop entirely?\n\nAm I following the code flow incorrectly, or is obtainNewMapTask essentially making maps^2 RPC calls in response to a single incoming RPC call? Even if the jobtracker and namenode are running on the same host, that could easily explain the sensitivity to timeouts in the current code.\n",
                            "created": "2006-02-13T16:22:46.000+0000",
                            "id": "12366155",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366155",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-13T16:22:46.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Bryan: I agree, this looks like a serious bug.  The TaskTracker should minimize the calls it makes to the NameNode.  Ideally it should only make a single call per job on each input split.",
                            "created": "2006-02-14T04:17:00.000+0000",
                            "id": "12366235",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366235",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-14T04:17:00.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  Here's a patch for the problem.  I changed two things.\n\n  1) The comment is right, there's no need to iterate through all choices in JobTracker\nafter we find a TaskInProgress to take the task.\n\n  2) Within a TaskInProgress (TIP), which tracks an individual split within a Job, we cache\nthe results of the getHints() call to the Distributed File System.\n",
                            "created": "2006-02-14T18:53:04.000+0000",
                            "id": "12366316",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366316",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-02-14T18:53:04.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  Sorry, my blurb above was a little unclear.\n\n  I should have said:\n\n  1)  Bryan's comment is right, we don't need to iterate through the whole\nlist in JobTracker's obtainNewMapTask call.  We now just do it until we\nfind a good cacheTarget or stdTarget value.\n\n  2) A TIP object tracks each individual split in the Job.  We cache\nthe data at each TIP.  This will be handy in case the TIP has to\nbe re-executed due to machine failure.  \n\n  I don't mind caching the hints aggressively, because it's \njust task-placement we're after.  If the hint is wrong (which only happens \nin case of machine failure), we might send the task to a suboptimal \nmachine.  No big deal.\n\n",
                            "created": "2006-02-14T18:59:18.000+0000",
                            "id": "12366317",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366317",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-02-14T18:59:18.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  Patch comitted.",
                            "created": "2006-02-15T04:08:59.000+0000",
                            "id": "12366368",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366368",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-02-15T04:08:59.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "I'm not sure this patch does quite what's desired.\n\nIt looks like before it would try as hard as possible to find a task with a cache hit, then fail to running either just the first executable task. Now, it will search for the first task that's either a cache hit *or* executable..... In principle, wouldn't you only want to break out of the loop for finding a cache hit? This, of course, still causes timeouts - is there any way to actually precompute the list of cache hits, so that it's just a matter of picking a task from a priority queue?",
                            "created": "2006-02-17T03:49:54.000+0000",
                            "id": "12366659",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366659",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-17T03:49:54.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "Of course, given the existing code, maybe it's worth trying a little harder - iterate through the list as before, but keep track of the time that's been taken, and give up if it gets to 1/2 of the RPC timeout, or something of the like.",
                            "created": "2006-02-17T03:50:44.000+0000",
                            "id": "12366660",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366660",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-17T03:50:44.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "But, you're right, Bryan, I think this is still not optimal.  It should certainly check to see if more map tasks have local input data for the calling node before it gives up.  Ideally it should not be iterating through all map tasks either, but rather create a mapping of node -> mapTask* for tasks that have local data for a node.  We could keep a queue of tasks whose entries in this table have not yet been computed.  When we fail to find a task with local data for a node, then we can pop a few (10?) entries off the queue and enter them in the map, and if there are still no matches, just give the node a task with remote input data.  This way we'd avoid ever doing too much work in a single call, and ever iterating over all tasks.",
                            "created": "2006-02-17T05:59:32.000+0000",
                            "id": "12366680",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12366680",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-17T05:59:32.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "I have another idea.\n\nFirst, switch the delegation of responsiblity for job assignment. Right now, it happens in the JobTracker instance, in response to an obtainNewMapTask call. This scales very poorly. In particular, it causes the RPC-timeouts if you do any sort of serious work in obtainNewMapTask. There's another bug, just reported as HADOOP-43, which occurs if you spend too long in a RPC call, and also described in the second comment, above.\n\nSo, instead of having the JobTracker do this reactively, either:\n1) Precompute - probably most scalably done by starting a mini-job, which just computes the list of who has precached data from a given FileSplit.\n2) Compute on demand - as a TaskTracker job. This could work by some protocol of offering the TaskTracker a set of possible jobs it could do work on, letting it pick the ones it thinks are best, and return the remainders for assignment. This, of course, would only work well for instances where tasks >> tasktracker instances.\n\nI looked at implementing something like 1, but decided I think 2 is a much better option. 1 would put a lot more instantaneous demand on the namenode. Plus, once you've finished precomputing the best nodes, if nodes come or go you don't really have a solution. 2 seems to distribute both the work and some of the demand, and it makes it possible for the cluster to grow or shrink dramatically without failing to take advantage of the local storage available at each node. Unfortunately, without any pre-work, it's possible that, doing option 2, you'd pick bad subsets of work to distribute to each node, and get no local I/O improvement at all.\n\nI'd really like to see something done, perferably soon. With dozens of nodes, and hundreds of gbs of data in my current problem set, it's very nearly impossible to get the current code to make progress, without killing tasktrackers (some with lots of work units already completed). I can do some of the coding, if there's agreement for what direction to push.",
                            "created": "2006-02-21T15:01:05.000+0000",
                            "id": "12367148",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12367148",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-21T15:01:05.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I'm re-opening this & assigning it to Mike.\n\nI think we can fix this by changing the TaskTracker to incrementally calculate things, as I alluded above.  The TaskTracker should avoid ever doing anything that might take very long.  RPC timeouts to the TaskTracker are very bad and must be avoided.\n\nWe can maintain a mapping of taskTracker->split, initially empty, and a queue of splits, initially filled with all of the splits.  (If basic split-generation is too expensive, since it calls file-length on each input file,, then we can eventually change the split API into a generator, which incrementally enumerates splits and use that in place of this queue.)  When a request for a task arrives from a tasktracker we can first examine the table.  If any splits are present for the calling tracker, then we return one and remove it from the table.  Otherwise we pop a constant number of splits (10?) off of the queue, enumerate the tasktrackers that host each split by calling the namenode, and add entries to the table.  Then we consult the table again.  In most cases (many more splits than tasktrackers) we should identify suitable splits.  If we fail then we assign a randomly selected, non-local split to the tasktracker.  Make sense?",
                            "created": "2006-02-23T05:26:33.000+0000",
                            "id": "12367400",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12367400",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-23T05:26:33.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Eric Baldeschwieler wrote:\n> [...] why not just dedicate a thread  \n> to planning and then load a complete plan?  That can produce more  \n> optimal placement and a simpler to understand initialization sequence.\n\nA separate thread in the JobTracker?  That could be a good approach.  We'd have a queue of submitted but as-yet unplanned jobs.  The thread can then pop a job off the queue, compute its splits, then start populating a tasktracker->split table.  When tasktrackers poll for work they can consult this table, potentially while the thread is still populating it.\n\nI'm hesitant to move this out of the JobTracker into the TaskTracker, since that introduces complexity.  But a single thread in the JobTracker should be simple to add and should mostly solve this.  +1",
                            "created": "2006-02-23T06:33:39.000+0000",
                            "id": "12367417",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12367417",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-23T06:33:39.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "My only concern is that this doesn't scale as well for really huge jobs, but, if implemented as you suggest (pre-filling, hand out non-matching jobs when you don't have matched jobs) seems like a reasonable trade off. \n\nI'd still think it'd be nice to better handle the case of newly-discovered tasktrackers, but that's probably much more minor than other scaling/responsiveness issues. Maybe a future enhancement for the JobTracker thread that does this work.",
                            "created": "2006-02-23T07:03:31.000+0000",
                            "id": "12367421",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12367421",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-23T07:03:31.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Runping Qi",
                                "emailAddress": "runping.qi@gmail.com",
                                "name": "runping",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=runping"
                            },
                            "body": "Having a separate thread in JobTracker can even pre-compute a data locality map that will enable optimal task assignment to task trackers.\nHere is the basic idea. As the thread computes the splits for a job, it can determine which nodes have local data for each split. The thread can populate \na map mapping a node to a  list of the splits whose data are on the node. When a tasktracker polls for a task, the JobTracker can look up the map by \nthe node name of the task tracker to see whether there are any un-assigned splits in the corresponding list. If yes,  assign one of them to the task tracker. \nOtherwise, randomlly choose a split for the task tracker.   ",
                            "created": "2006-02-24T03:12:06.000+0000",
                            "id": "12367554",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12367554",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Runping Qi",
                                "emailAddress": "runping.qi@gmail.com",
                                "name": "runping",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=runping"
                            },
                            "updated": "2006-02-24T03:12:06.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  I created a separate thread on the JobTracker that handles file-splitting and\ngathering info about split-caches.  The job is placed into the PREP state\nuntil it is processed by this JobTracker thread.  After processing, it moves\ninto the RUNNING state.  \n\n  This should allow the hard split-work to continue but still allow the JobTracker\nto process heartbeats.  For now, the thread lives at the JobTracker but perhaps\nsomeday we'll move it to a TaskTracker thread.\n\n  I also fixed the alg for choosing a task-allocation given a tasktracker.\n(Whether cached, non-cached, or speculative.)\n\n  Let me know if this fixes some of the problems you've been seeing. \n\n",
                            "created": "2006-02-28T08:46:46.000+0000",
                            "id": "12368047",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12368047",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-02-28T08:46:46.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I applied Mike's patch, with a few small changes, fixing an NPE and ArrayOutOfBounds in dfs.\n\nThere's still a bug where, with mapred.tasktracker.tasks.maximum=2, only a single map and a single reduce are running on each node.  I believe the intent is that there should be up to two of each related to a single job, so that the reduce tasks can be copying data while the maps are still running.",
                            "created": "2006-03-03T08:09:22.000+0000",
                            "id": "12368622",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12368622",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-03T08:09:22.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "This is great, and finally fixes my issues with a large job that would never start.\n\nHowever, the way things are in this patch (and the current code), the job doesn't get started until the background thread finishes computing all of the cache hints. This takes far too long - it took 15 minutes on a recent run. During that time, of course, no other work was getting done. How about moving the cachedHints-filling-loop to the end of initTasks(), and go ahead and set the job to RUNNING and \"tasksInited=true\" in the meantime?\n\nDoing this locally lets work commence immediately, while the cache hints continue to get filled in for future task allocations.",
                            "created": "2006-03-08T08:49:48.000+0000",
                            "id": "12369339",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376/comment/12369339",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-03-08T08:49:48.000+0000"
                        }
                    ],
                    "maxResults": 18,
                    "startAt": 0,
                    "total": 18
                },
                "components": [],
                "created": "2006-02-01T08:25:38.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-10 17:19:51.0",
                "customfield_12310222": "1_*:*_1_*:*_1194201000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_2_*:*_3698619000_*|*_4_*:*_1_*:*_700969000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "80542",
                "customfield_12310920": "78953",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "We've been using Nutch 0.8 (MapReduce) to perform some internet crawling. Things seemed to be going well until...\n\n060129 222409 Lost tracker 'tracker_56288'\n060129 222409 Task 'task_m_10gs5f' has been lost.\n060129 222409 Task 'task_m_10qhzr' has been lost.\n   ........\n   ........\n060129 222409 Task 'task_r_zggbwu' has been lost.\n060129 222409 Task 'task_r_zh8dao' has been lost.\n060129 222455 Server handler 8 on 8010 caught: java.net.SocketException: Socket closed\njava.net.SocketException: Socket closed\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:99)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:136)\n        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\n        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)\n        at java.io.DataOutputStream.flush(DataOutputStream.java:106)\n        at org.apache.nutch.ipc.Server$Handler.run(Server.java:216)\n060129 222455 Adding task 'task_m_cia5po' to set for tracker 'tracker_56288'\n060129 223711 Adding task 'task_m_ffv59i' to set for tracker 'tracker_25647'\n\nI'm hoping that someone could explain why task_m_cia5po got added to tracker_56288 after this tracker was lost.\n\nThe Crawl .main process died with the following output:\n\n060129 221129 Indexer: adding segment: /user/crawler/crawl-20060129091444/segments/20060129200246\nException in thread \"main\" java.io.IOException: timed out waiting for response\n    at org.apache.nutch.ipc.Client.call(Client.java:296)\n    at org.apache.nutch.ipc.RPC$Invoker.invoke(RPC.java:127)\n    at $Proxy1.submitJob(Unknown Source)\n    at org.apache.nutch.mapred.JobClient.submitJob(JobClient.java:259)\n    at org.apache.nutch.mapred.JobClient.runJob(JobClient.java:288)\n    at org.apache.nutch.indexer.Indexer.index(Indexer.java:263)\n    at org.apache.nutch.crawl.Crawl.main(Crawl.java:127)\n\nHowever, it definitely seems as if the JobTracker is still waiting for the job to finish (no failed jobs).\n\nDoug Cutting's response:\nThe bug here is that the RPC call times out while the map task is computing splits.  The fix is that the job tracker should not compute splits until after it has returned from the submitJob RPC.  Please submit a bug in Jira to help remind us to fix this.\n",
                "duedate": null,
                "environment": "MapReduce multi-computer crawl environment: 11 machines (1 master with JobTracker/NameNode, 10 slaves with TaskTrackers/DataNodes)",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12311791",
                        "outwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A problem which impairs or prevents the functions of the product.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                                    "id": "1",
                                    "name": "Bug",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                                    "id": "4",
                                    "name": "Minor",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "InputFormat used in job must be in JobTracker classpath (not loaded from job JAR)"
                            },
                            "id": "12328268",
                            "key": "HADOOP-12",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328268"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12311791",
                        "type": {
                            "id": "10030",
                            "inward": "is related to",
                            "name": "Reference",
                            "outward": "relates to",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Chris Schneider",
                    "emailAddress": "Schmed@TransPac.com",
                    "name": "schmed",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=schmed"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-03T08:09:22.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "RPC call times out while indexing map task is computing splits",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-16/votes",
                    "votes": 2
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-16/watchers",
                    "watchCount": 1
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328376",
            "key": "HADOOP-16",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328376"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "John Xing",
                                "emailAddress": "johnx@apache.org",
                                "name": "johnx",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                            },
                            "body": "It works with current nutch-0.8-dev. Will be ported to hadoop after ndfs is moved.",
                            "created": "2006-02-03T16:02:54.000+0000",
                            "id": "12365049",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328508/comment/12365049",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "John Xing",
                                "emailAddress": "johnx@apache.org",
                                "name": "johnx",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                            },
                            "updated": "2006-02-03T16:02:54.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [
                    {
                        "description": "Generic FileSystem code",
                        "id": "12310689",
                        "name": "fs",
                        "self": "https://issues.apache.org/jira/rest/api/2/component/12310689"
                    }
                ],
                "created": "2006-02-03T15:59:31.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": null,
                "customfield_12310222": "1_*:*_1_*:*_303551000_*|*_6_*:*_1_*:*_0",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124578",
                "customfield_12310920": "78968",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "tool to mount ndfs on linux. It depends on fuse and fuse-j.",
                "duedate": null,
                "environment": "linux only",
                "fixVersions": [],
                "issuelinks": [
                    {
                        "id": "12311790",
                        "outwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "An improvement or enhancement to an existing feature or task.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                                    "id": "4",
                                    "name": "Improvement",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "tool to mount dfs on linux"
                            },
                            "id": "12328568",
                            "key": "HADOOP-4",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328568"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12311790",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A new feature of the product, which has yet to be developed.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png",
                    "id": "2",
                    "name": "New Feature",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "John Xing",
                    "emailAddress": "johnx@apache.org",
                    "name": "johnx",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=johnx"
                },
                "resolution": {
                    "description": "The problem is a duplicate of an existing issue.",
                    "id": "3",
                    "name": "Duplicate",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/3"
                },
                "resolutiondate": "2006-02-07T04:18:42.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "tool to mount ndfs on linux",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:25.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-17/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-17/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328508",
            "key": "HADOOP-17",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328508"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "body": "Wish there was an \"edit\" option in JIRA.  Obviously it was within the SegmentReader -- though I don't believe it does anything special to try to read the data file off disk.\n\nI do not and have not seen this exception with a single local directory configuration.",
                            "created": "2006-01-11T02:46:51.000+0000",
                            "id": "12362355",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478/comment/12362355",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "updated": "2006-01-11T02:46:51.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I have sucessfully used mapred.local.dir with multiple values on many occasions.\n\nCan you please try to distill this to an easy to reproduce test-case?  Thanks.",
                            "created": "2006-01-12T03:49:20.000+0000",
                            "id": "12362482",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478/comment/12362482",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-01-12T03:49:20.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "body": "I enabled multiple local directories on 50% of my machines. This error, which does not appear otherwise (we processed a few hundred million pages without error), happens across all machines BUT always on part-##'s which were created on the split directory boxes.\n\nSecondly, the error only occurs during the segread command, org.apache.nutch.segment.SegmentReader, while retrieving the data out of common storage (NAS in our case).\n\n060203 222553 task_m_4x4zan 0.7223333% /opt/sitesell/sbider_data/nutch/segments/segmentset-2006-02-02254/20060202181143-3/content/part-00001/data:0+21025408\n060203 222553 task_m_4x4zan  Problem reading checksum file: java.io.EOFException. Ignoring.\n060203 222553 task_m_4x4zan  Error running child\n060203 222553 task_m_4x4zan java.lang.ArrayIndexOutOfBoundsException\n060203 222553 task_m_4x4zan     at java.util.zip.CRC32.update(CRC32.java:43)\n060203 222553 task_m_4x4zan     at org.apache.nutch.fs.NFSDataInputStream$Checker.read(NFSDataInputStream.java:92)\n060203 222553 task_m_4x4zan     at org.apache.nutch.fs.NFSDataInputStream$PositionCache.read(NFSDataInputStream.java:156)\n060203 222553 task_m_4x4zan     at java.io.BufferedInputStream.read1(BufferedInputStream.java:254)\n060203 222553 task_m_4x4zan     at java.io.BufferedInputStream.read(BufferedInputStream.java:313)\n060203 222553 task_m_4x4zan     at java.io.DataInputStream.readFully(DataInputStream.java:176)\n060203 222553 task_m_4x4zan     at org.apache.nutch.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:55)\n060203 222553 task_m_4x4zan     at org.apache.nutch.io.DataOutputBuffer.write(DataOutputBuffer.java:89)\n060203 222553 task_m_4x4zan     at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:378)\n060203 222553 task_m_4x4zan     at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:301)\n060203 222553 task_m_4x4zan     at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:323)\n060203 222553 task_m_4x4zan     at org.apache.nutch.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:60)\n060203 222553 task_m_4x4zan     at org.apache.nutch.segment.SegmentReader$InputFormat$1.next(SegmentReader.java:80)\n060203 222553 task_m_4x4zan     at org.apache.nutch.mapred.MapTask$2.next(MapTask.java:106)\n060203 222553 task_m_4x4zan     at org.apache.nutch.mapred.MapRunner.run(MapRunner.java:48)\n060203 222553 task_m_4x4zan     at org.apache.nutch.mapred.MapTask.run(MapTask.java:116)\n060203 222553 task_m_4x4zan     at org.apache.nutch.mapred.TaskTracker$Child.main(TaskTracker.java:603)\n\n060203 222557 task_m_4x4zan done; removing files.",
                            "created": "2006-02-04T14:52:26.000+0000",
                            "id": "12365169",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478/comment/12365169",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "updated": "2006-02-04T14:52:26.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "body": "Finally figured it out. One temp directory was filling up (different sizes) and the fetch was aborting BUT I didn't see this in the logs for the longest time.\n\nThe patch in NUTCH-143 helped track down the issue because it caused the error to be noticed be the scripts driving the code in a location close to where the error took place rather than several steps (possibly many hours) later..\n\nPlease close this bug.",
                            "created": "2006-03-04T14:26:40.000+0000",
                            "id": "12368835",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478/comment/12368835",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Rod Taylor",
                                "emailAddress": "rbt@sitesell.com",
                                "name": "rbt",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                            },
                            "updated": "2006-03-04T14:26:40.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Resoving at Rod's request.",
                            "created": "2006-03-07T06:30:32.000+0000",
                            "id": "12369070",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478/comment/12369070",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-07T06:30:32.000+0000"
                        }
                    ],
                    "maxResults": 5,
                    "startAt": 0,
                    "total": 5
                },
                "components": [],
                "created": "2006-01-11T02:45:05.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-01-12 03:49:20.0",
                "customfield_12310222": "1_*:*_1_*:*_4765527000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_24510695000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124579",
                "customfield_12310920": "78969",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "A brief read of the code indicated it may be possible to use multiple local directories using something like the below:\n\n  <property>\n    <name>mapred.local.dir</name>\n    <value>/local,/local1,/local2</value>\n    <description>The local directory where MapReduce stores intermediate\n    data files.\n    </description>\n  </property>\n\nThis failed with the below exception during either the generate or update phase (not entirely sure which).\n\njava.lang.ArrayIndexOutOfBoundsException\n        at java.util.zip.CRC32.update(CRC32.java:51)\n        at org.apache.nutch.fs.NFSDataInputStream$Checker.read(NFSDataInputStream.java:92)\n        at org.apache.nutch.fs.NFSDataInputStream$PositionCache.read(NFSDataInputStream.java:156)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:313)\n        at java.io.DataInputStream.readFully(DataInputStream.java:176)\n        at org.apache.nutch.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:55)\n        at org.apache.nutch.io.DataOutputBuffer.write(DataOutputBuffer.java:89)\n        at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:378)\n        at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:301)\n        at org.apache.nutch.io.SequenceFile$Reader.next(SequenceFile.java:323)\n        at org.apache.nutch.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:60)\n        at org.apache.nutch.segment.SegmentReader$InputFormat$1.next(SegmentReader.java:80)\n        at org.apache.nutch.mapred.MapTask$2.next(MapTask.java:106)\n        at org.apache.nutch.mapred.MapRunner.run(MapRunner.java:48)\n        at org.apache.nutch.mapred.MapTask.run(MapTask.java:116)\n        at org.apache.nutch.mapred.TaskTracker$Child.main(TaskTracker.java:604)",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.png",
                    "id": "2",
                    "name": "Critical",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Rod Taylor",
                    "emailAddress": "rbt@sitesell.com",
                    "name": "rbt",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                },
                "resolution": {
                    "description": "The problem isn't valid and it can't be fixed.",
                    "id": "6",
                    "name": "Invalid",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/6"
                },
                "resolutiondate": "2006-03-07T06:30:32.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Crash with multiple temp directories",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-18/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-18/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12327478",
            "key": "HADOOP-18",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12327478"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Doug Cutting",
                    "emailAddress": "cutting@apache.org",
                    "name": "cutting",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I added a format command to namenode.  Now one must run 'bin/hadoop namenode -format' whenever a new dfs.data.dir is configured.  A misconfigured namenode will thus no longer create a new empty filesystem and then tell all datanodes to discard their blocks.",
                            "created": "2006-03-29T03:15:58.000+0000",
                            "id": "12372133",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12317701/comment/12372133",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-29T03:15:58.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2005-10-07T11:46:42.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-03-29 03:15:58.0",
                "customfield_12310222": "1_*:*_1_*:*_14916558000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_773971000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "80541",
                "customfield_12310920": "78970",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "Our admins accidentally started a second nutch datanode pointing to the same directories as one already running (same machine) which in turn caused the entire contents of the datanode to go disappear.\n\nThis happened because the blocking was based on the username (since fixed in our start scripts) and it was started as two different users.\n\nThe ndfs.name.dir and ndfs.data.dir directories were both completely devoid of content, where they had about 150GB not all that much earlier.\n\n\nI think the solution is improved interlocking within the data directory itself (file locked with flock or something similar).",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12312117",
                        "outwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A problem which impairs or prevents the functions of the product.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                                    "id": "1",
                                    "name": "Bug",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.png",
                                    "id": "2",
                                    "name": "Critical",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "hadoop nameserver does not recognise ndfs nameserver image"
                            },
                            "id": "12329366",
                            "key": "HADOOP-56",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12329366"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12312117",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.png",
                    "id": "2",
                    "name": "Critical",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Rod Taylor",
                    "emailAddress": "rbt@sitesell.com",
                    "name": "rbt",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=rbt"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-29T03:16:00.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Datanode corruption",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:48.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-19/votes",
                    "votes": 1
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-19/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12317701",
            "key": "HADOOP-19",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12317701"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "body": "The svn patch\n",
                            "created": "2006-02-04T09:11:19.000+0000",
                            "id": "12365153",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328556/comment/12365153",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "updated": "2006-02-04T09:11:19.000+0000",
                            "visibility": {
                                "type": "group",
                                "value": "jira-users"
                            }
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Michel,\n\nCan you please re-generate this patch using the new hadoop packages?\n\nAlso, I'd prefer the method be named 'close()' instead of 'finished()'.\n\nFinally, perhaps we should move this into a Closeable interface that is extended by both Mapper and Reducer?\n\nThanks!\n\nDoug",
                            "created": "2006-02-09T06:48:11.000+0000",
                            "id": "12365634",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328556/comment/12365634",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T06:48:11.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "body": "Here is the updated patch:\nright package names and close() instead of finished()\n",
                            "created": "2006-02-09T10:45:50.000+0000",
                            "id": "12365672",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328556/comment/12365672",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "updated": "2006-02-09T10:45:50.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  I changed it so that Mapper and Reducer extend a Closeable interface rather than both providing a close() method directly.",
                            "created": "2006-02-10T02:22:13.000+0000",
                            "id": "12365760",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328556/comment/12365760",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-10T02:22:13.000+0000"
                        }
                    ],
                    "maxResults": 4,
                    "startAt": 0,
                    "total": 4
                },
                "components": [],
                "created": "2006-02-04T09:06:20.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-09 06:48:11.0",
                "customfield_12310222": "1_*:*_1_*:*_494153000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6407372000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "124580",
                "customfield_12310920": "78971",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "Mapper, Reducer need an occasion to do some cleanup after the last record is processed.\nProposal (patch attached)\nin interface Mapper:\n add method void finished();\nin interface Reducer:\n add method void finished();\n\nfinished() methods are called from MapTask, CombiningCollector, ReduceTask.\n------------\nKnown limitation: Fetcher (a multithreaded MapRunnable) does not call finished().\nThis is not currently a problem bec. fetcher Map/Reduce modules do not do anything in finished().\nThe right way to add finished() support to Fetcher would be to wait for all threads to finish, \nthen do:\n     if (collector instanceof CombiningCollector) ((CombiningCollector)collector).finished();\n------------\npatch begins: (svn trunk)\n\nIndex: src/test/org/apache/nutch/mapred/MapredLoadTest.java\n===================================================================\n--- src/test/org/apache/nutch/mapred/MapredLoadTest.java\t(revision 374781)\n+++ src/test/org/apache/nutch/mapred/MapredLoadTest.java\t(working copy)\n@@ -69,6 +69,8 @@\n                 out.collect(new IntWritable(Math.abs(r.nextInt())), new IntWritable(randomVal));\n             }\n         }\n+        public void finished() {\n+        }\n     }\n     static class RandomGenReducer implements Reducer {\n         public void configure(JobConf job) {\n@@ -81,6 +83,8 @@\n                 out.collect(new UTF8(\"\" + val), new UTF8(\"\"));\n             }\n         }\n+        public void finished() {\n+        }\n     }\n     static class RandomCheckMapper implements Mapper {\n         public void configure(JobConf job) {\n@@ -92,6 +96,8 @@\n \n             out.collect(new IntWritable(Integer.parseInt(str.toString().trim())), new IntWritable(1));\n         }\n+        public void finished() {\n+        }\n     }\n     static class RandomCheckReducer implements Reducer {\n         public void configure(JobConf job) {\n@@ -106,6 +112,8 @@\n             }\n             out.collect(new IntWritable(keyint), new IntWritable(count));\n         }\n+        public void finished() {\n+        }\n     }\n \n     int range;\nIndex: src/test/org/apache/nutch/fs/TestNutchFileSystem.java\n===================================================================\n--- src/test/org/apache/nutch/fs/TestNutchFileSystem.java\t(revision 374783)\n+++ src/test/org/apache/nutch/fs/TestNutchFileSystem.java\t(working copy)\n@@ -155,6 +155,8 @@\n \n       reporter.setStatus(\"wrote \" + name);\n     }\n+    \n+    public void finished() {}\n   }\n \n   public static void writeTest(NutchFileSystem fs, boolean fastCheck)\n@@ -247,6 +249,9 @@\n \n       reporter.setStatus(\"read \" + name);\n     }\n+    \n+    public void finished() {}\n+    \n   }\n \n   public static void readTest(NutchFileSystem fs, boolean fastCheck)\n@@ -339,6 +344,9 @@\n         in.close();\n       }\n     }\n+    \n+    public void finished() {}\n+    \n   }\n \n   public static void seekTest(NutchFileSystem fs, boolean fastCheck)\nIndex: src/java/org/apache/nutch/indexer/DeleteDuplicates.java\n===================================================================\n--- src/java/org/apache/nutch/indexer/DeleteDuplicates.java\t(revision 374776)\n+++ src/java/org/apache/nutch/indexer/DeleteDuplicates.java\t(working copy)\n@@ -225,6 +225,7 @@\n         }\n       }\n     }\n+    public void finished() {}\n   }\n     \n   private NutchFileSystem fs;\n@@ -265,6 +266,8 @@\n       reader.close();\n     }\n   }\n+  \n+  public void finished() {}\n \n   /** Write nothing. */\n   public RecordWriter getRecordWriter(final NutchFileSystem fs,\nIndex: src/java/org/apache/nutch/indexer/Indexer.java\n===================================================================\n--- src/java/org/apache/nutch/indexer/Indexer.java\t(revision 374778)\n+++ src/java/org/apache/nutch/indexer/Indexer.java\t(working copy)\n@@ -227,6 +227,8 @@\n \n     output.collect(key, new ObjectWritable(doc));\n   }\n+  \n+  public void finished() {}\n \n   public void index(File indexDir, File crawlDb, File linkDb, File[] segments)\n     throws IOException {\nIndex: src/java/org/apache/nutch/segment/SegmentReader.java\n===================================================================\n--- src/java/org/apache/nutch/segment/SegmentReader.java\t(revision 374778)\n+++ src/java/org/apache/nutch/segment/SegmentReader.java\t(working copy)\n@@ -143,7 +143,9 @@\n     }\n     output.collect(key, new ObjectWritable(dump.toString()));\n   }\n-\n+  \n+  public void finished() {}\n+  \n   public void reader(File segment) throws IOException {\n     LOG.info(\"Reader: segment: \" + segment);\n \nIndex: src/java/org/apache/nutch/mapred/Mapper.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/Mapper.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/Mapper.java\t(working copy)\n@@ -39,4 +39,9 @@\n   void map(WritableComparable key, Writable value,\n            OutputCollector output, Reporter reporter)\n     throws IOException;\n+\n+  /** Called after the last {@link #map} call on this Mapper object.\n+      Typical implementations do nothing.\n+  */\n+  void finished();\n }\nIndex: src/java/org/apache/nutch/mapred/lib/RegexMapper.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/RegexMapper.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/RegexMapper.java\t(working copy)\n@@ -53,4 +53,5 @@\n       output.collect(new UTF8(matcher.group(group)), new LongWritable(1));\n     }\n   }\n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/lib/InverseMapper.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/InverseMapper.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/InverseMapper.java\t(working copy)\n@@ -38,4 +38,6 @@\n     throws IOException {\n     output.collect((WritableComparable)value, key);\n   }\n+\n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/lib/IdentityReducer.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/IdentityReducer.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/IdentityReducer.java\t(working copy)\n@@ -42,4 +42,5 @@\n     }\n   }\n \n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/lib/IdentityMapper.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/IdentityMapper.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/IdentityMapper.java\t(working copy)\n@@ -39,4 +39,5 @@\n     output.collect(key, val);\n   }\n \n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/lib/LongSumReducer.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/LongSumReducer.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/LongSumReducer.java\t(working copy)\n@@ -47,4 +47,6 @@\n     // output sum\n     output.collect(key, new LongWritable(sum));\n   }\n+\n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/lib/TokenCountMapper.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/lib/TokenCountMapper.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/lib/TokenCountMapper.java\t(working copy)\n@@ -50,4 +50,6 @@\n       output.collect(new UTF8(st.nextToken()), new LongWritable(1));\n     }\n   }\n+\n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/mapred/ReduceTask.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/ReduceTask.java\t(revision 374781)\n+++ src/java/org/apache/nutch/mapred/ReduceTask.java\t(working copy)\n@@ -275,6 +275,7 @@\n       }\n \n     } finally {\n+      reducer.finished();\n       in.close();\n       lfs.delete(new File(sortedFile));           // remove sorted\n       out.close(reporter);\nIndex: src/java/org/apache/nutch/mapred/MapTask.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/MapTask.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/MapTask.java\t(working copy)\n@@ -50,7 +50,7 @@\n   public void write(DataOutput out) throws IOException {\n     super.write(out);\n     split.write(out);\n-    \n+\n   }\n   public void readFields(DataInput in) throws IOException {\n     super.readFields(in);\n@@ -126,6 +126,10 @@\n         }\n \n       } finally {\n+        if (combining) {\n+          ((CombiningCollector)collector).finished();\n+        }\n+\n         in.close();                               // close input\n       }\n     } finally {\n@@ -147,5 +151,5 @@\n   public NutchConf getConf() {\n     return this.nutchConf;\n   }\n-  \n+\n }\nIndex: src/java/org/apache/nutch/mapred/MapRunner.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/MapRunner.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/MapRunner.java\t(working copy)\n@@ -38,18 +38,22 @@\n   public void run(RecordReader input, OutputCollector output,\n                   Reporter reporter)\n     throws IOException {\n-    while (true) {\n-      // allocate new key & value instances\n-      WritableComparable key =\n-        (WritableComparable)job.newInstance(inputKeyClass);\n-      Writable value = (Writable)job.newInstance(inputValueClass);\n+    try {\n+      while (true) {\n+        // allocate new key & value instances\n+        WritableComparable key =\n+          (WritableComparable)job.newInstance(inputKeyClass);\n+        Writable value = (Writable)job.newInstance(inputValueClass);\n \n-      // read next key & value\n-      if (!input.next(key, value))\n-        return;\n+        // read next key & value\n+        if (!input.next(key, value))\n+          return;\n \n-      // map pair to output\n-      mapper.map(key, value, output, reporter);\n+        // map pair to output\n+        mapper.map(key, value, output, reporter);\n+      }\n+    } finally {\n+        mapper.finished();\n     }\n   }\n \nIndex: src/java/org/apache/nutch/mapred/CombiningCollector.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/CombiningCollector.java\t(revision 374780)\n+++ src/java/org/apache/nutch/mapred/CombiningCollector.java\t(working copy)\n@@ -78,4 +78,9 @@\n     count = 0;\n   }\n \n+  public synchronized void finished()\n+  {\n+    combiner.finished();\n+  }\n+\n }\nIndex: src/java/org/apache/nutch/mapred/Reducer.java\n===================================================================\n--- src/java/org/apache/nutch/mapred/Reducer.java\t(revision 374737)\n+++ src/java/org/apache/nutch/mapred/Reducer.java\t(working copy)\n@@ -38,4 +38,10 @@\n   void reduce(WritableComparable key, Iterator values,\n               OutputCollector output, Reporter reporter)\n     throws IOException;\n+\n+  /** Called after the last {@link #reduce} call on this Reducer object.\n+      Typical implementations do nothing.\n+  */\n+  void finished();\n+\n }\nIndex: src/java/org/apache/nutch/crawl/CrawlDbReader.java\n===================================================================\n--- src/java/org/apache/nutch/crawl/CrawlDbReader.java\t(revision 374737)\n+++ src/java/org/apache/nutch/crawl/CrawlDbReader.java\t(working copy)\n@@ -50,9 +50,9 @@\n \n /**\n  * Read utility for the CrawlDB.\n- * \n+ *\n  * @author Andrzej Bialecki\n- * \n+ *\n  */\n public class CrawlDbReader {\n \n@@ -68,6 +68,7 @@\n       output.collect(new UTF8(\"retry\"), new LongWritable(cd.getRetriesSinceFetch()));\n       output.collect(new UTF8(\"score\"), new LongWritable((long) (cd.getScore() * 1000.0)));\n     }\n+    public void finished() {}\n   }\n \n   public static class CrawlDbStatReducer implements Reducer {\n@@ -121,6 +122,7 @@\n         output.collect(new UTF8(\"avg score\"), new LongWritable(total / cnt));\n       }\n     }\n+    public void finished() {}\n   }\n \n   public static class CrawlDbDumpReducer implements Reducer {\n@@ -133,8 +135,11 @@\n \n     public void configure(JobConf job) {\n     }\n+\n+    public void finished() {\n+    }\n   }\n-  \n+\n   public void processStatJob(String crawlDb, NutchConf config) throws IOException {\n     LOG.info(\"CrawlDb statistics start: \" + crawlDb);\n     File tmpFolder = new File(crawlDb, \"stat_tmp\" + System.currentTimeMillis());\n@@ -219,7 +224,7 @@\n       System.out.println(\"not found\");\n     }\n   }\n-  \n+\n   public void processDumpJob(String crawlDb, String output, NutchConf config) throws IOException {\n \n     LOG.info(\"CrawlDb dump: starting\");\n@@ -270,4 +275,5 @@\n     }\n     return;\n   }\n+\n }\nIndex: src/java/org/apache/nutch/crawl/LinkDb.java\n===================================================================\n--- src/java/org/apache/nutch/crawl/LinkDb.java\t(revision 374779)\n+++ src/java/org/apache/nutch/crawl/LinkDb.java\t(working copy)\n@@ -118,7 +118,8 @@\n     output.collect(key, result);\n   }\n \n-\n+  public void finished() {}\n+\t\n   public void invert(File linkDb, File segmentsDir) throws IOException {\n     LOG.info(\"LinkDb: starting\");\n     LOG.info(\"LinkDb: linkdb: \" + linkDb);\nIndex: src/java/org/apache/nutch/crawl/Injector.java\n===================================================================\n--- src/java/org/apache/nutch/crawl/Injector.java\t(revision 374779)\n+++ src/java/org/apache/nutch/crawl/Injector.java\t(working copy)\n@@ -65,6 +65,8 @@\n                                              interval));\n       }\n     }\n+    \n+    public void finished() {}\n   }\n \n   /** Combine multiple new entries for a url. */\n@@ -76,6 +78,7 @@\n       throws IOException {\n       output.collect(key, (Writable)values.next()); // just collect first value\n     }\n+    public void finished() {}\n   }\n \n   /** Construct an Injector. */\nIndex: src/java/org/apache/nutch/crawl/Generator.java\n===================================================================\n--- src/java/org/apache/nutch/crawl/Generator.java\t(revision 374779)\n+++ src/java/org/apache/nutch/crawl/Generator.java\t(working copy)\n@@ -63,6 +63,8 @@\n       output.collect(crawlDatum, key);          // invert for sort by score\n     }\n \n+    public void finished() {}\n+    \n     /** Partition by host (value). */\n     public int getPartition(WritableComparable key, Writable value,\n                             int numReduceTasks) {\nIndex: src/java/org/apache/nutch/crawl/CrawlDbReducer.java\n===================================================================\n--- src/java/org/apache/nutch/crawl/CrawlDbReducer.java\t(revision 374781)\n+++ src/java/org/apache/nutch/crawl/CrawlDbReducer.java\t(working copy)\n@@ -115,4 +115,5 @@\n     }\n   }\n \n+  public void finished() {}\n }\nIndex: src/java/org/apache/nutch/parse/ParseSegment.java\n===================================================================\n--- src/java/org/apache/nutch/parse/ParseSegment.java\t(revision 374776)\n+++ src/java/org/apache/nutch/parse/ParseSegment.java\t(working copy)\n@@ -78,6 +78,8 @@\n     throws IOException {\n     output.collect(key, (Writable)values.next()); // collect first value\n   }\n+  \n+  public void finished() {}\n \n   public void parse(File segment) throws IOException {\n     LOG.info(\"Parse: starting\");\n\n\n\n\n\n",
                "duedate": null,
                "environment": "Linux",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Michel Tourn",
                    "emailAddress": "michel_apache@yahoo.com",
                    "name": "michel_tourn",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-10T02:22:13.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Mapper, Reducer need an occasion to cleanup after the last record is processed.",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-20/votes",
                    "votes": 1
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-20/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328556",
            "key": "HADOOP-20",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328556"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "I forgot to change the title line too. This patch fixes both problems.",
                            "created": "2006-02-07T04:20:29.000+0000",
                            "id": "12365322",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328622/comment/12365322",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-07T04:20:29.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I applied the patch.  Thanks, again, Owen.",
                            "created": "2006-02-07T04:40:17.000+0000",
                            "id": "12365331",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328622/comment/12365331",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T04:40:17.000+0000"
                        }
                    ],
                    "maxResults": 2,
                    "startAt": 0,
                    "total": 2
                },
                "components": [],
                "created": "2006-02-07T04:12:05.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 04:40:17.0",
                "customfield_12310222": "1_*:*_1_*:*_1692000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6658289000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "124581",
                "customfield_12310920": "78972",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The webapp files need to be updated so that the reference the new packages. I'll include a patch to fix it.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T04:40:17.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "the webapps need to be updated for the move from nutch",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-21/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-21/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328622",
            "key": "HADOOP-21",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328622"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just applied this.  Thanks, Sami.  Sorry I messed this up the first time...",
                            "created": "2006-02-07T04:50:07.000+0000",
                            "id": "12365333",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328625/comment/12365333",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T04:50:07.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2006-02-07T04:33:17.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 04:50:07.0",
                "customfield_12310222": "1_*:*_1_*:*_1010000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6657699000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124582",
                "customfield_12310920": "78973",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "Following patch will remove unused imports from java source files",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.png",
                    "id": "5",
                    "name": "Trivial",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/5"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=siren&avatarId=11533",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=siren&avatarId=11533"
                    },
                    "displayName": "Sami Siren",
                    "emailAddress": "ssiren@gmail.com",
                    "name": "siren",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=siren"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-07T04:50:07.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "remove unused imports",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:26.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-22/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-22/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328625",
            "key": "HADOOP-22",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328625"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Look closely at the order the config files are loaded.  This code has been in flux, and may have bugs.",
                            "created": "2006-02-07T04:52:00.000+0000",
                            "id": "12365335",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626/comment/12365335",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T04:52:00.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Ok, I found the problem and it was a config file ordering problem.\n\nThe problem is that the job's config file is loaded as a default resource and the site config file is a final resource and I had set the number of reduces to one in the site file, because on a single node cluster that seemed like a reasonable default.\n\nObviously, removing the default in the site file is necessary.\n\nI realize now that is why you created the separate mapred-default.xml. It doesn't feel right to have a config file that is specific for map/reduce, but I think there should be some kind of default config file that the user can override in the job but that is editted by the site.\n\nThings that probably belong there:\n  fs.default.name\n  mapred.job.tracker\n  mapred.map.tasks\n  mapred.reduce.tasks",
                            "created": "2006-02-07T07:51:18.000+0000",
                            "id": "12365359",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626/comment/12365359",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-07T07:51:18.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in flume-trunk #320 (See [https://builds.apache.org/job/flume-trunk/320/])\n    FLUME-1653: Update Hadoop-23 profile to point to hadoop-2 alpha artifacts (Revision 831a86fc5501a8624b184ea65e53749df31692b8)\n\n     Result = SUCCESS",
                            "created": "2012-10-30T03:35:09.313+0000",
                            "id": "13486622",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626/comment/13486622",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2012-10-30T03:35:09.313+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in HBase-0.94-security #176 (See [https://builds.apache.org/job/HBase-0.94-security/176/])\n    HBASE-8743 upgrade hadoop-23 version to 0.23.7 (Revision 1495626)\n\n     Result = SUCCESS",
                            "created": "2013-06-22T00:17:37.303+0000",
                            "id": "13690933",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626/comment/13690933",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-22T00:17:37.303+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "body": "Integrated in HBase-0.94 #1021 (See [https://builds.apache.org/job/HBase-0.94/1021/])\n    HBASE-8743 upgrade hadoop-23 version to 0.23.7 (Revision 1495626)\n\n     Result = SUCCESS",
                            "created": "2013-06-22T00:35:03.547+0000",
                            "id": "13690959",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626/comment/13690959",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Hudson",
                                "emailAddress": "jira@apache.org",
                                "name": "hudson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=hudson"
                            },
                            "updated": "2013-06-22T00:35:03.547+0000"
                        }
                    ],
                    "maxResults": 5,
                    "startAt": 0,
                    "total": 5
                },
                "components": [],
                "created": "2006-02-07T04:45:26.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 04:52:00.0",
                "customfield_12310222": "1_*:*_1_*:*_3055094000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_9073974000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124583",
                "customfield_12310920": "58638",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "Running on a single node cluster (it runs a job tracker and a single task tracker), even though my application asks for 7 reduces, it only gets one. I haven't tracked down what is happening yet.",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "The problem described is an issue which will never be fixed.",
                    "id": "2",
                    "name": "Won't Fix",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
                },
                "resolutiondate": "2006-03-14T13:23:40.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "single node cluster gets one reducer",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2013-06-22T00:35:03.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-23/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-23/watchers",
                    "watchCount": 1
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328626",
            "key": "HADOOP-23",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328626"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Doug Cutting",
                    "emailAddress": "cutting@apache.org",
                    "name": "cutting",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Hi,\n\nI have implemented the configuration interface.\n\nRemarks would be appreciated.\n\nGal.",
                            "created": "2006-05-10T16:00:38.000+0000",
                            "id": "12378857",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12378857",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-10T16:00:38.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Fix previous patch. Forgot to add the actual files :)",
                            "created": "2006-05-10T17:08:03.000+0000",
                            "id": "12378874",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12378874",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-10T17:08:03.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "David Bowen",
                                "emailAddress": "davidlbowen@gmail.com",
                                "name": "dbowen",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=dbowen"
                            },
                            "body": "\nThe code contains getObject and setObject methods.  Is this a good idea - considering that it means that the ConfigurationImpl cannot be written out and read back without losing those values?  I think it would be better to remove these and maintain the ability to serialize and deserialize.  (Is there a reason not to have Configuration extend Writable?)\n\nWhat is a use case for ConfigurationBase.getProperties() which returns an object of unknown type?  It might be better to have something like String[] getPropertyNames(String regex).  (And this should be in Configuration also.)  This allows for things like treating the property name space as a hierarchy, so that e.g. you can find all the properties beginning with some string.\n\n- David\n\n\n",
                            "created": "2006-05-11T03:04:35.000+0000",
                            "id": "12378968",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12378968",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "David Bowen",
                                "emailAddress": "davidlbowen@gmail.com",
                                "name": "dbowen",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=dbowen"
                            },
                            "updated": "2006-05-11T03:04:35.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Andrzej Bialecki ",
                                "emailAddress": "ab@apache.org",
                                "name": "ab",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ab"
                            },
                            "body": "In Nutch in many places we create objects with a \"pseudo-singleton\" semantics (i.e. one per task), that are costly to create. These methods were added to provide a convenient caching mechanism to carry around these objects within the same task. They don't have to be serialized/deserialized.",
                            "created": "2006-05-11T03:25:49.000+0000",
                            "id": "12378972",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12378972",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Andrzej Bialecki ",
                                "emailAddress": "ab@apache.org",
                                "name": "ab",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=ab"
                            },
                            "updated": "2006-05-11T03:25:49.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Since this is my first interaction with Hadoop code \"on a first name basis\" :) I didn't want to rock the boat too much.\n\nMy first goal was to implement the interfaces and the implementation with as little as possible major changes all arround the code. As it is now all test are still working and nothing broken.\n\nSo if the patch would \"pass\" the reviews it would be easier to make additions when all blocks are in place.\n\ngetPropertyNames is good idea to add as an interface to configuration.\n\nThanks.",
                            "created": "2006-05-11T04:44:47.000+0000",
                            "id": "12378979",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12378979",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-11T04:44:47.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Added some missing interfaces",
                            "created": "2006-05-11T17:27:26.000+0000",
                            "id": "12379060",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12379060",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-11T17:27:26.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Last minute changes :(\n\nHad to move getObject setObject to ConfigurationImpl",
                            "created": "2006-05-11T21:29:25.000+0000",
                            "id": "12379076",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12379076",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-11T21:29:25.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I finally had a chance to look closely at this.  One problem I now see is that it's incompatible: code that previously called 'new Configuration()' has to be updated to instead call 'new ConfigurationImpl()'.  Nutch is a good test-case for back-compatibility, since it uses so much of Hadoop's APIs.  Ideally we can figure out a way to do this so that, e.g., the new Hadoop jar can be dropped into existing Nutch and work correctly.\n\nI think this means that the interface cannot be named 'Configuration'.  Instead we should probably call it ConfigurationInterface, and change ConfigurationImpl to be Configuration.  Does that sound like a good solution?\n\nThanks for the patch, and thanks for your patience!",
                            "created": "2006-05-18T06:01:23.000+0000",
                            "id": "12412253",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412253",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-05-18T06:01:23.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "I think that all declarations and parameters should say Configuration that is the interface.\nAnd the constructors should be the only places where ConfigurationImpl\nappears explicitly. E.g. all occurrences\n      private static ConfigurationImpl conf = new ConfigurationImpl();\nshould be replaced by\n      private static Configuration conf = new ConfigurationImpl();\nI haven't seen a lot of nutch code, but if it uses only the API, then\nthat should work. If it does construct config instances then there should be\na static newInstance() somewhere I guess.\n",
                            "created": "2006-05-18T10:12:04.000+0000",
                            "id": "12412285",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412285",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-05-18T10:12:04.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "forgot to set abstract for getConfResource... in ConfigurationBase",
                            "created": "2006-05-18T23:02:34.000+0000",
                            "id": "12412375",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412375",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-18T23:02:34.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Hi,\n\nIn regards to the code compatibility - For Hadoop all new code is already included (tests also) is in this patch.\n\nFor Nutch I already have the patch ready and it is not that big a change since most code uses Configuration (so the actual change is only in construction) so ConfigurationImpl has a copy constructor that accepts a Configuration. I actualy tested it also. I can submit it here as well if we decide to use this patch.\n\nI'm not sure it would be a good idea to change the current design/implementation just for the sake of compatibility. I think the design(Doug's) and the implementation are clean and shall be more understandable to implementers/extenders.\n\n",
                            "created": "2006-05-18T23:22:48.000+0000",
                            "id": "12412376",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412376",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-18T23:22:48.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "API back-compatibility is important.  We'd like folks to be able to upgrade to new releases without having to change their code.  The convention we've had is that, code which compiles against release 0.X without deprecation warnings will still compile against release 0.X+1, but may require changes to compile against release 0.X+2.  Is that reasonable?\n\nIf so, then 'new Configuration()' must still create a usable configuration and not a compilation error in release 0.3.  It may be deprecated, but it should still work.  Yes, this is a pain, since Configuration would be a great name for the interface, but there's code out there (more than just Nutch) that we should try not to break.  Nutch is a good, public test case for this sort of back-compatibility, that's the reason I mention it.\n\nAnother approach might be to use a new package.  We could put the new classes in org.apache.hadoop.config, and then have org.apache.hadoop.conf.Configuration be a deprecated subclass of org.apache.hadoop.config.ConfigurationImpl.  Then, after 0.3 is released, we could remove the entire org.apache.hadoop.conf package.",
                            "created": "2006-05-20T02:25:02.000+0000",
                            "id": "12412580",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412580",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-05-20T02:25:02.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "I totaly agree with you Doug on API back compatibilty.\n\n+1 for org.apache.hadoop.config\n\nSo if Configuration subclasses ConfigurationImpl you would not have to introduce changes in Nutch for now? and you can postpone it to a suitable time?\n\n",
                            "created": "2006-05-20T03:52:39.000+0000",
                            "id": "12412592",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412592",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-20T03:52:39.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Right, we should not add dependencies to Nutch on as-yet-unreleased features in Hadoop.  But we want Nutch users to be able to use the current Hadoop trunk.  So once we've made the next Hadoop release, and upgraded Nutch's trunk to use that release, then we can introduce changes to Nutch.",
                            "created": "2006-05-20T05:13:37.000+0000",
                            "id": "12412598",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412598",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-05-20T05:13:37.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Great, I shall rewrite and submit a new patch for review.",
                            "created": "2006-05-20T06:27:22.000+0000",
                            "id": "12412610",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12412610",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-05-20T06:27:22.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Hi, at last I found some time :(\n\nAttached the patch that changes Configuration into an Interface.\n\nIt passes all tests.\n\nEnjoy.",
                            "created": "2006-10-20T23:48:25.000+0000",
                            "id": "12443973",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12443973",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-10-20T23:48:25.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "a patch that changes Configuration class to interface",
                            "created": "2006-10-20T23:50:23.000+0000",
                            "id": "12443974",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12443974",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-10-20T23:50:23.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "please ignore previous attachment. this is the correct file.",
                            "created": "2006-10-20T23:52:36.000+0000",
                            "id": "12443976",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12443976",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-10-20T23:52:36.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "When I apply this to trunk things don't compile.  I think you forgot to include ConfigurationImpl.java.\n\nI also wonder if, since we're editing all the places where a configuration is constructed, we might change things to use a factory.  So, instead of 'new ConfigurationImpl()' we'd have something like 'ConfigurationFactory.get()'.  That way, we could in the future change the default implementation without changing all of these places again.  E.g., if you're nesting Hadoop in JMX then you might specify a JMX configuration factory as the default.  Does that make sense?\n",
                            "created": "2006-10-24T21:02:35.000+0000",
                            "id": "12444508",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12444508",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-10-24T21:02:35.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "I agree with you Doug. I also took the liberty to make the ConfigurationFactory an interface.\n\nsigned sealed and delivered (without missing classes I hope :-)  )\n\nGal.",
                            "created": "2006-10-26T13:11:53.000+0000",
                            "id": "12444881",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12444881",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-10-26T13:11:53.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Done.... for some reason attaching thw file did not produce an email.",
                            "created": "2006-10-27T19:51:57.000+0000",
                            "id": "12445261",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12445261",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-10-27T19:51:57.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "body": "Any comment???",
                            "created": "2006-11-20T08:22:31.000+0000",
                            "id": "12451250",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12451250",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gal Nitzan",
                                "emailAddress": "gnitzan@usa.net",
                                "name": "gnitzan",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gnitzan"
                            },
                            "updated": "2006-11-20T08:22:31.000+0000"
                        },
                        {
                            "author": {
                                "active": false,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10453",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10453"
                                },
                                "displayName": "steve_l",
                                "name": "steve_l",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=steve_l"
                            },
                            "body": "Looking at this, I'm not sure moving to a formal Interface for Configuration is the right tactic, not if your goal is to allow for different back-ends. Here's why\n\n-there's a lot of code in Configuration which makes config work easier on top of the underling read/write a few types of name-value mappings, replicating this is expensive and creates an ongoing maintenance nightmare. \n\n-JobConf subclasses Configuration, and there are places where code checks for instanceof JobConf and/or a new JobConf gets created. If you really wanted to hand configuration off to something other than XML file datasources, you need to handle JobConf too, which is trickier.\n\nWhich means, right now, you don't want to extend Configuration, you want to extend JobConf, then work out how to sneak in a different factory. \n\nWhat may be easier would be an inner ConfSource interface, which supported the raw get/set operations, possibly typed, possibly simple strings. Then you'd be able to create Configurations bound to different ConfSource back ends. \n\nWhere there are problems here is in error  handling. Currently its Configuration.loadResource() that faults on bad XML, by throwing a simple RuntimeException. If you allow different conf sources, you need to allow for trouble happening later on, when the LDAP or JDBC runtime decides to throw some exception. Either the ConfSource methods are allowed to throw any Exception, or there is a need for a standard ConfigurationRuntimeException to throw/wrap trouble.\n\n\n\n",
                            "created": "2008-04-15T18:20:27.084+0000",
                            "id": "12589175",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12589175",
                            "updateAuthor": {
                                "active": false,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10453",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10453"
                                },
                                "displayName": "steve_l",
                                "name": "steve_l",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=steve_l"
                            },
                            "updated": "2008-04-15T18:20:27.084+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Steve, I agree with your analysis.  This is a very old issue!  Perhaps we should just close it as \"won't fix\" and, if someone needs to integrate Hadoop with a different configuration system, pursue the ConfSource approach?",
                            "created": "2008-04-15T18:30:57.871+0000",
                            "id": "12589182",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12589182",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2008-04-15T18:30:57.871+0000"
                        },
                        {
                            "author": {
                                "active": false,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10453",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10453"
                                },
                                "displayName": "steve_l",
                                "name": "steve_l",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=steve_l"
                            },
                            "body": "I concur; a WONTFIX is a better outcome, with\n\n1. a new improvement 'support multiple configuration back ends' added.\n\n2. a separate issue 'add a specific ConfigurationException that extends RuntimeException to throw for Configuration problems'...that can be added before any back-end improvements, and could also be used to address HADOOP-2081 and any number format exceptions thrown from any HADOOP-2461 -related changes. This is simpler and would seem to be higher priority. Its easier to test, too.",
                            "created": "2008-04-16T13:08:06.544+0000",
                            "id": "12589543",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627/comment/12589543",
                            "updateAuthor": {
                                "active": false,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10453",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10453"
                                },
                                "displayName": "steve_l",
                                "name": "steve_l",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=steve_l"
                            },
                            "updated": "2008-04-16T13:08:06.544+0000"
                        }
                    ],
                    "maxResults": 25,
                    "startAt": 0,
                    "total": 25
                },
                "components": [
                    {
                        "description": "Hadoop configuration mechanism.",
                        "id": "12310711",
                        "name": "conf",
                        "self": "https://issues.apache.org/jira/rest/api/2/component/12310711"
                    }
                ],
                "created": "2006-02-07T05:09:24.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-05-10 16:00:38.0",
                "customfield_12310222": "10002_*:*_1_*:*_335706000_*|*_1_*:*_2_*:*_92415763161_*|*_5_*:*_1_*:*_0",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "8.0",
                "customfield_12310320": null,
                "customfield_12310420": "124584",
                "customfield_12310920": "78974",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The Configuration class should become an interface, e.g.:\n\npublic interface Configuration {\n  String get(String nam);\n  String set(String name, String value);\n\n  int getInt(String name);\n  void setInt(String name, int value);\n  float getFloat(String name);\n  void setFloat(String name, float value);\n  //... other utility methods based on get(String) and set(String,String) ...\n}\n\nAn abstract class named ConfigurationBase should be implemented as follows:\n\npublic abstract class ConfigurationBase implements Configuration {\n  abstract public String get(String nam);\n  abstract public String set(String name, String value);\n\n  public  int getInt(String name) { ... implementation in terms of get(String) ... }\n  public void setInt(String name, int value) {... implementation in terms of set(String, String) ...}\n  public float getFloat(String name)  { ... implementation in terms of get(String) ... }\n  public void setFloat(String name, float value)  {... implementation in terms of set(String, String) ...}\n  //... other utility methods based on get(String) and set(String,String) ...\n}\n\nA concrete, default implementation will be provided as follows:\n\npublic class ConfigurationImpl implements Writable extends ConfigurationBase {\n  private Properties properties;\n\n  // implement abstract methods from ConfigurationBase\n  public String get(String name) { ... implemented in terms of props ...}\n  public String set(String name, String value) { .. implemented in terms of props ... }\n\n  // Writable methods\n  public write(DataOutputStream out);\n  public readFields(DataInputStream in);\n\n  // permit chaining of configurations\n  public Configuration getDefaults();\n  public void setDefaults(Configuration defaults);\n}\n\nOnly code which creates configurations should need to be updated, so this shouldn't be a huge change.",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [
                    {
                        "id": "12320653",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "An improvement or enhancement to an existing feature or task.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                                    "id": "4",
                                    "name": "Improvement",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is open and ready for the assignee to start work on it.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                                    "id": "1",
                                    "name": "Open",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/1"
                                },
                                "summary": "Improve how Hadoop gets configured"
                            },
                            "id": "12398420",
                            "key": "HADOOP-3582",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12398420"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12320653",
                        "type": {
                            "id": "12310010",
                            "inward": "is part of",
                            "name": "Incorporates",
                            "outward": "incorporates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"
                        }
                    }
                ],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Doug Cutting",
                    "emailAddress": "cutting@apache.org",
                    "name": "cutting",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                },
                "resolution": {
                    "description": "The problem described is an issue which will never be fixed.",
                    "id": "2",
                    "name": "Won't Fix",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
                },
                "resolutiondate": "2009-01-15T17:27:13.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "make Configuration an interface",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-04-23T19:24:57.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12312118",
                        "name": "0.7.2",
                        "releaseDate": "2006-10-18",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12312118"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-24/votes",
                    "votes": 1
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-24/watchers",
                    "watchCount": 3
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328627",
            "key": "HADOOP-24",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328627"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "In the patch, it looks like I just deleted Grep instead of moving it to src/examples/.../Grep.java. Please make sure it doesn't disappear.",
                            "created": "2006-02-07T08:26:34.000+0000",
                            "id": "12365363",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365363",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-07T08:26:34.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "A few comments:\n\nI prefer 'ant compile' to do the minimum required for development, so it shouldn't build examples.  Similarly, I prefer 'ant jar' to build only the primary jar.  Examples, test code, javadoc, etc. should be out of the compile-debug loop.\n\nThis should probably go in org.apache.hadoop.examples rather than org.apache.hadoop.mapred.demo, no?\n\nThe mapper is missing a javadoc comment.\n\nThe usage string in the javadoc should probably instead propose something like: bin/hadoop org.apache.hadoop.examples.WordCount, and we should make sure that the examples jar goes on the classpath.\n\nI also wonder whether we should encourage folks to explicitly set the number of map and reduce tasks for each job.  I prefer to think of this as normally a site configuration and/or automatic process.\n\nFinally, since I'm already nitpicking, doesn't the 'try' block in your main() do the same thing as just permitting main() to throw IOException?  The JVM prints a stack trace, no?\n",
                            "created": "2006-02-07T09:02:04.000+0000",
                            "id": "12365365",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365365",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-07T09:02:04.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Ok, how about if I add a target for \"examples\" that builds the examples tar ball. Although compiling the examples is really fast and if they are compiled by default, there is one less thing for the new user tutorial to explain.\n\nThe new package name makes sense.\n\nI guess we can use the hadoop script to set up the classpath, but the users are going to need to figure out the classpath when they write their own applications. I guess we could go one step further and modify the script to take a jar and run the \"main\" class of the jar. So it would look like:\n% bin/hadoop run my-app.jar [args...]\nFor the example jar, we could use a driver that tested the next string for the class to run, so it would look like:\n% bin/hadoop run build/hadoop-examples.jar (wordcount|grep|...) [args...]\nThoughts? \n\nI think that having the application set the number of maps and reduces is better than having it defined by the cluster. Certainly the number of reduces should be set by the user and/or application rather than the cluster since it controls the output fragmentation. But even the optimum number of map instances depends a lot on how resource hungry the map function is.\n\nAnd finally, you are right that letting main throw out the exception is equivalent, but I bet the Java language spec doesn't require that the JVM print the exception that was thrown out of main. I'll change it. (Too much C++ coding where exceptions don't have stacks associated with them by the runtime system.)",
                            "created": "2006-02-07T16:58:36.000+0000",
                            "id": "12365402",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365402",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-07T16:58:36.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I don't feel that strongly in particular about \"ant compile\" compiling the examples.  It's more the principle of keeping that command, the default, minimal.  When the next person comes along and adds something optional that compiles to build.xml I don't want them to also add it to \"ant compile\".\n\nOn the other hand, \"ant test\" should be maximal, compiling and testing as much as possible.  My rule is that \"ant clean test\" should be run before every commit.\n\nI like the idea of making bin/hadoop easily extensible with something like 'bin/hadoop run build/hadoop-examples.jar'.  We could by convention create executable jars whose default main() listed the commands that the jar supports.  We could even change hadoop.jar to be like this, moving the command selection logic out of the shell script and into a Java class.  +1\n\nI really think it would be nice if for common MapReduce operations (e.g., sorting, inverting, etc.) on a well configured cluster one does not have to specify number of map tasks or reduce tasks.  That way one can run something on one cluster with 20 single-processor machines, and then turn and run it on another with 200 dual-processor machines with the system doing a reasonable job.  One should also be able to fine-tune things for a particular cluster if one likes, but that should be optional.  There are cases where the precise number of outputs is critical, but there are (in my experience) many more where the precise number of outputs does not matter.\n\nOne way to sidestep this might be to add a standard  '-D' option to bin/hadoop that permits one to specify any configuration option.  That way one could, e.g., always easily set the number of map or reduce tasks for each job, but also not be forced to.\n\nAnd you're right: a JVM probably isn't required to print that stack, but I'm strongly in favor of things that make code smaller (easier to read, easier to maintain), especially example code.",
                            "created": "2006-02-08T02:20:36.000+0000",
                            "id": "12365449",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365449",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-08T02:20:36.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Ok, here is a new patch.\n\nI added the generic \"jar\" option to bin/hadoop. \nTo get it to work right, I couldn't use the -jar option to java because it ignores the -cp option, so I implemented a utility function that looks in a jar file to find the Main-Class attribute. (org.apache.hadoop.util.PrintJarMainClass)\n\nI moved the examples to org.apache.hadoop.examples.\n\nI created a example driver that you can give either 'wordcount' or 'grep' to run the appropriate class and made it the Main-Class of the example jar file.\n\nI made the map and reduce arguments optional to WordCount. (I thought about using jakarta-common-cli, but it just cluttered up the example.)\n\nI changed the Map class to MapClass so that it didn't conflict with java.utils.Map and put in a javadoc.\n\nI pulled the examples out of the compile and jar targets and added it to the test target.",
                            "created": "2006-02-08T09:43:54.000+0000",
                            "id": "12365502",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365502",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-08T09:43:54.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "I realized that I should probably put the example jar file into the distribution. \n\nI also remove an incorrect javadoc attribute @date. (Why doesn't javadoc have a @date?)",
                            "created": "2006-02-09T02:30:50.000+0000",
                            "id": "12365598",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365598",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-09T02:30:50.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I made a few changes and committed this.  In particular, I:\n  - moved  the package.html to the examples package;\n  - put  the examples javadoc in a separate group, so it's clear it's not part of the core API\n  - put the version in the example jar file name\n  - added Apache licenses to newly contributed files\n",
                            "created": "2006-02-09T04:23:26.000+0000",
                            "id": "12365617",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365617",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T04:23:26.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "When the example tarball was renamed, the package target was broken.",
                            "created": "2006-02-09T04:56:10.000+0000",
                            "id": "12365620",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365620",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-09T04:56:10.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Okay, I think I fixed that.  Thanks!",
                            "created": "2006-02-09T05:44:35.000+0000",
                            "id": "12365626",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365626",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T05:44:35.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "There is one more problem with the example jar with the version, the string of the jar name was being set in the JobConf.\n\nClearly that doesn't work if the version is in the jar filename.\n\nHere is a patch to WordCount that finds the jar file that contains a given class.\n\nIf we want to go this way, it should probably be in hadoop.utils somewhere.\n\nThoughts?",
                            "created": "2006-02-09T10:18:22.000+0000",
                            "id": "12365671",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365671",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-09T10:18:22.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Ah, I missed that.\n\nI like the idea of adding findContainingJar() as a public utility method somewhere.  This could a jobConf method, since it is very relevant to jobs.  Can you imagine other Hadoop uses of this, that would motivate putting it in a class in the util package, or should we just put it on JobConf?\n\nThanks,\n\nDoug",
                            "created": "2006-02-10T01:45:48.000+0000",
                            "id": "12365758",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365758",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-10T01:45:48.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "Until we come up with such a use, I'd go ahead and make it a static method of the JobConf.\n\nI accidently left a println in the findContainingJar method that needs to be removed.",
                            "created": "2006-02-10T01:59:31.000+0000",
                            "id": "12365759",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365759",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-10T01:59:31.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Okay, I did this.  I also added a JobConf constructor that specifies this.",
                            "created": "2006-02-10T03:42:47.000+0000",
                            "id": "12365776",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639/comment/12365776",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-10T03:42:47.000+0000"
                        }
                    ],
                    "maxResults": 13,
                    "startAt": 0,
                    "total": 13
                },
                "components": [],
                "created": "2006-02-07T08:15:24.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-07 09:02:04.0",
                "customfield_12310222": "1_*:*_1_*:*_158882000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6486500000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "5.0",
                "customfield_12310320": null,
                "customfield_12310420": "124585",
                "customfield_12310920": "78975",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The new example is the word count example from Google's paper. I moved the examples into a separate jar file to demonstrate how to run stand-alone application code.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-09T04:23:26.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "a new map/reduce example and moving the examples from src/java to src/examples",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2012-07-24T19:08:08.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-25/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-25/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328639",
            "key": "HADOOP-25",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328639"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Mike Cafarella",
                    "emailAddress": "mjc@cloudera.com",
                    "name": "michael_cafarella",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  OK, the above comment is a little misleading.\n\n  We used to have a difference space-management system in place, which would set\ncertain nodes off-limits if they didn't have enough space.  Now we choose nodes probabilistically,\nwith more weight given to nodes with more space.\n\n  That's probably a little too cute than is necessary.  We should just have hard limits on how\nmuch a given node will take before it complains and never receives further node allocations.",
                            "created": "2006-02-08T03:16:14.000+0000",
                            "id": "12365457",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328675/comment/12365457",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-02-08T03:16:14.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "\n  Patch for this problem.\n",
                            "created": "2006-03-05T09:02:58.000+0000",
                            "id": "12368913",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328675/comment/12368913",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-03-05T09:02:58.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "body": "Tested and fixed, in revision 383247.",
                            "created": "2006-03-05T10:03:58.000+0000",
                            "id": "12368916",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328675/comment/12368916",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Mike Cafarella",
                                "emailAddress": "mjc@cloudera.com",
                                "name": "michael_cafarella",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                            },
                            "updated": "2006-03-05T10:03:58.000+0000"
                        }
                    ],
                    "maxResults": 3,
                    "startAt": 0,
                    "total": 3
                },
                "components": [],
                "created": "2006-02-08T03:05:14.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": null,
                "customfield_12310222": "1_*:*_1_*:*_2185124000_*|*_6_*:*_1_*:*_0",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124586",
                "customfield_12310920": "78976",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "\n  We used to have node-allocation be sensitive to available disk space.  It turned out that\nthis was a little accident-prone and hard to debug on then-available machines, so I removed it.\n\n  DFS is mature enough now that this needs to come back and work properly.  A node with less\nthan X bytes should never accept a new block for allocation.\n",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Mike Cafarella",
                    "emailAddress": "mjc@cloudera.com",
                    "name": "michael_cafarella",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-05T10:03:58.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "DFS node choice doesn't take available space into account effectively",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:48.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-26/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-26/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328675",
            "key": "HADOOP-26",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328675"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "Just to add specifics: since a task processor might've already completed previous tasks - when it runs out of space, it shouldn't be allocated new jobs, but it should stay available for serving map output to reduce jobs that need the completed output. Likewise, once such tasks have been cleared, and more space is available, the task runner should return to available status automatically.",
                            "created": "2006-02-09T04:03:24.000+0000",
                            "id": "12365610",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12365610",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-09T04:03:24.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "body": "I just ran into this problem, but the machine did actually have space available.\nHowever, it was on another disk set in dfs.data.dir. So the first disk is full and the second one\nalmost empty. Would it not make sense to just continue putting the map output to the second disk?",
                            "created": "2006-05-11T19:14:51.000+0000",
                            "id": "12379064",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12379064",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "updated": "2006-05-11T19:14:51.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "body": "To begin with, disregard my last comment, I have no idea what I was thinking :)\n\nCreated this patch to stop a job from losing the map tasks already completed when a task tracker runs out of space.\nInstead, the task tracker will stop accepting new tasks if the space runs below a certain threshold.\nHowever, if for some reason space clears up it will start accepting tasks again.\n\nIf for example a reduce operation previously have been assigned to the task tracker there's a chance it will run out of space anyway. So if the tracker goes below a second threshold it will completely stop accepting new tasks until the job is done and also kill the reduce operation running, or if none is found a map task. It will try to take the one with the least progress.\n\nThe solution might not be ideal, but it's at least better then having the job fail all the time because the task trackers drop off one by one.\n\nSuggestions are of course welcome.\nI've tested this on our tiny cluster and it seems to work fine, just saved me a couple of hours of redundant computation on a big job\n\n/Johan",
                            "created": "2006-06-19T21:52:48.000+0000",
                            "id": "12416774",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12416774",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "updated": "2006-06-19T21:52:48.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "body": "Does anyone have any comments on the patch?\nI guess this issue is beneath the radar since it doesn't have a \"affects version\" added to it.\nIt is very important to me though, since we run a cluster with limited disk space on a few of the nodes.",
                            "created": "2006-06-26T18:01:17.000+0000",
                            "id": "12417779",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12417779",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "updated": "2006-06-26T18:01:17.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "I still think this issue is important. The point of MapReduce is to squeeze as much performance out of what you've got as possible. I regularly have machines with hundreds of gigs of space fail because one of their 4 drives is full. And, yes, the cascading failure problem is the real kicker. It sounds like your patch attacks both of those things - as soon as I have a chance, I'll test it against my current cluster and see how it performs.",
                            "created": "2006-06-27T01:16:57.000+0000",
                            "id": "12417866",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12417866",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-06-27T01:16:57.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I think this is a good change to make, but the patch still has a few issues.\n\nI don't think it is sufficient to check if any device has enough room, but rather, one should check that all devices have enough room.  Local file names are hashed to determine which device to store a file on.  Unless that algorithm changes (Configuration.getLocalPath()), we should make sure that all local devices have a minimum amount of space.\n\nAlso, the indentation and formatting of the patch is non-standard, using tabs instead of spaces, and one chunk of the patch fails to apply cleanly.\n\nThanks!",
                            "created": "2006-06-28T01:49:21.000+0000",
                            "id": "12418085",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12418085",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-06-28T01:49:21.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "body": "Now checks all the local dirs as requested\nAlso, changed from tab -> space",
                            "created": "2006-06-28T03:34:21.000+0000",
                            "id": "12418121",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12418121",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Johan Oskarsson",
                                "emailAddress": "johan.oskarsson@gmail.com",
                                "name": "johanoskarsson",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=johanoskarsson"
                            },
                            "updated": "2006-06-28T03:34:21.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just committed this.  Thanks, Johan.",
                            "created": "2006-06-28T22:27:40.000+0000",
                            "id": "12418262",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12418262",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-06-28T22:27:40.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "p sutter",
                                "emailAddress": "sutter@gmail.com",
                                "name": "psutter",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=psutter"
                            },
                            "body": "\nOne impact of this fix is that an invalid directory name in the temp files list will now prevent a node from running, whereas before that was tolerated.\n\nWe have a couple of nodes in our cluster with 3 drives instead of 4 (they each have a dead drive), and previously we were able to run just fine with one config file on all nodes. \n\n\n\n",
                            "created": "2006-06-30T23:33:54.000+0000",
                            "id": "12418673",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676/comment/12418673",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "p sutter",
                                "emailAddress": "sutter@gmail.com",
                                "name": "psutter",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=psutter"
                            },
                            "updated": "2006-06-30T23:33:54.000+0000"
                        }
                    ],
                    "maxResults": 9,
                    "startAt": 0,
                    "total": 9
                },
                "components": [],
                "created": "2006-02-08T03:07:03.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-09 04:03:24.0",
                "customfield_12310222": "1_*:*_1_*:*_12165637000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_21594000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "124587",
                "customfield_12310920": "78977",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "\n  What it says above.  MapRed TaskTrackers should not offer task service if the local disk\nspace is too constrained.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12311021",
                        "name": "0.4.0",
                        "releaseDate": "2006-06-28",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12311021"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12313255",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "An improvement or enhancement to an existing feature or task.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                                    "id": "4",
                                    "name": "Improvement",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "The task tracker should track disk space used, and have a configurable cap"
                            },
                            "id": "12345273",
                            "key": "HADOOP-336",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12345273"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12313255",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Mike Cafarella",
                    "emailAddress": "mjc@cloudera.com",
                    "name": "michael_cafarella",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michael_cafarella"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-06-28T22:27:40.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "MapRed tries to allocate tasks to nodes that have no available disk space",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-27/votes",
                    "votes": 2
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-27/watchers",
                    "watchCount": 1
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328676",
            "key": "HADOOP-27",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328676"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Ugh.  I like (3).  We should really try to limit public classes to the user API we intend to support long-term.  The only way I can see to achieve this is to compile the jsp's to servlets offline using Ant's jspc task, where you can specify a package.",
                            "created": "2006-02-09T03:02:20.000+0000",
                            "id": "12365602",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328724/comment/12365602",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T03:02:20.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Here's something that will compile the jsp pages as servlets.  More changes are required to configure jetty to use them, but this is a proof of concept.",
                            "created": "2006-02-09T03:22:46.000+0000",
                            "id": "12365608",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328724/comment/12365608",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T03:22:46.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The JSP pages are now pre-compiled to servlets that can access package-private classes.",
                            "created": "2006-02-09T05:39:50.000+0000",
                            "id": "12365625",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328724/comment/12365625",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-09T05:39:50.000+0000"
                        }
                    ],
                    "maxResults": 3,
                    "startAt": 0,
                    "total": 3
                },
                "components": [],
                "created": "2006-02-09T02:41:46.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-09 03:02:20.0",
                "customfield_12310222": "1_*:*_1_*:*_10684000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6481917000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124588",
                "customfield_12310920": "78978",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "Changing the classes to private broke the webapps. \n\nThe required public classes are:\norg.apache.hadoop.mapred.JobInProgress\norg.apache.hadoop.mapred.JobProfile\norg.apache.hadoop.mapred.JobStatus\norg.apache.hadoop.mapred.TaskTrackerStatus\n\nTo fix, we need one of:\n  1. The classes need to be made public again\n  2. The functionality needs to be made available through the classes that are public\n  3. The webapps need to move into the mapred package.",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-09T05:39:50.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "webapps broken",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-28/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-28/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328724",
            "key": "HADOOP-28",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328724"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jerome Charron",
                                "emailAddress": "jerome.charron@gmail.com",
                                "name": "jerome.charron",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jerome.charron"
                            },
                            "body": "The attached patch directly uses the constructor with Configuration parameter if the class to instanciate extends Configurable.\n(Tested with Nutch).",
                            "created": "2006-02-09T22:29:59.000+0000",
                            "id": "12365724",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328760/comment/12365724",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jerome Charron",
                                "emailAddress": "jerome.charron@gmail.com",
                                "name": "jerome.charron",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jerome.charron"
                            },
                            "updated": "2006-02-09T22:29:59.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Wouldn't it be simpler to just add a default constructor to Configured?",
                            "created": "2006-08-31T21:07:47.000+0000",
                            "id": "12431982",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328760/comment/12431982",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-08-31T21:07:47.000+0000"
                        }
                    ],
                    "maxResults": 2,
                    "startAt": 0,
                    "total": 2
                },
                "components": [],
                "created": "2006-02-09T22:28:40.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-08-31 21:07:47.0",
                "customfield_12310222": "1_*:*_1_*:*_92516404205_*|*_5_*:*_1_*:*_0",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124589",
                "customfield_12310920": "78979",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "The Nutch parse command fails, because the ParseSegment class has no default constructor.\nHowever, ParseSegment extends Configured, so it can be directly instanciated with a Configuration parameter.\n",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Jerome Charron",
                    "emailAddress": "jerome.charron@gmail.com",
                    "name": "jerome.charron",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=jerome.charron"
                },
                "resolution": {
                    "description": "The problem described is an issue which will never be fixed.",
                    "id": "2",
                    "name": "Won't Fix",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
                },
                "resolutiondate": "2009-01-15T17:28:44.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "JobConf newInstance() method imposes a default constructor",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:40.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-29/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-29/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328760",
            "key": "HADOOP-29",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328760"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "body": "Example combined usage:\nbin/nutch ndfs -lsr /user/michel/ | cut -f 1 | xargs -i bin/nutch ndfs -cat {}\n\nlists all files/dirs, writes them all to stdout\n\n",
                            "created": "2006-02-10T08:17:14.000+0000",
                            "id": "12365795",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328784/comment/12365795",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Michel Tourn",
                                "emailAddress": "michel_apache@yahoo.com",
                                "name": "michel_tourn",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                            },
                            "updated": "2006-02-10T08:17:14.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just applied this.  Thanks, Michel!",
                            "created": "2006-02-11T02:37:16.000+0000",
                            "id": "12365930",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328784/comment/12365930",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-11T02:37:16.000+0000"
                        }
                    ],
                    "maxResults": 2,
                    "startAt": 0,
                    "total": 2
                },
                "components": [],
                "created": "2006-02-10T08:14:53.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-11 02:37:16.0",
                "customfield_12310222": "1_*:*_1_*:*_66143000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6320071000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124590",
                "customfield_12310920": "78980",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "patch attached",
                "duedate": null,
                "environment": null,
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Michel Tourn",
                    "emailAddress": "michel_apache@yahoo.com",
                    "name": "michel_tourn",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=michel_tourn"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-11T02:37:16.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "DFS shell: support for ls -r and cat",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:27.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-30/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-30/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328784",
            "key": "HADOOP-30",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328784"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "I would argue that rather than creating more framework, you just use the arguments and dispatch on the first argument. If you need something generic you could do something like I did with the ExampleDriver.",
                            "created": "2006-02-10T10:03:05.000+0000",
                            "id": "12365807",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328789/comment/12365807",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-02-10T10:03:05.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "stack",
                                "emailAddress": "stack@duboce.net",
                                "name": "stack",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=stack"
                            },
                            "body": "That will work.  Thanks.\n\n(I'd close this issue but I don't have sufficent permissions).",
                            "created": "2006-02-10T10:14:25.000+0000",
                            "id": "12365810",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328789/comment/12365810",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "stack",
                                "emailAddress": "stack@duboce.net",
                                "name": "stack",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=stack"
                            },
                            "updated": "2006-02-10T10:14:25.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Closing at  reporter's request.",
                            "created": "2006-02-11T01:31:30.000+0000",
                            "id": "12365916",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328789/comment/12365916",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-11T01:31:30.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gordon Mohr",
                                "emailAddress": "gojomoapachesf@xavvy.com",
                                "name": "gojomo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gojomo"
                            },
                            "body": "Perhaps ExampleDriver could itself be renamed/moved to more general 'Launcher' that's documented as a framework convenience class for Hadoop users who have a single-Jar, many main()s usage?",
                            "created": "2006-02-11T03:06:12.000+0000",
                            "id": "12365935",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328789/comment/12365935",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Gordon Mohr",
                                "emailAddress": "gojomoapachesf@xavvy.com",
                                "name": "gojomo",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=gojomo"
                            },
                            "updated": "2006-02-11T03:06:12.000+0000"
                        }
                    ],
                    "maxResults": 4,
                    "startAt": 0,
                    "total": 4
                },
                "components": [],
                "created": "2006-02-10T09:16:53.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-10 10:03:05.0",
                "customfield_12310222": "1_*:*_1_*:*_58477000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_26602238000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124591",
                "customfield_12310920": "78981",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "One use case I forsee is building one jar but using this one jar running multiple jobs: E.g. A single nutch job jar would now be used to do indexing job, later same jar is used to do dedup, etc. Currently, the recently added hadoop 'jar' option just takes the jar name then looks in the jar MANIFEST.MF for the Main-Class, failing if not present. This is grand but for the scenario above, it means I have to create a jar per job I want to run -- each with a different MANIFEST.MF#Main-Class entry. \n\nCan we pass the Main-Class on the hadoop command-line as an (optional) argument to 'hadoop jar JAR_NAME'? (I can make a patch if wanted). ",
                "duedate": null,
                "environment": null,
                "fixVersions": [],
                "issuelinks": [],
                "issuetype": {
                    "description": "A new feature of the product, which has yet to be developed.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png",
                    "id": "2",
                    "name": "New Feature",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "stack",
                    "emailAddress": "stack@duboce.net",
                    "name": "stack",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=stack"
                },
                "resolution": {
                    "description": "The problem described is an issue which will never be fixed.",
                    "id": "2",
                    "name": "Won't Fix",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
                },
                "resolutiondate": "2006-02-11T01:31:30.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Stipulate main class in a job jar when using 'hadoop jar JARNAME'",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-12-15T23:02:08.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-31/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-31/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328789",
            "key": "HADOOP-31",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328789"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                    },
                    "displayName": "Owen O'Malley",
                    "emailAddress": "omalley@apache.org",
                    "name": "owen.omalley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "body": "This was fixed by 0.4.0 by the fix for HADOOP-278.",
                            "created": "2006-07-27T03:13:00.000+0000",
                            "id": "12423759",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328800/comment/12423759",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=16820",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=16820"
                                },
                                "displayName": "Owen O'Malley",
                                "emailAddress": "omalley@apache.org",
                                "name": "owen.omalley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley"
                            },
                            "updated": "2006-07-27T03:13:00.000+0000"
                        }
                    ],
                    "maxResults": 1,
                    "startAt": 0,
                    "total": 1
                },
                "components": [],
                "created": "2006-02-10T16:07:02.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-07-27 03:13:00.0",
                "customfield_12310222": "1_*:*_1_*:*_14382358000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_17000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "0.0",
                "customfield_12310320": null,
                "customfield_12310420": "124592",
                "customfield_12310920": "78982",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "This, in the very least, affects anything using the default listFiles() from InputFormatBase. If no files are enumerated, an exception is thrown... but the JobTracker keeps attempting to run listFiles() for this job. Trying to stop the job with hadoop job -kill job_name just results in timeouts, and further started jobs also don't progress. This happens every single time with, say, \"wordcount\", and a non-existent input path.",
                "duedate": null,
                "environment": "hadoop-trunk, running distributed map reduce",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12311021",
                        "name": "0.4.0",
                        "releaseDate": "2006-06-28",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12311021"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Bryan Pendleton",
                    "emailAddress": "bpapache5@geekdom.net",
                    "name": "bpendleton",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                },
                "resolution": {
                    "description": "The problem is a duplicate of an existing issue.",
                    "id": "3",
                    "name": "Duplicate",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/3"
                },
                "resolutiondate": "2006-07-27T03:13:00.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Creating job with InputDir set to non-existant directory locks up jobtracker",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:51:39.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-32/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-32/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328800",
            "key": "HADOOP-32",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328800"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Konstantin Shvachko",
                    "emailAddress": "shv.hadoop@gmail.com",
                    "name": "shv",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                },
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "DF.patch uses relative file names\nPlease disregard the DFpatch.txt attachment",
                            "created": "2006-02-14T11:58:02.000+0000",
                            "id": "12366290",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12366290",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-02-14T11:58:02.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Fixing things to not call DF twice per heartbeat would be great.  But why do we need the DiskUsage class?  Can't we just keep the DF instance and reuse it?  I don't see the advantage of wrapping the DF inside another class.  It just adds code, and less code is better.  Also, the logic of getRemaining() is duplicated after your patch.\n\nPerhaps what's needed is a private getDF() method in FSDataset, that checks to see if a cached DF instance has been refreshed in the last N milleseconds.  If it has not then it is refreshed.  Then it is returned.  Something like:\n\nprivate synchronized DF getDF() {\n  long now = System.getMillisTime();\n  if ((now - lastDfTime) > DF_INTERVAL) {\n    df = new DF();\n    lastDfTime = now;\n  }\n  return DF();\n}\n\nThen getRemaining() and getCapacity() can be defined in terms of getDF().  Does this make sense?\n\nFinally, Hadoop currently requires Cygwin in a number of places, most notably in the startup scripts.  The current strategy is not to maintain native Windows versions of these, but rather to rely on Cygwin.  This patch increases the code size without removing the dependency on Cygwin.  If you like, we could start another bug to entirely remove the dependency on Cygwin, porting all scripts, DF, etc.  But that is a low-priority item for me, since Cygwin offers a fine solution with no code duplication.\n\nIn summary, I'd love to see a patch that fixes the DF problem with a minimum of code.  Thanks!",
                            "created": "2006-02-24T02:01:18.000+0000",
                            "id": "12367534",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12367534",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-24T02:01:18.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "1. Having the lastDfTime, and updating DF every time DF_INTERVAL passes is definitely a good solution.\nI would go even further and place the DF renew/refresh logic directly into the DF class so that functions\ncalling DF get-methods were free to assume the data is up to date.\nI don't know whether we need that, but DF_INTERVAL can be made a configurable parameter.\nThis will bring in more code, but will make the use of the DF class easier in the end.\nDo we want it?\n\n2. My patch does not remove the dependency on Cygwin. What it does is\nit removes dependency on Cygwin in one particular case without compromising performance for the mainstream OS.\nThe whole file system can run (and actually runs) on windows after that without overheads of cygwin.\nAdditional code is justifiable and inevitable in this case until Sun will implement this functionality for us using native libraries :-).\n\n3. What do you mean by minimizing the code?\nIs it \"the minimum of changes to the existing code that solve the problem\", or is it\nthe minimal amount of total code committed to the repository?\nOr is it minimizing the code required in the future to use the feature?\nThis is actually an interesting topic for discussion......\n",
                            "created": "2006-02-25T11:38:58.000+0000",
                            "id": "12367755",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12367755",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-02-25T11:38:58.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "Yes, DF_INTERVAL should be configurable.\n\nCaching inside DF sounds fine.  We'd then want to add a DF field to FSDataset, so that we always reuse the same instance.\n\nBy minimizing the code I primarily mean minimal total code committed to the repository.  Minimizing the size of patches is also good, since it makes it easier to understand.\n\nI do not see how removing the dependency on cygwin in this one case helps the project: it makes it bigger but adds no functionality and removes no dependencies.  Dependencies are also not bad: we don't want to re-invent things.  Cygwin has already solved this problem (and some others) for us permitting us to focus on Hadoop's more critical issues.",
                            "created": "2006-02-28T03:37:59.000+0000",
                            "id": "12368006",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368006",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-28T03:37:59.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "body": "Konstantin,\n\nThank you for submitting that patch, even though it wasn't accepted I just copied your tryOtherOS method into my code to get rid of that annoying Unix dependency.  I was suprised to see a dependency like that on an operating system command.  Frankly, as a developer and a user, a little extra code is a lot less annoying than several megs of Cygwin and a few hours getting it working (especially since it never worked right).",
                            "created": "2006-02-28T05:45:38.000+0000",
                            "id": "12368021",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368021",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "updated": "2006-02-28T05:45:38.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "So, Tim, I take it you're using Hadoop on XP without Cygwin?  What are you using for startup scripts?",
                            "created": "2006-02-28T05:57:22.000+0000",
                            "id": "12368023",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368023",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-28T05:57:22.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "body": "Doug,\n\nI'm getting there, so far the NameNode and the DataNode are working.  I've just got hacky batch files so far, I don't have the nice shell script system you guys developed.  Here's my batch file for the NameNode:\n\njava -Xmx256m -cp c:\\java\\lib\\hadoop-nightly\\conf;\"c:\\program files\\java\\jdk1.5.0_06\\lib\\tools.jar\";c:\\java\\lib\\hadoop-nightly\\hadoop-nightly.jar;c:\\java\\lib\\hadoop-nightly\\hadoop-nightly-examples.jar;c:\\java\\lib\\hadoop-nightly\\hadoop-nightly-examples.jar;c:\\java\\lib\\hadoop-nightly\\hadoop-nightly.jar;c:\\java\\lib\\hadoop-nightly\\lib\\commons-logging-api-1.0.4.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-5.1.4.jar;c:\\java\\lib\\hadoop-nightly\\lib\\junit-3.8.1.jar;c:\\java\\lib\\hadoop-nightly\\lib\\lucene-core-1.9-rc1-dev.jar;c:\\java\\lib\\hadoop-nightly\\lib\\servlet-api.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-ext\\ant.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-ext\\commons-el.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-ext\\jasper-compiler.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-ext\\jasper-runtime.jar;c:\\java\\lib\\hadoop-nightly\\lib\\jetty-ext\\jsp-api.jar org.apache.hadoop.dfs.NameNode\n\nNow I am just tryng to figure out why JobTracker won't work.  I couldn't get JobTracker working in Cygwin either, so I thought I'd edit the code to give me stack traces and see if I could narrow it down, which led me to try to get it working right in CodeGuide without having to keep going back to Cygwin...",
                            "created": "2006-02-28T06:14:55.000+0000",
                            "id": "12368027",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368027",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "updated": "2006-02-28T06:14:55.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "body": "Oops, I didn't realize lines were not auto-wrapping.  Sorry about that.  And I meant to say I knew my batch file doesn't have relative paths, I was just copying and pasting to get it working.",
                            "created": "2006-02-28T06:16:28.000+0000",
                            "id": "12368028",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368028",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Tim Patton",
                                "emailAddress": "tpatton@dealcatcher.com",
                                "name": "tpatton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=tpatton"
                            },
                            "updated": "2006-02-28T06:16:28.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "This patch (DF2.patch) covers DF caching and reuse of the same instance of DF in FSDataset.\nI removed main() from the DF class, and created class TestDF in the test directory.\nAdditionally, for those who want Windows XP/2003 df functionality without cygwin\nI attach DF.java, which covers that and is ready for adding other OSs, if desired.\nJust replace committed DF.java with the one attached.",
                            "created": "2006-03-02T09:12:36.000+0000",
                            "id": "12368399",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368399",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-03-02T09:12:36.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "Done some code reduction.\nDF3.patch is the latest version now.",
                            "created": "2006-03-03T05:09:58.000+0000",
                            "id": "12368593",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12368593",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-03-03T05:09:58.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "This still needs a few improvements.\n\n- why are all the fields protected?  shouldn't they be private?\n- the test case isn't a junit test.\n- the toString() method now needs to call to doDF().\n- the javadoc now says it uses a windows command, but it doesn't\n\n",
                            "created": "2006-03-16T09:05:50.000+0000",
                            "id": "12370627",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12370627",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-16T09:05:50.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "- The fields are protected rather than private in order to keep the class extensible, if anybody\n  would want to support other OSs, like I did in the attached version of DF.java\n- I would remove this test entirely, don't see any reason to test DF outside the file system.\n- Don't think toString() should call doDF(). We probably want toString to reflect the current\n  state of the class, rather the current state of the disk drive.\n- The Javadoc should say exactly the same it was originally saying, my mistake.",
                            "created": "2006-03-16T10:19:18.000+0000",
                            "id": "12370631",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12370631",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-03-16T10:19:18.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "DF4.path\n\n- made fields private\n- made test junit\n- left toString() unchanged\n- removed WinXp comment\n\nIs there anything else holding us?",
                            "created": "2006-03-17T09:10:25.000+0000",
                            "id": "12370768",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12370768",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-03-17T09:10:25.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "Updating the DF patch. \nThe constructor is now calling df to assign actual values to the members.\nmain() is back instead of the testDF.\nDF.java is also updated to reflect these changes.",
                            "created": "2006-03-25T10:42:35.000+0000",
                            "id": "12371829",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12371829",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-03-25T10:42:35.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "The patch looks great.  I just committed it.  Thanks, Konstantin!",
                            "created": "2006-03-30T07:39:44.000+0000",
                            "id": "12372333",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12372333",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-03-30T07:39:44.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "body": "I'm updating the universal version of DF.java to reflect changes introduced by HADOOP-344.\nDF is hadoop's only dependency on cygwin not counting the scripts.\nIn order to run it on windows XP (without cygwin) you need to replace DF.java with the\nfile attached.\n",
                            "created": "2006-07-25T20:16:53.000+0000",
                            "id": "12423435",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12423435",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Konstantin Shvachko",
                                "emailAddress": "shv.hadoop@gmail.com",
                                "name": "shv",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                            },
                            "updated": "2006-07-25T20:16:53.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jean-Fran\u00e7ois M\u00e9nard",
                                "emailAddress": "jeanfrancoismenard@gmail.com",
                                "name": "jfmenard",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jfmenard"
                            },
                            "body": "The result of 'fsutil' is localised.\n\nOn my french windows XP, the result is:\n\nNombre total d'octets libres             : 23775694848\nNombre total d'octets                    : 143913521152\nNombre total d'octets libres disponibles  : 23775694848\n\nI modified DF.java accordingly for my needs, but if the order of lines is always the same, I guess that parsing the lines sequentially should do the trick.",
                            "created": "2008-01-06T07:56:33.777+0000",
                            "id": "12556354",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841/comment/12556354",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jean-Fran\u00e7ois M\u00e9nard",
                                "emailAddress": "jeanfrancoismenard@gmail.com",
                                "name": "jfmenard",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jfmenard"
                            },
                            "updated": "2008-01-06T07:56:33.777+0000"
                        }
                    ],
                    "maxResults": 17,
                    "startAt": 0,
                    "total": 17
                },
                "components": [
                    {
                        "description": "Generic FileSystem code",
                        "id": "12310689",
                        "name": "fs",
                        "self": "https://issues.apache.org/jira/rest/api/2/component/12310689"
                    }
                ],
                "created": "2006-02-11T07:43:36.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-24 02:01:18.0",
                "customfield_12310222": "1_*:*_1_*:*_4060572000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_671744000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "2.0",
                "customfield_12310320": null,
                "customfield_12310420": "124593",
                "customfield_12310920": "78983",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "1. DF is called twice for each heartbeat, which happens each 3 seconds.\nThere is a simple fix for that in the attached patch.\n\n2. cygwin is required to run df program in windows environment.\nThere is a class org.apache.commons.io.FileSystemUtils, which can return disk free space\nfor different OSs, but it does not have means to get disk capacity.\nIn general in windows there is no efficient and uniform way to calculate disk capacity\nusing a shell command.\nThe choices are 'chkdsk' and 'defrag -a', but both of them are too slow to be called\nevery 3 seconds.\nWinXP and 2003 server have a new tool called fsutil, which provides all necessary info.\nI implemented a call to fsutil in case df fails, and the OS is right.\nOther win versions should still run cygwin.\nI tested this fetaure for linux, winXP and cygwin.\nSee attached patch.",
                "duedate": null,
                "environment": "Unix, Cygwin, Win XP",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12312618",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "An improvement or enhancement to an existing feature or task.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                                    "id": "4",
                                    "name": "Improvement",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                                    "id": "4",
                                    "name": "Minor",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "Cannot start Nutch datanodes on Windows outside of a cygwin environment  because of DF"
                            },
                            "id": "12328076",
                            "key": "NUTCH-187",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328076"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12312618",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/improvement.png",
                    "id": "4",
                    "name": "Improvement",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.png",
                    "id": "4",
                    "name": "Minor",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Konstantin Shvachko",
                    "emailAddress": "shv.hadoop@gmail.com",
                    "name": "shv",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=shv"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-03-30T07:39:48.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "DF enhancement: performance and win XP support",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:48.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-33/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-33/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328841",
            "key": "HADOOP-33",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328841"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jeremy Bensley",
                                "emailAddress": "jbensley.ng@gmail.com",
                                "name": "jbensley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jbensley"
                            },
                            "body": "Proposed patch for issue",
                            "created": "2006-02-14T02:01:49.000+0000",
                            "id": "12366213",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328900/comment/12366213",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Jeremy Bensley",
                                "emailAddress": "jbensley.ng@gmail.com",
                                "name": "jbensley",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=jbensley"
                            },
                            "updated": "2006-02-14T02:01:49.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "body": "I just comitted this.  Thanks!",
                            "created": "2006-02-14T04:03:32.000+0000",
                            "id": "12366233",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328900/comment/12366233",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Doug Cutting",
                                "emailAddress": "cutting@apache.org",
                                "name": "cutting",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=cutting"
                            },
                            "updated": "2006-02-14T04:03:32.000+0000"
                        }
                    ],
                    "maxResults": 2,
                    "startAt": 0,
                    "total": 2
                },
                "components": [],
                "created": "2006-02-14T02:00:26.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-02-14 04:03:32.0",
                "customfield_12310222": "1_*:*_1_*:*_7386000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6055696000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124594",
                "customfield_12310920": "78984",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "In the build.xml file, many paths are defined in terms of the present working directory (PWD) instead of relative to the location of the build.xml. Thus, whenever trying to compile from a directory other than the hadoop root, errors such as this appear:\n\nBUILD FAILED\n/home/jeremy/cvs/hadoop/build.xml:109: org.apache.jasper.JasperException: The -uriroot option must specify a pre-existing directory\n\nI have scripts / vim parameters that connect to other machines for compiling using ssh, and am not necessarily always in the root whenever I compile.\n\nI am attaching a patch which sets all paths relative to ${basedir}, and removes the override of ${basedir} to the PWD. Please let me know if there are reasons why the build environment must be relative to the working directory.",
                "duedate": null,
                "environment": "Fedora Core 4",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.png",
                    "id": "5",
                    "name": "Trivial",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/5"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Jeremy Bensley",
                    "emailAddress": "jbensley.ng@gmail.com",
                    "name": "jbensley",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=jbensley"
                },
                "resolution": {
                    "description": "A fix for this issue is checked into the tree and tested.",
                    "id": "1",
                    "name": "Fixed",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
                },
                "resolutiondate": "2006-02-14T04:03:32.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Build Paths Relative to PWD in build.xml",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2006-08-03T17:46:27.000+0000",
                "versions": [],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-34/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-34/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328900",
            "key": "HADOOP-34",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328900"
        },
        {
            "expand": "editmeta,renderedFields,transitions,changelog,operations",
            "fields": {
                "aggregateprogress": {
                    "progress": 0,
                    "total": 0
                },
                "aggregatetimeestimate": null,
                "aggregatetimeoriginalestimate": null,
                "aggregatetimespent": null,
                "assignee": null,
                "comment": {
                    "comments": [
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "body": "Alright, well, for diagnostic purposes, I added a \"health\" stat to each file in -ls. The getFileHealth() function I define could probably be stuck into a utility class somewhere... especially if it were to be called periodically during a mapreduce run. The patch also refactors how the \"Configuration\" instance is used in the DFSShell.\n\nAlso, I had to add a try/catch around the call to getHints(), because for several of my existing files I get the following stack track when trying to call getHints():\n\nException in thread \"main\" java.io.IOException: java.lang.NullPointerException\n        at org.apache.hadoop.ipc.Client.call(Client.java:301)\n        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:141)\n        at org.apache.hadoop.dfs.$Proxy0.getHints(Unknown Source)\n        at org.apache.hadoop.dfs.DFSClient.getHints(DFSClient.java:69)\n        at org.apache.hadoop.dfs.DistributedFileSystem.getFileCacheHints(DistributedFileSystem.java:63)\n        at org.apache.hadoop.dfs.DFSShell.getFileHealth(DFSShell.java:43)\n        at org.apache.hadoop.dfs.DFSShell.ls(DFSShell.java:117)\n        at org.apache.hadoop.dfs.DFSShell.main(DFSShell.java:283)",
                            "created": "2006-02-14T08:26:35.000+0000",
                            "id": "12366260",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328902/comment/12366260",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Bryan Pendleton",
                                "emailAddress": "bpapache5@geekdom.net",
                                "name": "bpendleton",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                            },
                            "updated": "2006-02-14T08:26:35.000+0000"
                        },
                        {
                            "author": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Sameer Paranjpye",
                                "emailAddress": "sparanjpye@yahoo.com",
                                "name": "sameerp",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=sameerp"
                            },
                            "body": "Duplicate of HADOOP-83",
                            "created": "2006-03-25T05:33:23.000+0000",
                            "id": "12371803",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328902/comment/12371803",
                            "updateAuthor": {
                                "active": true,
                                "avatarUrls": {
                                    "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                                    "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                                },
                                "displayName": "Sameer Paranjpye",
                                "emailAddress": "sparanjpye@yahoo.com",
                                "name": "sameerp",
                                "self": "https://issues.apache.org/jira/rest/api/2/user?username=sameerp"
                            },
                            "updated": "2006-03-25T05:33:23.000+0000"
                        }
                    ],
                    "maxResults": 2,
                    "startAt": 0,
                    "total": 2
                },
                "components": [],
                "created": "2006-02-14T03:30:18.000+0000",
                "customfield_10010": null,
                "customfield_12310191": null,
                "customfield_12310192": null,
                "customfield_12310220": "2006-03-25 05:33:23.0",
                "customfield_12310222": "1_*:*_1_*:*_3376986000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_1111330000",
                "customfield_12310230": null,
                "customfield_12310290": null,
                "customfield_12310291": null,
                "customfield_12310300": null,
                "customfield_12310310": "1.0",
                "customfield_12310320": null,
                "customfield_12310420": "124595",
                "customfield_12310920": "78985",
                "customfield_12310921": null,
                "customfield_12311120": null,
                "customfield_12311421": null,
                "description": "I've now several times run into a problem where a large run gets stalled as a result of a missing data block. The latest was a stall in the Summer - ie, the data might've all been there, but it was impossible to proceed because the CRC file was missing a block. It would be nice to:\n\n1) Have a \"health check\" running on a map reduce. If any data isn't available, emmit periodic warnings, and maybe have a timeout for if the data never comes back. Such warnings *should* specify which file(s) are affected by the missing blocks.\n2) Have a utility, possible part of the existing dfs utility, which can check for dfs files with unlocatable blocks. Possibly, even show a 'health' of a file - ie, what percentage of its blocks are currently at the desired replication level. Currently, there's no way that I know of to find out if a file in DFS is going to be unreadable.",
                "duedate": null,
                "environment": "~20 datanode DFS cluster",
                "fixVersions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "issuelinks": [
                    {
                        "id": "12312116",
                        "inwardIssue": {
                            "fields": {
                                "issuetype": {
                                    "description": "A problem which impairs or prevents the functions of the product.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                                    "id": "1",
                                    "name": "Bug",
                                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                                    "subtask": false
                                },
                                "priority": {
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                                    "id": "3",
                                    "name": "Major",
                                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                                },
                                "status": {
                                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                                    "id": "6",
                                    "name": "Closed",
                                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                                },
                                "summary": "infinite retries accessing a missing block"
                            },
                            "id": "12330297",
                            "key": "HADOOP-83",
                            "self": "https://issues.apache.org/jira/rest/api/2/issue/12330297"
                        },
                        "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12312116",
                        "type": {
                            "id": "12310000",
                            "inward": "is duplicated by",
                            "name": "Duplicate",
                            "outward": "duplicates",
                            "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                        }
                    }
                ],
                "issuetype": {
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/bug.png",
                    "id": "1",
                    "name": "Bug",
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "subtask": false
                },
                "labels": [],
                "lastViewed": null,
                "priority": {
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.png",
                    "id": "3",
                    "name": "Major",
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                },
                "progress": {
                    "progress": 0,
                    "total": 0
                },
                "project": {
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                        "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
                    },
                    "id": "12310240",
                    "key": "HADOOP",
                    "name": "Hadoop Common",
                    "self": "https://issues.apache.org/jira/rest/api/2/project/HADOOP"
                },
                "reporter": {
                    "active": true,
                    "avatarUrls": {
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
                    },
                    "displayName": "Bryan Pendleton",
                    "emailAddress": "bpapache5@geekdom.net",
                    "name": "bpendleton",
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bpendleton"
                },
                "resolution": {
                    "description": "The problem is a duplicate of an existing issue.",
                    "id": "3",
                    "name": "Duplicate",
                    "self": "https://issues.apache.org/jira/rest/api/2/resolution/3"
                },
                "resolutiondate": "2006-03-25T05:33:24.000+0000",
                "status": {
                    "description": "The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "id": "6",
                    "name": "Closed",
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6"
                },
                "subtasks": [],
                "summary": "Files missing chunks can cause mapred runs to get stuck",
                "timeestimate": null,
                "timeoriginalestimate": null,
                "timespent": null,
                "timetracking": {},
                "updated": "2009-07-08T16:41:46.000+0000",
                "versions": [
                    {
                        "archived": false,
                        "description": "",
                        "id": "12310812",
                        "name": "0.1.0",
                        "releaseDate": "2006-04-02",
                        "released": true,
                        "self": "https://issues.apache.org/jira/rest/api/2/version/12310812"
                    }
                ],
                "votes": {
                    "hasVoted": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-35/votes",
                    "votes": 0
                },
                "watches": {
                    "isWatching": false,
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-35/watchers",
                    "watchCount": 0
                },
                "worklog": {
                    "maxResults": 0,
                    "startAt": 0,
                    "total": 0,
                    "worklogs": []
                },
                "workratio": -1
            },
            "id": "12328902",
            "key": "HADOOP-35",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/12328902"
        }
    ],
    "maxResults": 30,
    "startAt": 1,
    "total": 7925
}
